{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1yRAv8+U9Pn80xEfJDbmY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TANESHDEVHARE/Regression-model-by-Keras/blob/main/Build_Regression_Model_in_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries & Package**"
      ],
      "metadata": {
        "id": "POr5jMAeQEtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "mGxG2U9OQPgA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preparation**"
      ],
      "metadata": {
        "id": "jVqSrXhEQcYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('concrete_data.csv')"
      ],
      "metadata": {
        "id": "gDWY73doQhqg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XKN4drOVQs6B",
        "outputId": "ca15a851-b92a-4025-963e-26b24ff2ed91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
              "0   540.0                 0.0      0.0  162.0               2.5   \n",
              "1   540.0                 0.0      0.0  162.0               2.5   \n",
              "2   332.5               142.5      0.0  228.0               0.0   \n",
              "3   332.5               142.5      0.0  228.0               0.0   \n",
              "4   198.6               132.4      0.0  192.0               0.0   \n",
              "\n",
              "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
              "0            1040.0           676.0   28     79.99  \n",
              "1            1055.0           676.0   28     61.89  \n",
              "2             932.0           594.0  270     40.27  \n",
              "3             932.0           594.0  365     41.05  \n",
              "4             978.4           825.5  360     44.30  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8c7da37-7196-444b-81db-4df19acbc175\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>79.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>61.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "      <td>40.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "      <td>41.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "      <td>44.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8c7da37-7196-444b-81db-4df19acbc175')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a8c7da37-7196-444b-81db-4df19acbc175 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a8c7da37-7196-444b-81db-4df19acbc175');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dd5abc01-ecda-4225-89f7-10b59696ba29\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd5abc01-ecda-4225-89f7-10b59696ba29')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dd5abc01-ecda-4225-89f7-10b59696ba29 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1030,\n  \"fields\": [\n    {\n      \"column\": \"Cement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.50636449481532,\n        \"min\": 102.0,\n        \"max\": 540.0,\n        \"num_unique_values\": 278,\n        \"samples\": [\n          337.9,\n          290.2,\n          262.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blast Furnace Slag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86.27934174810584,\n        \"min\": 0.0,\n        \"max\": 359.4,\n        \"num_unique_values\": 185,\n        \"samples\": [\n          94.7,\n          119.0,\n          136.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fly Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.99700415268765,\n        \"min\": 0.0,\n        \"max\": 200.1,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          98.0,\n          142.0,\n          195.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Water\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.35421856503247,\n        \"min\": 121.8,\n        \"max\": 247.0,\n        \"num_unique_values\": 195,\n        \"samples\": [\n          195.4,\n          183.8,\n          127.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Superplasticizer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.97384139248552,\n        \"min\": 0.0,\n        \"max\": 32.2,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          15.0,\n          28.2,\n          16.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coarse Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 77.75395396672077,\n        \"min\": 801.0,\n        \"max\": 1145.0,\n        \"num_unique_values\": 284,\n        \"samples\": [\n          852.1,\n          913.9,\n          914.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fine Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.17598014240437,\n        \"min\": 594.0,\n        \"max\": 992.6,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          710.0,\n          695.4,\n          769.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63,\n        \"min\": 1,\n        \"max\": 365,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          91,\n          100,\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Strength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.705741961912512,\n        \"min\": 2.33,\n        \"max\": 82.6,\n        \"num_unique_values\": 845,\n        \"samples\": [\n          41.68,\n          39.59,\n          2.33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-Q31Ml9Qwj-",
        "outputId": "460cccd2-9c58-4432-8143-a71a219c4d3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1030 entries, 0 to 1029\n",
            "Data columns (total 9 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   Cement              1030 non-null   float64\n",
            " 1   Blast Furnace Slag  1030 non-null   float64\n",
            " 2   Fly Ash             1030 non-null   float64\n",
            " 3   Water               1030 non-null   float64\n",
            " 4   Superplasticizer    1030 non-null   float64\n",
            " 5   Coarse Aggregate    1030 non-null   float64\n",
            " 6   Fine Aggregate      1030 non-null   float64\n",
            " 7   Age                 1030 non-null   int64  \n",
            " 8   Strength            1030 non-null   float64\n",
            "dtypes: float64(8), int64(1)\n",
            "memory usage: 72.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "iSJuODGoQ1JJ",
        "outputId": "e760aa77-5154-4c83-fca3-e267f1d3123f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
              "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
              "mean    281.167864           73.895825    54.188350   181.567282   \n",
              "std     104.506364           86.279342    63.997004    21.354219   \n",
              "min     102.000000            0.000000     0.000000   121.800000   \n",
              "25%     192.375000            0.000000     0.000000   164.900000   \n",
              "50%     272.900000           22.000000     0.000000   185.000000   \n",
              "75%     350.000000          142.950000   118.300000   192.000000   \n",
              "max     540.000000          359.400000   200.100000   247.000000   \n",
              "\n",
              "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
              "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
              "mean           6.204660        972.918932      773.580485    45.662136   \n",
              "std            5.973841         77.753954       80.175980    63.169912   \n",
              "min            0.000000        801.000000      594.000000     1.000000   \n",
              "25%            0.000000        932.000000      730.950000     7.000000   \n",
              "50%            6.400000        968.000000      779.500000    28.000000   \n",
              "75%           10.200000       1029.400000      824.000000    56.000000   \n",
              "max           32.200000       1145.000000      992.600000   365.000000   \n",
              "\n",
              "          Strength  \n",
              "count  1030.000000  \n",
              "mean     35.817961  \n",
              "std      16.705742  \n",
              "min       2.330000  \n",
              "25%      23.710000  \n",
              "50%      34.445000  \n",
              "75%      46.135000  \n",
              "max      82.600000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51d22817-e194-4de4-bd6d-50c0519fc4d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>281.167864</td>\n",
              "      <td>73.895825</td>\n",
              "      <td>54.188350</td>\n",
              "      <td>181.567282</td>\n",
              "      <td>6.204660</td>\n",
              "      <td>972.918932</td>\n",
              "      <td>773.580485</td>\n",
              "      <td>45.662136</td>\n",
              "      <td>35.817961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>104.506364</td>\n",
              "      <td>86.279342</td>\n",
              "      <td>63.997004</td>\n",
              "      <td>21.354219</td>\n",
              "      <td>5.973841</td>\n",
              "      <td>77.753954</td>\n",
              "      <td>80.175980</td>\n",
              "      <td>63.169912</td>\n",
              "      <td>16.705742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>121.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>594.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>192.375000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>164.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>932.000000</td>\n",
              "      <td>730.950000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>23.710000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>272.900000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>968.000000</td>\n",
              "      <td>779.500000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>34.445000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>350.000000</td>\n",
              "      <td>142.950000</td>\n",
              "      <td>118.300000</td>\n",
              "      <td>192.000000</td>\n",
              "      <td>10.200000</td>\n",
              "      <td>1029.400000</td>\n",
              "      <td>824.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>46.135000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>540.000000</td>\n",
              "      <td>359.400000</td>\n",
              "      <td>200.100000</td>\n",
              "      <td>247.000000</td>\n",
              "      <td>32.200000</td>\n",
              "      <td>1145.000000</td>\n",
              "      <td>992.600000</td>\n",
              "      <td>365.000000</td>\n",
              "      <td>82.600000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51d22817-e194-4de4-bd6d-50c0519fc4d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-51d22817-e194-4de4-bd6d-50c0519fc4d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-51d22817-e194-4de4-bd6d-50c0519fc4d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ec5a72c5-b03a-4b60-ba42-c34063cc398c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec5a72c5-b03a-4b60-ba42-c34063cc398c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ec5a72c5-b03a-4b60-ba42-c34063cc398c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Cement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 305.925723919693,\n        \"min\": 102.0,\n        \"max\": 1030.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          281.16786407766995,\n          272.9,\n          1030.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blast Furnace Slag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 349.7840582355622,\n        \"min\": 0.0,\n        \"max\": 1030.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1030.0,\n          73.89582524271846,\n          142.95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fly Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 349.10248573300066,\n        \"min\": 0.0,\n        \"max\": 1030.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1030.0,\n          54.18834951456311,\n          200.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Water\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 314.8829234606696,\n        \"min\": 21.35421856503247,\n        \"max\": 1030.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          181.56728155339806,\n          185.0,\n          1030.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Superplasticizer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 361.22346926276094,\n        \"min\": 0.0,\n        \"max\": 1030.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1030.0,\n          6.204660194174758,\n          10.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coarse Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 334.4689898607596,\n        \"min\": 77.75395396672077,\n        \"max\": 1145.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          972.9189320388349,\n          968.0,\n          1030.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fine Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 295.86618714901516,\n        \"min\": 80.17598014240437,\n        \"max\": 1030.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          773.5804854368932,\n          779.5,\n          1030.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 355.7357522307611,\n        \"min\": 1.0,\n        \"max\": 1030.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          45.662135922330094,\n          28.0,\n          1030.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Strength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 352.74449506712654,\n        \"min\": 2.33,\n        \"max\": 1030.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          35.817961165048544,\n          34.445,\n          1030.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A. Build a Baseline Model**"
      ],
      "metadata": {
        "id": "Ctgt_fhCRBkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictors =  data.drop('Strength' ,axis=1)\n",
        "target = data['Strength']"
      ],
      "metadata": {
        "id": "CM-FfAdWRKfL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=1)"
      ],
      "metadata": {
        "id": "0GbXXWHrRbJ5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "QKQyHGeuRuQk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "7mGCF5ruRwUd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define regression model\n",
        "def regression_model():\n",
        "    #create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model"
      ],
      "metadata": {
        "id": "6M7ONNN_R0-j"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_cols = predictors.shape[1]\n",
        "mean_squared_errors = []\n",
        "\n",
        "for i in range(50):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=1)\n",
        "    model = regression_model()\n",
        "    model.fit(x_train, y_train, validation_data=(x_test, y_test) ,epochs=50, verbose=2)\n",
        "\n",
        "    mse = model.evaluate(x_test, y_test, verbose=0)\n",
        "    mean_squared_errors.append(mse)\n",
        "\n",
        "# Compute the mean and standard deviation of the mean squared errors\n",
        "import numpy as np\n",
        "mean_mse = np.mean(mean_squared_errors)\n",
        "std_mse = np.std(mean_squared_errors)\n",
        "\n",
        "print(\"Mean Squared Error:\", mean_mse)\n",
        "print(\"Standard Deviation of Mean Squared Error:\", std_mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASD8OdUkSM3G",
        "outputId": "b50ca47b-685f-4032-9bcd-4a1f9e600eaf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 46175.4258 - val_loss: 18301.4004\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 9329.8311 - val_loss: 2879.5784\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 3ms/step - loss: 2234.5093 - val_loss: 1782.3479\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1794.8859 - val_loss: 1680.0715\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 7ms/step - loss: 1679.4514 - val_loss: 1538.4648\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 5ms/step - loss: 1563.5231 - val_loss: 1424.7708\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1461.4456 - val_loss: 1306.5275\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1355.0764 - val_loss: 1208.7727\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1261.1995 - val_loss: 1113.3005\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1171.2975 - val_loss: 1023.1093\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 3ms/step - loss: 1088.1082 - val_loss: 943.3088\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 7ms/step - loss: 1013.9861 - val_loss: 870.9753\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 7ms/step - loss: 946.1230 - val_loss: 807.3309\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 882.1289 - val_loss: 748.0842\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 825.1388 - val_loss: 698.5597\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 772.5767 - val_loss: 652.9292\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 727.8265 - val_loss: 611.8314\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 685.8121 - val_loss: 574.7646\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 7ms/step - loss: 649.3956 - val_loss: 543.4378\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 614.8932 - val_loss: 517.4770\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 585.6707 - val_loss: 492.5678\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 559.1353 - val_loss: 471.2352\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 535.2253 - val_loss: 451.3257\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 7ms/step - loss: 513.0298 - val_loss: 433.8705\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 492.2289 - val_loss: 420.3067\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 474.6921 - val_loss: 405.9301\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 458.0410 - val_loss: 395.3930\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 442.6652 - val_loss: 382.6807\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 429.3016 - val_loss: 373.1596\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 415.1045 - val_loss: 362.8782\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 402.3375 - val_loss: 353.2261\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 391.0339 - val_loss: 347.5845\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 379.2081 - val_loss: 336.2823\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 369.7180 - val_loss: 330.2092\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 359.2276 - val_loss: 321.5493\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 350.8691 - val_loss: 315.9883\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 340.3617 - val_loss: 307.1638\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 7ms/step - loss: 333.2304 - val_loss: 302.6046\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 323.9174 - val_loss: 293.3487\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 314.6044 - val_loss: 292.2052\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 307.6508 - val_loss: 282.2641\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 7ms/step - loss: 300.2025 - val_loss: 277.9130\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 294.3177 - val_loss: 271.9842\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 286.7318 - val_loss: 267.2015\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 280.4217 - val_loss: 264.7748\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 274.8778 - val_loss: 254.7671\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 267.9532 - val_loss: 255.2380\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 13ms/step - loss: 262.6773 - val_loss: 251.1706\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 12ms/step - loss: 255.9481 - val_loss: 243.3590\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 248.9326 - val_loss: 236.3798\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 274262.0312 - val_loss: 173698.7188\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 119963.2031 - val_loss: 67830.3516\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 44499.6719 - val_loss: 23673.8633\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 5ms/step - loss: 16135.5391 - val_loss: 9400.7324\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 8012.4375 - val_loss: 5975.1660\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 7ms/step - loss: 6205.7827 - val_loss: 5335.4062\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 5821.3203 - val_loss: 5133.4912\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 5619.4473 - val_loss: 4966.5815\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 5440.1763 - val_loss: 4808.7764\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 5ms/step - loss: 5257.1553 - val_loss: 4654.0142\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 5087.9917 - val_loss: 4508.5161\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 4928.5239 - val_loss: 4363.8926\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 4761.1045 - val_loss: 4239.9380\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 4616.3311 - val_loss: 4117.1021\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 3ms/step - loss: 4478.9097 - val_loss: 3999.6870\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 4340.2842 - val_loss: 3892.7759\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 4219.4683 - val_loss: 3785.3281\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 4096.9839 - val_loss: 3689.9644\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 3981.6719 - val_loss: 3591.5879\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 3872.4075 - val_loss: 3510.7532\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 3765.3352 - val_loss: 3423.1501\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 3666.0132 - val_loss: 3344.8384\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 3573.8843 - val_loss: 3268.4712\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 3478.9768 - val_loss: 3198.4663\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 3ms/step - loss: 3390.4446 - val_loss: 3132.3584\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 3309.3118 - val_loss: 3066.0713\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 3230.9570 - val_loss: 3002.6738\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 3144.3550 - val_loss: 2934.6106\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 3069.3196 - val_loss: 2874.3120\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 2995.9172 - val_loss: 2814.5327\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 2929.6575 - val_loss: 2762.6904\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 2857.5935 - val_loss: 2704.8674\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 2789.2070 - val_loss: 2654.4885\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 2728.2034 - val_loss: 2601.9585\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 2660.9888 - val_loss: 2549.8088\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 2599.8970 - val_loss: 2499.5828\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 2540.2510 - val_loss: 2453.0254\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 2482.3669 - val_loss: 2404.7292\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 2429.7131 - val_loss: 2355.9131\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 2373.2659 - val_loss: 2309.1665\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 5ms/step - loss: 2318.0249 - val_loss: 2274.0513\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 2271.9409 - val_loss: 2219.3728\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 2213.7605 - val_loss: 2180.6497\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 2169.3994 - val_loss: 2138.3428\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 2118.6919 - val_loss: 2092.2969\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 2070.4165 - val_loss: 2056.4221\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 2023.4147 - val_loss: 2014.1954\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 1976.9244 - val_loss: 1976.0640\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 1933.8369 - val_loss: 1936.9692\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 1891.5776 - val_loss: 1895.1345\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 12552.3916 - val_loss: 5887.3955\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 3109.9722 - val_loss: 1503.2732\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1356.6090 - val_loss: 1111.6996\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1257.5886 - val_loss: 1036.1954\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 7ms/step - loss: 1170.8693 - val_loss: 967.1393\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1090.5367 - val_loss: 901.2267\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1015.6469 - val_loss: 826.3863\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 942.3505 - val_loss: 766.2295\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 875.7245 - val_loss: 705.7280\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 3ms/step - loss: 816.0826 - val_loss: 648.4771\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 753.0491 - val_loss: 605.5385\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 7ms/step - loss: 701.9419 - val_loss: 559.4816\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 651.3760 - val_loss: 514.3805\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 606.6674 - val_loss: 480.5410\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 567.6279 - val_loss: 450.5246\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 530.6680 - val_loss: 416.9935\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 497.4754 - val_loss: 392.9911\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 465.6266 - val_loss: 367.2361\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 437.9131 - val_loss: 348.3950\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 414.1235 - val_loss: 329.8292\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 391.8496 - val_loss: 312.3626\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 7ms/step - loss: 373.1440 - val_loss: 301.7291\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 13ms/step - loss: 355.6534 - val_loss: 287.0827\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 12ms/step - loss: 338.3932 - val_loss: 276.2616\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 13ms/step - loss: 322.8729 - val_loss: 264.4382\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 11ms/step - loss: 310.2904 - val_loss: 256.1536\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 297.1326 - val_loss: 246.6670\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 286.7402 - val_loss: 240.7166\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 277.2818 - val_loss: 234.3760\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 268.5286 - val_loss: 227.7732\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 259.3081 - val_loss: 222.8835\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 252.0586 - val_loss: 218.6625\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 244.7547 - val_loss: 213.0563\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 238.2150 - val_loss: 208.9317\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 231.8879 - val_loss: 205.4504\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 225.6829 - val_loss: 201.7103\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 220.6197 - val_loss: 197.8166\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 215.0523 - val_loss: 196.0207\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 210.2724 - val_loss: 191.9686\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 205.8705 - val_loss: 191.2679\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 201.4234 - val_loss: 186.7765\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 198.7220 - val_loss: 186.5757\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 194.2021 - val_loss: 181.6636\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 190.4439 - val_loss: 178.9803\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 187.6548 - val_loss: 177.4373\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 183.8796 - val_loss: 175.8214\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 180.7702 - val_loss: 174.2533\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 177.5535 - val_loss: 171.6357\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 174.3866 - val_loss: 170.6312\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 171.8050 - val_loss: 167.4448\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 7764.3892 - val_loss: 5246.1826\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 4153.5474 - val_loss: 3634.0229\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 3100.5266 - val_loss: 2743.7354\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 2375.7625 - val_loss: 2028.5186\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 5ms/step - loss: 1785.8077 - val_loss: 1493.3400\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1350.7567 - val_loss: 1120.6085\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1038.9838 - val_loss: 836.7989\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 811.9817 - val_loss: 641.0003\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 641.9694 - val_loss: 509.7283\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 532.7516 - val_loss: 422.4998\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 442.8485 - val_loss: 350.7581\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 382.9037 - val_loss: 311.1181\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 5ms/step - loss: 341.0771 - val_loss: 284.6966\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 5ms/step - loss: 307.2188 - val_loss: 261.2511\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 3ms/step - loss: 280.6396 - val_loss: 243.1388\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 261.8217 - val_loss: 230.3454\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 244.6880 - val_loss: 219.3963\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 232.3279 - val_loss: 210.4065\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 214.7827 - val_loss: 198.3045\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 207.8482 - val_loss: 191.9725\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 193.4304 - val_loss: 184.3565\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 182.5788 - val_loss: 177.9184\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 178.8662 - val_loss: 172.8326\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 167.6506 - val_loss: 167.0568\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 160.8177 - val_loss: 161.1671\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 154.9912 - val_loss: 158.0133\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.5927 - val_loss: 153.6232\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 7ms/step - loss: 144.8331 - val_loss: 149.1683\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 139.3922 - val_loss: 146.8432\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.1957 - val_loss: 144.0024\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 134.3443 - val_loss: 141.6529\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 129.9416 - val_loss: 138.9432\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 5ms/step - loss: 127.9099 - val_loss: 147.3994\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 127.1618 - val_loss: 137.8842\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 3ms/step - loss: 122.8091 - val_loss: 137.1734\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 122.2212 - val_loss: 133.7296\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 120.6935 - val_loss: 132.1723\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 119.5305 - val_loss: 131.2197\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 117.2195 - val_loss: 129.2890\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 117.8500 - val_loss: 131.1089\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 114.4981 - val_loss: 130.2245\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 113.6170 - val_loss: 129.4455\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 112.4600 - val_loss: 127.3633\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 112.0009 - val_loss: 127.6394\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 111.2219 - val_loss: 128.5524\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 7ms/step - loss: 111.0387 - val_loss: 127.9678\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 109.6646 - val_loss: 126.3567\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 111.2250 - val_loss: 125.6274\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 13ms/step - loss: 113.3959 - val_loss: 131.1922\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 112.7466 - val_loss: 124.9972\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 59ms/step - loss: 2238.9082 - val_loss: 1484.8478\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 18ms/step - loss: 1236.4733 - val_loss: 1028.5651\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 5ms/step - loss: 897.4196 - val_loss: 745.2389\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 661.6445 - val_loss: 546.7911\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 502.8855 - val_loss: 413.7823\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 398.3830 - val_loss: 340.3018\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 335.0987 - val_loss: 286.2433\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 290.4932 - val_loss: 256.0466\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 262.8555 - val_loss: 233.0201\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 243.3538 - val_loss: 216.7856\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 227.7616 - val_loss: 203.9337\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 216.7486 - val_loss: 194.4078\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 207.3434 - val_loss: 186.6342\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 201.2728 - val_loss: 184.0838\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 193.1131 - val_loss: 174.4418\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 187.9368 - val_loss: 169.9889\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 182.1344 - val_loss: 166.3300\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 179.4753 - val_loss: 165.4546\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 172.9809 - val_loss: 160.1741\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 169.5274 - val_loss: 156.8987\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.1196 - val_loss: 156.2000\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 163.5858 - val_loss: 152.8437\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 160.0277 - val_loss: 149.4350\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 157.8329 - val_loss: 147.7542\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 153.5047 - val_loss: 145.8195\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 153.0070 - val_loss: 143.7189\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 149.5087 - val_loss: 141.8726\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 147.0344 - val_loss: 141.1132\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.9389 - val_loss: 139.4003\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 143.0123 - val_loss: 137.6796\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.7268 - val_loss: 136.3547\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.1244 - val_loss: 134.9815\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 139.2185 - val_loss: 136.1681\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 137.2417 - val_loss: 132.2359\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 138.1240 - val_loss: 131.4135\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 133.1403 - val_loss: 133.2625\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 131.3314 - val_loss: 128.6812\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 129.8865 - val_loss: 127.5773\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 128.9143 - val_loss: 126.8949\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 126.3727 - val_loss: 125.1327\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 124.7838 - val_loss: 123.2975\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 123.7102 - val_loss: 121.9259\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 122.8830 - val_loss: 121.3011\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 122.4819 - val_loss: 119.6938\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 121.1815 - val_loss: 118.9706\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 7ms/step - loss: 119.1031 - val_loss: 118.0505\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 117.6880 - val_loss: 121.3978\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 117.7851 - val_loss: 118.4057\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 114.7939 - val_loss: 114.2292\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 113.2042 - val_loss: 114.4506\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 42ms/step - loss: 222548.1094 - val_loss: 166189.3281\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 129891.6172 - val_loss: 93192.8516\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 68541.8672 - val_loss: 46825.4453\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 32787.1250 - val_loss: 22054.1250\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 15043.0684 - val_loss: 10421.2256\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 7151.4277 - val_loss: 5677.3682\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 4184.2773 - val_loss: 3958.8164\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 3172.6702 - val_loss: 3400.0247\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 2855.7175 - val_loss: 3181.2424\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 2709.2981 - val_loss: 3049.5186\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 2603.9714 - val_loss: 2940.1147\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 2519.6316 - val_loss: 2823.9526\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 5ms/step - loss: 2421.4424 - val_loss: 2720.2122\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 2331.0242 - val_loss: 2617.9216\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 2242.2380 - val_loss: 2513.4048\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 2154.1577 - val_loss: 2415.3689\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 2075.3164 - val_loss: 2315.1125\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1987.8372 - val_loss: 2219.2134\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 1907.6602 - val_loss: 2131.3584\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 8ms/step - loss: 1830.7587 - val_loss: 2040.7300\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 12ms/step - loss: 1754.8412 - val_loss: 1956.7904\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1683.0012 - val_loss: 1877.0961\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1614.7743 - val_loss: 1797.1962\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1547.3998 - val_loss: 1720.6721\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 8ms/step - loss: 1485.3794 - val_loss: 1648.7615\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 12ms/step - loss: 1423.1289 - val_loss: 1576.8104\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 1366.1855 - val_loss: 1510.2045\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 1306.2834 - val_loss: 1443.6201\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 1251.9879 - val_loss: 1382.8446\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 1200.1315 - val_loss: 1323.9283\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 14ms/step - loss: 1150.0513 - val_loss: 1267.1033\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 12ms/step - loss: 1104.0038 - val_loss: 1212.9738\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 1058.8256 - val_loss: 1162.3761\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 1016.9279 - val_loss: 1113.4163\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 975.0347 - val_loss: 1066.2103\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 935.9360 - val_loss: 1024.7609\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 899.0886 - val_loss: 980.8656\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 5ms/step - loss: 863.6656 - val_loss: 940.5674\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 829.7939 - val_loss: 901.2378\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 797.3085 - val_loss: 865.3108\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 767.9396 - val_loss: 829.0474\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 737.9001 - val_loss: 798.0826\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 711.1766 - val_loss: 767.1244\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 5ms/step - loss: 685.2510 - val_loss: 736.8686\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 660.2859 - val_loss: 708.0671\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 636.2418 - val_loss: 681.9609\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 614.6108 - val_loss: 655.8846\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 592.7141 - val_loss: 633.2065\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 574.0388 - val_loss: 610.5049\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 553.9232 - val_loss: 588.4053\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 60ms/step - loss: 351982.4375 - val_loss: 242099.4375\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 182641.8906 - val_loss: 106583.3672\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 73720.8516 - val_loss: 36903.9961\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 25398.1699 - val_loss: 12835.8086\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 9930.1104 - val_loss: 7770.7563\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 5ms/step - loss: 6722.6323 - val_loss: 7249.3906\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 6237.1831 - val_loss: 7233.6157\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 6088.0151 - val_loss: 7061.7412\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 5957.0796 - val_loss: 6812.5542\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 5810.6509 - val_loss: 6567.8882\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 5685.2002 - val_loss: 6383.0376\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 5560.0566 - val_loss: 6170.5791\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 5416.6348 - val_loss: 6061.2900\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 5ms/step - loss: 5292.0127 - val_loss: 5849.3408\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 5172.7969 - val_loss: 5688.3926\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 5074.2588 - val_loss: 5494.7188\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 4934.1279 - val_loss: 5380.2246\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 4821.1641 - val_loss: 5208.9902\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 4729.0005 - val_loss: 5047.3564\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 4615.6729 - val_loss: 4919.4067\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 4510.6226 - val_loss: 4843.3169\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 5ms/step - loss: 4412.1694 - val_loss: 4633.4658\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 4310.4380 - val_loss: 4553.8701\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 4218.3569 - val_loss: 4456.9912\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 4128.9297 - val_loss: 4331.7749\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 4045.0159 - val_loss: 4273.2573\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 3955.9380 - val_loss: 4114.2227\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 3883.3491 - val_loss: 3968.5137\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 3796.4309 - val_loss: 3893.0630\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 3715.3235 - val_loss: 3795.6262\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 3639.1929 - val_loss: 3710.6873\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 3563.7915 - val_loss: 3658.3330\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 3484.9788 - val_loss: 3534.5371\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 3424.2395 - val_loss: 3436.0732\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 3348.8499 - val_loss: 3400.7905\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 3285.3384 - val_loss: 3325.4939\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 3218.9219 - val_loss: 3206.8499\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 3155.1475 - val_loss: 3179.6238\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 3092.0422 - val_loss: 3106.6250\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 3034.9407 - val_loss: 3042.1121\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 5ms/step - loss: 2974.2219 - val_loss: 2971.0691\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 2910.1521 - val_loss: 2908.9624\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 2864.0007 - val_loss: 2833.9575\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 2794.0735 - val_loss: 2811.3303\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 2736.4609 - val_loss: 2730.3999\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 3ms/step - loss: 2683.0249 - val_loss: 2679.2546\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 2633.5151 - val_loss: 2631.6746\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 7ms/step - loss: 2573.7080 - val_loss: 2545.2529\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 7ms/step - loss: 2524.6096 - val_loss: 2497.5032\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 2472.1824 - val_loss: 2458.8081\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 60ms/step - loss: 45128.0312 - val_loss: 20180.9004\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 20ms/step - loss: 14037.1592 - val_loss: 9439.0625\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 11ms/step - loss: 9176.4248 - val_loss: 9071.2930\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 8450.1377 - val_loss: 8063.3496\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 7688.2412 - val_loss: 7313.6665\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 6932.2573 - val_loss: 6591.1968\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 6203.5137 - val_loss: 5897.7324\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 5522.3013 - val_loss: 5162.2563\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 4824.4258 - val_loss: 4518.5601\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 4214.6216 - val_loss: 3937.2979\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 3682.5510 - val_loss: 3413.6460\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 3209.7019 - val_loss: 2939.3367\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 2757.2500 - val_loss: 2569.9741\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 2387.1594 - val_loss: 2197.6604\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 2072.7920 - val_loss: 1867.0538\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1795.0946 - val_loss: 1638.1165\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1564.3787 - val_loss: 1402.7054\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1358.8545 - val_loss: 1258.7644\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1191.4915 - val_loss: 1071.4030\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1055.0421 - val_loss: 963.5908\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 920.3907 - val_loss: 829.5030\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 5ms/step - loss: 819.5604 - val_loss: 755.8289\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 723.2787 - val_loss: 641.3493\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 647.8657 - val_loss: 571.2336\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 574.6017 - val_loss: 515.7781\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 515.5588 - val_loss: 451.1243\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 460.6642 - val_loss: 428.8882\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 411.6187 - val_loss: 362.8602\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 368.9160 - val_loss: 327.5536\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 332.7401 - val_loss: 299.1459\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 301.0484 - val_loss: 281.6303\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 272.4707 - val_loss: 244.7950\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 248.8537 - val_loss: 235.9919\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 230.7202 - val_loss: 210.0105\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 207.7654 - val_loss: 197.6141\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 195.9509 - val_loss: 181.1351\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 179.5354 - val_loss: 169.5300\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 168.9297 - val_loss: 160.8623\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 158.4714 - val_loss: 154.4368\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.9012 - val_loss: 151.0592\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 143.0272 - val_loss: 145.8216\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.2926 - val_loss: 139.9162\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 134.0975 - val_loss: 136.9421\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 129.1894 - val_loss: 135.8145\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 125.6131 - val_loss: 132.7000\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 125.8152 - val_loss: 130.7484\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 123.9005 - val_loss: 129.5989\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 119.2729 - val_loss: 128.6998\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 117.4980 - val_loss: 127.8384\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 116.2575 - val_loss: 131.1891\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1359.9742 - val_loss: 677.2521\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 753.4994 - val_loss: 563.0373\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 610.7313 - val_loss: 473.0556\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 530.9166 - val_loss: 434.9162\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 472.1899 - val_loss: 415.7905\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 428.3335 - val_loss: 364.3389\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 383.7048 - val_loss: 330.3640\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 343.8640 - val_loss: 299.0316\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 309.5516 - val_loss: 272.2023\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 283.4337 - val_loss: 252.0709\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 257.7801 - val_loss: 239.0906\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 239.9288 - val_loss: 216.7058\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 220.3945 - val_loss: 203.1222\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 205.3768 - val_loss: 193.4835\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 194.5662 - val_loss: 182.7085\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 182.3213 - val_loss: 176.2007\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 174.8683 - val_loss: 169.2544\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 164.2650 - val_loss: 165.0401\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 7ms/step - loss: 159.5434 - val_loss: 168.7675\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 152.7150 - val_loss: 159.6249\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 149.2142 - val_loss: 155.1311\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 7ms/step - loss: 147.7640 - val_loss: 153.2109\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 5ms/step - loss: 140.9059 - val_loss: 151.5739\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 138.0064 - val_loss: 153.6467\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 139.0246 - val_loss: 151.8961\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 132.5991 - val_loss: 148.6062\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 131.2221 - val_loss: 148.3760\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 129.2980 - val_loss: 147.5674\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 127.6016 - val_loss: 146.0981\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 7ms/step - loss: 126.5353 - val_loss: 162.0316\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 127.7274 - val_loss: 144.8297\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 123.3322 - val_loss: 145.4844\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 122.9428 - val_loss: 143.9342\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 12ms/step - loss: 122.6851 - val_loss: 143.8575\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 120.2036 - val_loss: 141.8718\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 8ms/step - loss: 122.0738 - val_loss: 144.0956\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 11ms/step - loss: 119.3114 - val_loss: 141.3559\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 5ms/step - loss: 117.2417 - val_loss: 141.2287\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 115.7168 - val_loss: 142.8342\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 115.1220 - val_loss: 139.3258\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 114.8421 - val_loss: 138.6949\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 112.8372 - val_loss: 139.5722\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 112.8149 - val_loss: 138.1296\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 115.4923 - val_loss: 138.0715\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 117.4547 - val_loss: 141.4323\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 7ms/step - loss: 111.2159 - val_loss: 141.4025\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 109.5242 - val_loss: 136.8576\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 5ms/step - loss: 108.9778 - val_loss: 136.2227\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 108.3796 - val_loss: 143.9424\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 108.8481 - val_loss: 135.3463\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 127301.3516 - val_loss: 73438.9219\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 51429.7852 - val_loss: 25305.9180\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 16742.9102 - val_loss: 7797.0444\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 5500.0044 - val_loss: 4087.0708\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 3153.1169 - val_loss: 3739.2791\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 2778.7742 - val_loss: 3589.1619\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 2614.6982 - val_loss: 3373.6643\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 2468.9573 - val_loss: 3162.5737\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 2332.3235 - val_loss: 2979.9817\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 7ms/step - loss: 2202.0203 - val_loss: 2805.6907\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 2072.6953 - val_loss: 2662.2097\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 1953.2245 - val_loss: 2490.0171\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1834.3477 - val_loss: 2347.6680\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 1725.2054 - val_loss: 2216.2168\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1620.6577 - val_loss: 2076.0105\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1524.2579 - val_loss: 1944.2533\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1431.2471 - val_loss: 1839.4144\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1347.3689 - val_loss: 1731.0917\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 7ms/step - loss: 1264.8394 - val_loss: 1622.4744\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 1191.5154 - val_loss: 1530.5909\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1121.8750 - val_loss: 1441.1329\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1058.0546 - val_loss: 1360.4449\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 996.9578 - val_loss: 1280.0461\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 941.0683 - val_loss: 1211.1210\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 889.3309 - val_loss: 1145.9296\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 840.4788 - val_loss: 1092.6259\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 798.2447 - val_loss: 1033.3495\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 757.4457 - val_loss: 980.9247\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 720.7572 - val_loss: 929.4968\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 686.2465 - val_loss: 882.5067\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 653.0919 - val_loss: 849.2351\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 624.3218 - val_loss: 807.0390\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 598.5041 - val_loss: 769.1858\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 573.0344 - val_loss: 742.8201\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 550.6270 - val_loss: 702.3251\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 529.2036 - val_loss: 683.9686\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 509.1900 - val_loss: 649.4661\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 491.7027 - val_loss: 630.0125\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 474.2801 - val_loss: 605.6568\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 459.1719 - val_loss: 591.7883\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 443.8460 - val_loss: 564.6943\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 430.7786 - val_loss: 548.3647\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 417.6521 - val_loss: 535.0202\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 405.9270 - val_loss: 520.2905\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 394.4855 - val_loss: 503.5652\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 383.6838 - val_loss: 487.0268\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 374.7122 - val_loss: 477.0958\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 364.8767 - val_loss: 462.2409\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 354.9381 - val_loss: 451.8367\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 347.1052 - val_loss: 440.7754\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 52ms/step - loss: 889638.6875 - val_loss: 771616.3750\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 6ms/step - loss: 700438.6875 - val_loss: 608538.7500\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 554931.5000 - val_loss: 484566.5312\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 444280.1562 - val_loss: 389929.3750\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 8ms/step - loss: 359523.7812 - val_loss: 317041.7812\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 8ms/step - loss: 293866.0625 - val_loss: 260402.4375\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 242561.0938 - val_loss: 215781.1562\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 8ms/step - loss: 201889.8125 - val_loss: 180400.8125\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 169442.0781 - val_loss: 151891.3750\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 8ms/step - loss: 143192.8594 - val_loss: 128788.1016\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 11ms/step - loss: 121827.1094 - val_loss: 109887.8203\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 104270.8125 - val_loss: 94349.3125\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 89780.1406 - val_loss: 81411.7969\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 5ms/step - loss: 77681.3438 - val_loss: 70663.7344\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 67563.8203 - val_loss: 61665.8047\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 59057.5312 - val_loss: 54130.5547\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 51886.6250 - val_loss: 47820.0469\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 45859.6523 - val_loss: 42428.3438\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 40732.0430 - val_loss: 37796.1133\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 36311.4922 - val_loss: 33803.7344\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 32509.4609 - val_loss: 30330.8320\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 29196.3613 - val_loss: 27292.2207\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 26288.2441 - val_loss: 24608.7734\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 23722.1738 - val_loss: 22242.1934\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 21450.8262 - val_loss: 20118.5371\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 19414.6602 - val_loss: 18230.2773\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 17600.2266 - val_loss: 16527.0430\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 15966.5586 - val_loss: 14997.8477\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 14494.5947 - val_loss: 13617.7441\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 13167.5449 - val_loss: 12368.9531\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 11966.1045 - val_loss: 11239.8027\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 10878.0059 - val_loss: 10211.0244\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 5ms/step - loss: 9884.7432 - val_loss: 9279.8984\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 8982.6035 - val_loss: 8432.0508\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 8162.5576 - val_loss: 7654.7710\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 7409.4673 - val_loss: 6950.0518\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 6725.3418 - val_loss: 6301.1758\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 6095.8765 - val_loss: 5711.9214\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 5524.4863 - val_loss: 5168.0630\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 4998.2427 - val_loss: 4676.9390\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 4521.1919 - val_loss: 4228.3154\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 7ms/step - loss: 4087.6387 - val_loss: 3814.7375\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 3690.9272 - val_loss: 3443.8191\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 3335.3760 - val_loss: 3110.6716\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 3016.7393 - val_loss: 2813.5178\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 2730.2632 - val_loss: 2545.7058\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 2475.9385 - val_loss: 2312.5889\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 2258.4001 - val_loss: 2113.1946\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 2069.1665 - val_loss: 1941.0939\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 5ms/step - loss: 1903.8466 - val_loss: 1793.6620\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 12660.1553 - val_loss: 7066.2168\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 6509.1450 - val_loss: 4974.5742\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 4997.7905 - val_loss: 4250.4062\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 4323.9136 - val_loss: 3573.3467\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 7ms/step - loss: 3654.3159 - val_loss: 2969.1958\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 3050.0081 - val_loss: 2486.8809\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 2573.2922 - val_loss: 2092.6804\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 2195.9915 - val_loss: 1774.7189\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1910.9625 - val_loss: 1539.1702\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1643.2522 - val_loss: 1355.5016\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1432.5723 - val_loss: 1164.0714\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1272.8599 - val_loss: 1033.0453\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1127.4767 - val_loss: 958.9925\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1024.9850 - val_loss: 843.7097\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 911.1341 - val_loss: 757.8789\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 820.0107 - val_loss: 693.7894\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 738.4355 - val_loss: 625.4647\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 676.2048 - val_loss: 572.7800\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 607.8133 - val_loss: 522.9940\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 553.6912 - val_loss: 477.3972\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 500.1591 - val_loss: 429.5383\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 446.1501 - val_loss: 386.9456\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 396.7769 - val_loss: 326.1936\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 332.8784 - val_loss: 284.3215\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 293.3150 - val_loss: 250.0025\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 263.3657 - val_loss: 236.6845\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 239.3025 - val_loss: 229.1472\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 7ms/step - loss: 218.8075 - val_loss: 221.6657\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 203.4154 - val_loss: 218.6585\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 192.0336 - val_loss: 213.7793\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 7ms/step - loss: 187.4367 - val_loss: 214.8582\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 8ms/step - loss: 182.7704 - val_loss: 210.5788\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 176.4117 - val_loss: 206.5328\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 172.7070 - val_loss: 195.9828\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 12ms/step - loss: 163.5790 - val_loss: 195.0704\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 161.4279 - val_loss: 205.0628\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 162.9984 - val_loss: 185.2301\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 7ms/step - loss: 154.1885 - val_loss: 183.5180\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 14ms/step - loss: 152.4090 - val_loss: 189.8957\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 11ms/step - loss: 148.0878 - val_loss: 183.1214\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.9733 - val_loss: 170.3721\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 143.1528 - val_loss: 171.1643\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 8ms/step - loss: 140.5762 - val_loss: 163.9407\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 138.6752 - val_loss: 162.4823\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 13ms/step - loss: 135.3712 - val_loss: 159.1683\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 134.4011 - val_loss: 172.8508\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 136.1174 - val_loss: 154.7874\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 128.3731 - val_loss: 153.4287\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 127.4732 - val_loss: 154.8174\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 126.6616 - val_loss: 147.2502\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 157618.5469 - val_loss: 115053.7500\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 88405.9219 - val_loss: 61682.6875\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 46525.1953 - val_loss: 31203.0938\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 23260.3184 - val_loss: 15128.5195\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 11316.8506 - val_loss: 7255.2339\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 5621.4331 - val_loss: 3668.2888\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 3061.4900 - val_loss: 2149.6431\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 2002.3898 - val_loss: 1580.0623\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1577.3417 - val_loss: 1383.4208\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1415.7032 - val_loss: 1309.4713\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1347.3141 - val_loss: 1274.5079\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1307.7825 - val_loss: 1247.3531\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 7ms/step - loss: 1275.9329 - val_loss: 1221.2314\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1245.1610 - val_loss: 1194.9661\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1215.0304 - val_loss: 1164.7709\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 1184.7076 - val_loss: 1135.4645\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1154.1229 - val_loss: 1107.5596\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1123.9004 - val_loss: 1078.4406\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1095.6694 - val_loss: 1049.6046\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 1066.1168 - val_loss: 1023.3817\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1038.1732 - val_loss: 999.5811\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1010.1744 - val_loss: 972.1747\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 984.2527 - val_loss: 945.3300\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 5ms/step - loss: 958.8843 - val_loss: 924.5067\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 929.9821 - val_loss: 897.8495\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 905.0312 - val_loss: 874.4271\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 880.9589 - val_loss: 853.0369\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 857.0641 - val_loss: 829.4130\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 833.8824 - val_loss: 808.8812\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 811.0487 - val_loss: 788.2173\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 788.9872 - val_loss: 768.3076\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 768.1254 - val_loss: 749.7774\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 747.9386 - val_loss: 731.4930\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 728.1587 - val_loss: 713.4385\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 709.3419 - val_loss: 697.3555\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 690.8351 - val_loss: 681.2204\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 673.7835 - val_loss: 665.5324\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 5ms/step - loss: 656.4305 - val_loss: 650.3934\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 639.5166 - val_loss: 635.5716\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 623.9163 - val_loss: 621.5162\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 608.8911 - val_loss: 609.8987\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 7ms/step - loss: 593.1408 - val_loss: 595.0562\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 580.1733 - val_loss: 583.1776\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 565.4918 - val_loss: 570.2979\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 551.8251 - val_loss: 559.6818\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 539.8320 - val_loss: 548.1495\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 527.1746 - val_loss: 538.5378\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 514.8309 - val_loss: 527.2580\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 502.9914 - val_loss: 516.6531\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 492.2251 - val_loss: 506.9196\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 20804.5898 - val_loss: 9455.4893\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 6150.2495 - val_loss: 3131.4946\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 5ms/step - loss: 2261.1360 - val_loss: 1525.4468\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1254.4180 - val_loss: 1122.2102\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 974.2832 - val_loss: 964.2788\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 832.7100 - val_loss: 847.1799\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 730.0190 - val_loss: 755.4294\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 5ms/step - loss: 648.0435 - val_loss: 680.2626\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 580.9929 - val_loss: 618.2598\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 12ms/step - loss: 526.1889 - val_loss: 565.1998\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 480.1803 - val_loss: 522.2230\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 8ms/step - loss: 439.8150 - val_loss: 482.2529\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 405.2043 - val_loss: 450.1096\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 376.5912 - val_loss: 421.8656\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 8ms/step - loss: 351.4534 - val_loss: 396.1249\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 11ms/step - loss: 329.3813 - val_loss: 375.9618\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 310.6432 - val_loss: 357.7432\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 8ms/step - loss: 294.2360 - val_loss: 342.4301\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 279.8060 - val_loss: 328.1222\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 266.5728 - val_loss: 316.3731\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 11ms/step - loss: 255.7586 - val_loss: 305.1092\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 245.6107 - val_loss: 295.3107\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 237.3633 - val_loss: 287.3108\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 5ms/step - loss: 229.9801 - val_loss: 279.1941\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 222.7364 - val_loss: 272.8179\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 216.8524 - val_loss: 265.6558\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 211.2062 - val_loss: 260.7233\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 206.2604 - val_loss: 254.4773\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 201.5791 - val_loss: 250.4564\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 197.6567 - val_loss: 246.0054\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 194.1505 - val_loss: 242.0344\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 190.9726 - val_loss: 238.2073\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 187.7417 - val_loss: 233.8174\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 184.8274 - val_loss: 231.0334\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 7ms/step - loss: 181.6691 - val_loss: 227.1708\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 179.2000 - val_loss: 224.2262\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 176.9128 - val_loss: 219.8391\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 173.6141 - val_loss: 218.6339\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 171.9258 - val_loss: 215.3538\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 168.9710 - val_loss: 210.3116\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 165.6801 - val_loss: 208.3937\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 162.5801 - val_loss: 203.9227\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 159.7478 - val_loss: 200.3972\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 157.1012 - val_loss: 196.3549\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 155.6882 - val_loss: 192.5664\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 152.4944 - val_loss: 188.9045\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 149.3830 - val_loss: 186.1825\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.7352 - val_loss: 180.9064\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 143.6491 - val_loss: 179.1183\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.6316 - val_loss: 174.6572\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 74671.0859 - val_loss: 36558.5195\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 21097.3223 - val_loss: 9240.1621\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 5ms/step - loss: 6720.1304 - val_loss: 5544.3545\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 5091.7705 - val_loss: 5163.0991\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 4698.5464 - val_loss: 4728.0645\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 7ms/step - loss: 4332.2295 - val_loss: 4317.3140\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 3992.1970 - val_loss: 3946.1680\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 3655.2788 - val_loss: 3621.1079\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 3364.6050 - val_loss: 3306.8967\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 3084.4702 - val_loss: 3026.3154\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 2832.3845 - val_loss: 2774.3918\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 2606.4224 - val_loss: 2541.5688\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 2394.6875 - val_loss: 2342.9797\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 2209.3752 - val_loss: 2158.1257\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 2046.0363 - val_loss: 1993.3655\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1890.0109 - val_loss: 1844.1913\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1750.8098 - val_loss: 1715.0073\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1631.6254 - val_loss: 1602.0281\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1522.5907 - val_loss: 1496.1294\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1422.9512 - val_loss: 1404.5128\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1339.4879 - val_loss: 1322.0474\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 7ms/step - loss: 1258.7755 - val_loss: 1252.0834\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1187.3031 - val_loss: 1187.3236\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 1125.3242 - val_loss: 1134.6296\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1067.3420 - val_loss: 1086.8430\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 1019.6945 - val_loss: 1038.0021\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 969.5200 - val_loss: 1001.6732\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 930.1613 - val_loss: 965.8149\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 894.1475 - val_loss: 928.7375\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 859.8812 - val_loss: 901.2726\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 830.3944 - val_loss: 881.1549\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 802.7517 - val_loss: 849.3114\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 5ms/step - loss: 775.8466 - val_loss: 831.6758\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 750.0847 - val_loss: 804.3722\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 731.0865 - val_loss: 785.6807\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 709.5997 - val_loss: 768.5930\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 689.7211 - val_loss: 750.4937\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 8ms/step - loss: 669.9454 - val_loss: 735.6456\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 8ms/step - loss: 653.7997 - val_loss: 719.0068\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 637.2922 - val_loss: 703.5421\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 13ms/step - loss: 623.9585 - val_loss: 694.9563\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 607.0712 - val_loss: 674.6990\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 7ms/step - loss: 594.9653 - val_loss: 664.9504\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 5ms/step - loss: 581.4760 - val_loss: 651.9719\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 567.3038 - val_loss: 638.1020\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 557.7646 - val_loss: 625.2888\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 545.2095 - val_loss: 614.3825\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 532.6128 - val_loss: 603.7030\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 7ms/step - loss: 522.0575 - val_loss: 591.5746\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 12ms/step - loss: 511.4003 - val_loss: 585.3332\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 111524.4922 - val_loss: 74694.5547\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 50448.9922 - val_loss: 29733.4785\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 17046.8652 - val_loss: 8412.9990\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 7ms/step - loss: 4492.0557 - val_loss: 2881.2383\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 2381.4326 - val_loss: 2360.6157\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 2113.9727 - val_loss: 2111.4727\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1884.4567 - val_loss: 1910.6238\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1692.7277 - val_loss: 1707.8717\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 1518.4580 - val_loss: 1529.2234\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1368.0956 - val_loss: 1374.1542\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1234.7103 - val_loss: 1243.7609\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 7ms/step - loss: 1113.1304 - val_loss: 1113.3120\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1005.4761 - val_loss: 1011.4406\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 911.6484 - val_loss: 916.0077\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 825.5130 - val_loss: 831.4730\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 754.6821 - val_loss: 756.8652\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 685.9790 - val_loss: 691.5237\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 624.7996 - val_loss: 633.0665\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 7ms/step - loss: 574.4974 - val_loss: 579.3644\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 525.7294 - val_loss: 534.1448\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 484.4293 - val_loss: 492.8124\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 447.7343 - val_loss: 456.9557\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 414.0805 - val_loss: 424.0963\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 383.9128 - val_loss: 395.4982\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 358.4390 - val_loss: 369.4610\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 333.9828 - val_loss: 345.8207\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 311.9802 - val_loss: 326.0906\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 292.8368 - val_loss: 306.9477\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 277.5877 - val_loss: 290.8179\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 260.9780 - val_loss: 276.3195\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 247.0872 - val_loss: 263.2931\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 235.1667 - val_loss: 251.6894\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 224.2823 - val_loss: 241.3595\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 215.0831 - val_loss: 232.0885\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 205.8243 - val_loss: 223.8575\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 197.7590 - val_loss: 216.2653\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 191.1489 - val_loss: 209.2933\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 184.5625 - val_loss: 203.3233\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 179.1947 - val_loss: 197.7366\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 173.6798 - val_loss: 192.9923\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 169.1318 - val_loss: 188.6585\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 165.1278 - val_loss: 184.7858\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 161.2922 - val_loss: 181.1884\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 158.0258 - val_loss: 178.0038\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 155.3443 - val_loss: 175.0746\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 152.0176 - val_loss: 172.5381\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.0476 - val_loss: 170.0829\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 147.3487 - val_loss: 167.7910\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 145.2675 - val_loss: 165.8363\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 143.2819 - val_loss: 163.9510\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 551.8514 - val_loss: 385.8553\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 386.0848 - val_loss: 274.1129\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 287.5164 - val_loss: 231.5706\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 242.2798 - val_loss: 211.3909\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 220.2413 - val_loss: 201.0500\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 206.9445 - val_loss: 195.5535\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 5ms/step - loss: 197.0535 - val_loss: 188.7598\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 187.1191 - val_loss: 180.7666\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 178.6305 - val_loss: 178.0001\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 5ms/step - loss: 174.8279 - val_loss: 170.8947\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 7ms/step - loss: 166.4861 - val_loss: 170.1598\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 7ms/step - loss: 162.4107 - val_loss: 162.1410\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 155.1969 - val_loss: 157.8090\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 150.8591 - val_loss: 157.6360\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 11ms/step - loss: 150.3973 - val_loss: 154.0651\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.4455 - val_loss: 146.8469\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 138.2266 - val_loss: 148.2168\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 133.8632 - val_loss: 142.0889\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 131.0060 - val_loss: 139.4229\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 127.7385 - val_loss: 136.7686\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 12ms/step - loss: 124.9262 - val_loss: 134.6928\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 123.2342 - val_loss: 132.2278\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 13ms/step - loss: 121.9167 - val_loss: 132.6114\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 9ms/step - loss: 121.7711 - val_loss: 129.7243\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 11ms/step - loss: 116.3953 - val_loss: 127.6911\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 115.1141 - val_loss: 128.5404\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 112.7491 - val_loss: 123.5742\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 114.1628 - val_loss: 122.8874\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 112.9441 - val_loss: 121.6686\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 113.4619 - val_loss: 122.5046\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 110.9210 - val_loss: 121.2869\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 108.2769 - val_loss: 124.7977\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 108.6034 - val_loss: 120.6060\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 107.6788 - val_loss: 126.2697\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 109.5990 - val_loss: 121.8499\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 107.0878 - val_loss: 121.5900\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 106.6574 - val_loss: 117.9161\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 107.4542 - val_loss: 117.1685\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 8ms/step - loss: 112.0261 - val_loss: 123.6070\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 108.1304 - val_loss: 116.3686\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 105.3118 - val_loss: 119.6179\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 106.3305 - val_loss: 137.0812\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 109.2160 - val_loss: 116.1620\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 104.9995 - val_loss: 114.9223\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 104.8097 - val_loss: 116.0031\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 107.6573 - val_loss: 116.8407\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 8ms/step - loss: 103.8197 - val_loss: 115.9833\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 103.8395 - val_loss: 114.5653\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 7ms/step - loss: 105.8739 - val_loss: 116.7631\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 5ms/step - loss: 103.7712 - val_loss: 113.1470\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 13349.8984 - val_loss: 2562.1233\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 2274.1086 - val_loss: 2525.7385\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1675.8291 - val_loss: 2043.5538\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 7ms/step - loss: 1498.2032 - val_loss: 1829.7096\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 5ms/step - loss: 1324.7026 - val_loss: 1592.4851\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1156.0391 - val_loss: 1423.7352\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1027.9884 - val_loss: 1262.1919\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 907.1599 - val_loss: 1111.3252\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 807.0654 - val_loss: 991.5750\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 725.1769 - val_loss: 893.6712\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 652.9210 - val_loss: 794.3027\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 589.5142 - val_loss: 724.6385\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 534.2248 - val_loss: 663.9592\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 489.0512 - val_loss: 609.3657\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 450.0725 - val_loss: 545.6897\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 417.6159 - val_loss: 513.3350\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 387.8062 - val_loss: 478.9418\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 360.0525 - val_loss: 444.5822\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 336.1232 - val_loss: 409.5704\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 319.9684 - val_loss: 385.2469\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 298.6826 - val_loss: 349.1440\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 281.7532 - val_loss: 333.6171\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 268.9079 - val_loss: 318.0091\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 250.7951 - val_loss: 302.1466\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 240.1833 - val_loss: 289.5383\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 226.0341 - val_loss: 263.5414\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 214.7445 - val_loss: 257.0953\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 205.0378 - val_loss: 248.8143\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 7ms/step - loss: 195.4088 - val_loss: 231.7666\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 189.7972 - val_loss: 222.9200\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 5ms/step - loss: 179.9018 - val_loss: 230.0230\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 174.1106 - val_loss: 204.8008\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.9428 - val_loss: 199.2611\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 160.1513 - val_loss: 193.3488\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 155.1495 - val_loss: 184.3546\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.2643 - val_loss: 178.1806\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.3593 - val_loss: 174.3483\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.3081 - val_loss: 166.5106\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 137.2839 - val_loss: 166.1120\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 134.4396 - val_loss: 156.5875\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 131.9979 - val_loss: 154.1796\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 130.0156 - val_loss: 153.7838\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 7ms/step - loss: 128.4351 - val_loss: 149.5663\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 123.8418 - val_loss: 145.7483\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 120.6464 - val_loss: 152.2943\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 123.3811 - val_loss: 151.3999\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 118.3054 - val_loss: 141.2120\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 7ms/step - loss: 117.0166 - val_loss: 137.3945\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 12ms/step - loss: 115.1277 - val_loss: 138.4126\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 113.8709 - val_loss: 139.0102\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 59ms/step - loss: 135127.6562 - val_loss: 79052.2578\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 18ms/step - loss: 50954.3203 - val_loss: 24535.3242\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 14732.5879 - val_loss: 5857.3950\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 3924.5562 - val_loss: 1862.6442\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 7ms/step - loss: 1958.1488 - val_loss: 1411.4269\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1701.7483 - val_loss: 1356.4701\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 5ms/step - loss: 1633.0118 - val_loss: 1295.4631\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1567.6279 - val_loss: 1231.6991\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1503.0098 - val_loss: 1171.3265\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1435.7329 - val_loss: 1115.6559\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1375.1312 - val_loss: 1065.5421\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1315.0386 - val_loss: 1006.6418\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1252.4642 - val_loss: 957.3912\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1195.9832 - val_loss: 912.0040\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1143.0636 - val_loss: 867.1299\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 1092.6625 - val_loss: 828.8687\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1045.7300 - val_loss: 793.0116\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 7ms/step - loss: 1001.0841 - val_loss: 757.5916\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 960.9000 - val_loss: 728.4818\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 919.9166 - val_loss: 698.1273\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 882.9813 - val_loss: 672.3329\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 849.4977 - val_loss: 648.9404\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 817.9156 - val_loss: 626.7920\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 788.9746 - val_loss: 606.9543\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 7ms/step - loss: 759.5324 - val_loss: 587.5063\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 732.6844 - val_loss: 569.7750\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 707.6475 - val_loss: 553.4191\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 7ms/step - loss: 684.6895 - val_loss: 537.3832\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 662.7009 - val_loss: 523.1177\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 641.1815 - val_loss: 508.7386\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 620.6848 - val_loss: 495.5448\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 600.6865 - val_loss: 482.2838\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 582.0962 - val_loss: 469.2766\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 564.0964 - val_loss: 456.2899\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 545.2664 - val_loss: 445.3102\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 7ms/step - loss: 529.2947 - val_loss: 434.6344\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 512.2910 - val_loss: 421.3712\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 496.7106 - val_loss: 410.8299\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 481.8479 - val_loss: 399.9757\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 466.3244 - val_loss: 388.2732\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 451.0066 - val_loss: 377.0765\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 436.8053 - val_loss: 367.4389\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 423.4144 - val_loss: 357.2160\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 409.2366 - val_loss: 346.7743\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 396.9066 - val_loss: 336.7175\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 383.3296 - val_loss: 327.0980\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 371.3054 - val_loss: 317.7230\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 359.7702 - val_loss: 309.2265\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 347.1169 - val_loss: 299.4111\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 336.1198 - val_loss: 292.8498\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 65ms/step - loss: 6347.4409 - val_loss: 6099.1592\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 4703.1548 - val_loss: 4924.1084\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 3730.6230 - val_loss: 3910.1833\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 2984.4314 - val_loss: 3114.0405\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 2376.3252 - val_loss: 2398.9792\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 7ms/step - loss: 1812.4360 - val_loss: 1770.0868\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1375.7675 - val_loss: 1283.2739\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 7ms/step - loss: 1022.0134 - val_loss: 960.0956\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 5ms/step - loss: 774.2914 - val_loss: 744.8871\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 608.9548 - val_loss: 572.5139\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 493.8347 - val_loss: 466.6606\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 407.3629 - val_loss: 396.1306\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 360.1425 - val_loss: 346.7088\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 315.5198 - val_loss: 319.0284\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 283.2419 - val_loss: 298.7631\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 272.6655 - val_loss: 274.1400\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 13ms/step - loss: 249.6330 - val_loss: 265.8557\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 239.5912 - val_loss: 247.9682\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 8ms/step - loss: 224.3020 - val_loss: 236.2606\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 11ms/step - loss: 217.4222 - val_loss: 233.0327\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 204.7865 - val_loss: 216.4796\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 192.3789 - val_loss: 208.2440\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 186.5948 - val_loss: 200.5323\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 13ms/step - loss: 176.4321 - val_loss: 193.2061\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 169.0948 - val_loss: 186.1997\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 14ms/step - loss: 165.3959 - val_loss: 190.2164\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 11ms/step - loss: 156.5775 - val_loss: 181.9391\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 153.9341 - val_loss: 168.9600\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 149.0569 - val_loss: 165.4430\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.1187 - val_loss: 164.9961\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.7926 - val_loss: 165.6949\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 134.3037 - val_loss: 148.8523\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 129.4793 - val_loss: 144.8954\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 125.1397 - val_loss: 152.4218\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 122.8479 - val_loss: 139.0740\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 7ms/step - loss: 118.1976 - val_loss: 139.4314\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 114.8111 - val_loss: 133.1664\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 112.5990 - val_loss: 132.0968\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 111.3327 - val_loss: 128.0458\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 108.2471 - val_loss: 130.5203\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 107.4380 - val_loss: 125.2932\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 105.1112 - val_loss: 122.3669\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 102.7438 - val_loss: 121.0642\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 102.2958 - val_loss: 119.5281\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 99.4299 - val_loss: 118.6899\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 97.6874 - val_loss: 125.9931\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 97.4674 - val_loss: 118.0764\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 5ms/step - loss: 97.4345 - val_loss: 115.8545\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 96.7727 - val_loss: 119.1743\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 94.9028 - val_loss: 114.2291\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 354228.5938 - val_loss: 250064.0781\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 201295.5312 - val_loss: 133449.2969\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 105838.0547 - val_loss: 64132.0859\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 49606.6406 - val_loss: 26207.8047\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 20604.4805 - val_loss: 10532.9834\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 9954.0225 - val_loss: 7185.6294\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 7ms/step - loss: 7731.4526 - val_loss: 7118.1221\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 7411.9868 - val_loss: 7085.9443\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 7280.8394 - val_loss: 6943.4849\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 7170.9287 - val_loss: 6812.1587\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 7ms/step - loss: 7030.9438 - val_loss: 6778.8540\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 6903.4058 - val_loss: 6619.3281\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 6779.7046 - val_loss: 6517.5884\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 6647.6714 - val_loss: 6399.0503\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 6512.1733 - val_loss: 6255.2705\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 6387.0269 - val_loss: 6180.4336\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 6258.7207 - val_loss: 6049.6479\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 6124.3784 - val_loss: 5935.5859\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 5997.4370 - val_loss: 5791.2847\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 5867.0410 - val_loss: 5711.5562\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 5747.3252 - val_loss: 5591.1577\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 5620.1694 - val_loss: 5525.3179\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 5489.6284 - val_loss: 5354.9443\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 5363.8486 - val_loss: 5242.9370\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 5243.0898 - val_loss: 5144.2573\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 5126.7207 - val_loss: 5035.6665\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 5020.1729 - val_loss: 4955.2217\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 4893.1323 - val_loss: 4798.7109\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 4770.7134 - val_loss: 4707.5083\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 4658.1221 - val_loss: 4590.5615\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 4541.8140 - val_loss: 4525.7012\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 4429.9194 - val_loss: 4374.8281\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 4316.6489 - val_loss: 4306.9941\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 4210.3760 - val_loss: 4219.6099\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 4105.5503 - val_loss: 4083.6775\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 3990.7195 - val_loss: 3994.1833\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 3887.2195 - val_loss: 3909.7593\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 3785.0430 - val_loss: 3783.5190\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 3684.0547 - val_loss: 3697.5122\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 3583.4851 - val_loss: 3596.8701\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 3485.0117 - val_loss: 3495.0312\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 3390.1848 - val_loss: 3405.0247\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 5ms/step - loss: 3293.4673 - val_loss: 3302.9961\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 3194.1187 - val_loss: 3254.1951\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 3108.5537 - val_loss: 3108.0710\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 3008.1650 - val_loss: 3065.0850\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 13ms/step - loss: 2922.5576 - val_loss: 2981.4746\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 13ms/step - loss: 2830.9377 - val_loss: 2871.0530\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 2748.8687 - val_loss: 2775.9395\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 2662.2473 - val_loss: 2716.8564\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 62ms/step - loss: 403244.0625 - val_loss: 293712.0000\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 230199.8125 - val_loss: 163018.5156\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 126801.8125 - val_loss: 87826.2656\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 7ms/step - loss: 67984.4609 - val_loss: 45922.9648\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 35731.2305 - val_loss: 23854.2773\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 18993.5449 - val_loss: 12674.1338\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 10626.6553 - val_loss: 7513.9580\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 6794.8052 - val_loss: 5166.3848\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 5041.9424 - val_loss: 4186.7739\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 4265.0747 - val_loss: 3734.3215\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 5ms/step - loss: 3877.1667 - val_loss: 3499.2610\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 3636.9148 - val_loss: 3326.3191\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 3446.0171 - val_loss: 3172.1848\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 3275.9324 - val_loss: 3014.3000\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 3100.2798 - val_loss: 2858.3022\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 2926.9390 - val_loss: 2698.7505\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 2756.7522 - val_loss: 2537.8313\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 2589.7161 - val_loss: 2375.2583\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 2426.7336 - val_loss: 2217.0171\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 2269.8289 - val_loss: 2065.5703\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 2113.5159 - val_loss: 1925.5151\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1966.3210 - val_loss: 1791.2734\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 1829.2372 - val_loss: 1666.6770\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1703.2260 - val_loss: 1552.8641\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1588.2714 - val_loss: 1446.6191\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 1483.0684 - val_loss: 1353.2295\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 1387.6289 - val_loss: 1263.1437\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 1298.1708 - val_loss: 1187.7943\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 1219.1090 - val_loss: 1109.9641\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 1145.3304 - val_loss: 1043.2355\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 1075.9327 - val_loss: 977.8314\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 1014.6813 - val_loss: 920.4066\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 958.6368 - val_loss: 871.3497\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 907.6309 - val_loss: 827.6569\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 861.8585 - val_loss: 785.9457\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 819.7958 - val_loss: 747.3062\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 778.8068 - val_loss: 712.8556\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 5ms/step - loss: 741.4319 - val_loss: 678.1947\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 704.9769 - val_loss: 648.5474\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 672.5370 - val_loss: 620.4092\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 641.7378 - val_loss: 591.8666\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 611.6666 - val_loss: 565.7280\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 584.5403 - val_loss: 540.9748\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 558.2465 - val_loss: 517.0543\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 535.3640 - val_loss: 494.5568\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 513.2903 - val_loss: 473.7838\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 492.3271 - val_loss: 453.5647\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 472.9437 - val_loss: 435.4724\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 454.7919 - val_loss: 417.4349\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 436.8025 - val_loss: 402.8112\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 42ms/step - loss: 14723.5088 - val_loss: 4649.8394\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 3561.9414 - val_loss: 4111.5566\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 3060.6165 - val_loss: 3307.0361\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 2613.7795 - val_loss: 2669.8416\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 2035.9716 - val_loss: 1991.3217\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1520.1490 - val_loss: 1486.9343\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1129.7341 - val_loss: 1080.3280\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 821.7089 - val_loss: 757.5482\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 594.7735 - val_loss: 543.5087\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 425.8701 - val_loss: 410.6347\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 312.0380 - val_loss: 289.0417\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 232.2805 - val_loss: 222.8241\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 181.6707 - val_loss: 184.9106\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 150.1223 - val_loss: 160.6356\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 131.7232 - val_loss: 146.7009\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 121.0429 - val_loss: 139.2488\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 114.9241 - val_loss: 139.0276\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 7ms/step - loss: 111.7001 - val_loss: 137.8399\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 109.6854 - val_loss: 139.0408\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 8ms/step - loss: 107.9916 - val_loss: 135.0943\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 108.5274 - val_loss: 132.9702\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 13ms/step - loss: 106.2545 - val_loss: 132.2501\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 8ms/step - loss: 104.5375 - val_loss: 129.4280\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 11ms/step - loss: 102.8534 - val_loss: 129.9738\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 102.6346 - val_loss: 128.8129\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 100.8617 - val_loss: 131.1213\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 101.0218 - val_loss: 137.2529\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 102.5452 - val_loss: 130.2357\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 100.5184 - val_loss: 126.5531\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 97.7647 - val_loss: 124.5221\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 96.9754 - val_loss: 123.6099\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 7ms/step - loss: 96.5004 - val_loss: 122.4200\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 9ms/step - loss: 95.0780 - val_loss: 121.2789\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 10ms/step - loss: 95.8630 - val_loss: 123.3249\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 94.8968 - val_loss: 119.9097\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 93.5659 - val_loss: 119.3095\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 92.3272 - val_loss: 117.8335\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 93.5626 - val_loss: 118.3358\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 92.3066 - val_loss: 121.2144\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 91.1271 - val_loss: 120.7827\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 90.4881 - val_loss: 123.5169\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 91.6542 - val_loss: 117.1468\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 90.6678 - val_loss: 115.7223\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 90.1155 - val_loss: 115.1832\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 89.0160 - val_loss: 115.6708\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 91.2697 - val_loss: 118.9459\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 89.2376 - val_loss: 114.6203\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 87.8798 - val_loss: 112.7488\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 90.1905 - val_loss: 114.0060\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 88.6398 - val_loss: 113.3817\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 887.1552 - val_loss: 674.6567\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 709.1732 - val_loss: 563.4749\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 606.8143 - val_loss: 495.4391\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 540.5468 - val_loss: 436.9041\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 488.6978 - val_loss: 393.5732\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 444.5192 - val_loss: 364.6429\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 414.0491 - val_loss: 337.6813\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 380.1988 - val_loss: 307.7165\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 353.0039 - val_loss: 285.9200\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 331.3528 - val_loss: 270.0990\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 310.6866 - val_loss: 254.3299\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 294.6556 - val_loss: 243.2132\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 281.0385 - val_loss: 230.7269\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 267.9729 - val_loss: 225.3618\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 257.5868 - val_loss: 211.7644\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 246.1681 - val_loss: 205.5972\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 5ms/step - loss: 236.2699 - val_loss: 200.2722\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 228.1874 - val_loss: 193.5740\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 220.9066 - val_loss: 187.6210\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 211.7567 - val_loss: 186.3437\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 206.2746 - val_loss: 180.6084\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 199.9953 - val_loss: 177.6274\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 193.6552 - val_loss: 172.0364\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 187.6857 - val_loss: 170.2032\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 183.8196 - val_loss: 164.5118\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 178.5351 - val_loss: 162.5829\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 172.9072 - val_loss: 161.3774\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 169.4240 - val_loss: 167.3580\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 169.0295 - val_loss: 153.7916\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 161.0114 - val_loss: 152.4340\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 158.6221 - val_loss: 150.8849\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 155.0308 - val_loss: 148.9628\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 150.1150 - val_loss: 144.9861\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 147.6538 - val_loss: 142.9140\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.4232 - val_loss: 143.8737\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 8ms/step - loss: 140.7907 - val_loss: 139.2016\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 137.4987 - val_loss: 139.4725\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 134.9970 - val_loss: 134.6914\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 132.0480 - val_loss: 136.7920\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 131.3058 - val_loss: 133.4190\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 129.6227 - val_loss: 134.3694\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 125.7971 - val_loss: 130.3221\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 125.4683 - val_loss: 130.9599\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 122.8918 - val_loss: 130.9070\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 129.9986 - val_loss: 132.6985\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 119.9020 - val_loss: 127.8810\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 118.9767 - val_loss: 126.6378\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 117.4703 - val_loss: 126.2214\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 117.0530 - val_loss: 127.6275\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 115.2778 - val_loss: 129.2197\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 56ms/step - loss: 1574.0554 - val_loss: 1177.1915\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 18ms/step - loss: 1018.0775 - val_loss: 795.5963\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 766.9346 - val_loss: 676.2096\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 14ms/step - loss: 685.3454 - val_loss: 601.0369\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 626.3345 - val_loss: 538.6901\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 13ms/step - loss: 574.4247 - val_loss: 486.3688\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 521.3942 - val_loss: 435.9315\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 5ms/step - loss: 473.9291 - val_loss: 394.4852\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 433.9807 - val_loss: 360.0522\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 401.3676 - val_loss: 332.0630\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 7ms/step - loss: 373.0435 - val_loss: 309.9156\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 350.6250 - val_loss: 288.8711\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 328.0080 - val_loss: 271.4603\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 309.9295 - val_loss: 257.3837\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 294.8381 - val_loss: 244.6157\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 280.7124 - val_loss: 234.5999\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 269.5903 - val_loss: 224.4727\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 258.9285 - val_loss: 216.8461\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 249.0662 - val_loss: 211.1295\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 242.2018 - val_loss: 205.0229\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 234.3656 - val_loss: 199.4221\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 228.3196 - val_loss: 196.1862\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 221.2519 - val_loss: 191.6836\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 215.2867 - val_loss: 187.9977\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 212.7698 - val_loss: 184.9664\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 7ms/step - loss: 204.2825 - val_loss: 181.5960\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 201.1454 - val_loss: 177.9585\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 196.2565 - val_loss: 175.3053\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 192.6798 - val_loss: 172.6007\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 187.4979 - val_loss: 170.4897\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 184.5719 - val_loss: 168.0264\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 179.8666 - val_loss: 165.9239\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 177.3861 - val_loss: 165.8439\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 172.1515 - val_loss: 161.5565\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 168.4841 - val_loss: 159.4020\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 164.7487 - val_loss: 157.8251\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 162.5149 - val_loss: 158.7172\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 160.1481 - val_loss: 153.8971\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 157.0476 - val_loss: 158.7677\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 155.9036 - val_loss: 151.1255\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 150.1752 - val_loss: 149.6880\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.9981 - val_loss: 150.1253\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.1743 - val_loss: 147.0327\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.8971 - val_loss: 145.8880\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 141.9002 - val_loss: 146.8383\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 137.2434 - val_loss: 143.9782\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 135.8976 - val_loss: 143.1680\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 135.2035 - val_loss: 142.4722\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 131.5675 - val_loss: 142.2888\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 130.1527 - val_loss: 141.2002\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 857615.8750 - val_loss: 741446.3125\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 660301.8125 - val_loss: 570328.3125\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 502967.5625 - val_loss: 430520.6875\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 366277.0000 - val_loss: 306190.1250\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 251770.1250 - val_loss: 206441.6562\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 164613.1094 - val_loss: 132807.2656\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 102324.7734 - val_loss: 81209.4297\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 60077.7969 - val_loss: 47166.7461\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 33534.1211 - val_loss: 26393.9648\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 18253.4902 - val_loss: 15115.6504\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 10632.4873 - val_loss: 9557.0781\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 7205.7212 - val_loss: 7151.6611\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 5910.0029 - val_loss: 6105.5366\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 5ms/step - loss: 5418.8701 - val_loss: 5703.0459\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 5ms/step - loss: 5240.8999 - val_loss: 5477.3618\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 5134.1865 - val_loss: 5359.3081\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 5059.6221 - val_loss: 5235.9658\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 4975.6479 - val_loss: 5152.0723\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 4902.2236 - val_loss: 5058.4585\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 4825.0708 - val_loss: 4961.6392\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 4751.6284 - val_loss: 4867.7930\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 4677.2852 - val_loss: 4799.2339\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 4600.4058 - val_loss: 4704.0352\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 4527.8823 - val_loss: 4611.5103\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 4451.9746 - val_loss: 4529.0127\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 4384.1587 - val_loss: 4458.7070\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 4306.1538 - val_loss: 4365.7661\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 4237.2690 - val_loss: 4275.6167\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 7ms/step - loss: 4163.9312 - val_loss: 4202.2065\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 4094.8044 - val_loss: 4119.2915\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 4026.8813 - val_loss: 4052.1221\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 3956.1030 - val_loss: 3955.1233\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 3888.2961 - val_loss: 3883.6570\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 3822.0667 - val_loss: 3816.1582\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 7ms/step - loss: 3757.2434 - val_loss: 3741.6174\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 12ms/step - loss: 3694.5273 - val_loss: 3678.1489\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 3632.1504 - val_loss: 3595.4458\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 13ms/step - loss: 3572.9407 - val_loss: 3532.8696\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 13ms/step - loss: 3511.0940 - val_loss: 3467.6250\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 3450.3020 - val_loss: 3407.8662\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 3395.0398 - val_loss: 3346.6118\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 3336.6108 - val_loss: 3278.3362\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 3282.2944 - val_loss: 3217.5630\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 3228.2263 - val_loss: 3157.9304\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 3177.2534 - val_loss: 3091.7290\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 3123.1997 - val_loss: 3047.8374\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 3070.9956 - val_loss: 2992.2529\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 7ms/step - loss: 3022.9497 - val_loss: 2929.8577\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 2974.3706 - val_loss: 2887.0818\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 2926.1577 - val_loss: 2821.3777\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 7088.9473 - val_loss: 4475.1328\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 4720.9785 - val_loss: 3895.4846\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 4191.2793 - val_loss: 3455.0972\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 3650.2815 - val_loss: 2909.5554\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 7ms/step - loss: 2977.1978 - val_loss: 2317.9624\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 2482.1616 - val_loss: 2002.4713\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 2137.8906 - val_loss: 1726.3701\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1833.2302 - val_loss: 1500.2631\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 1578.1862 - val_loss: 1280.5648\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1357.3010 - val_loss: 1121.6531\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 7ms/step - loss: 1124.1820 - val_loss: 910.3730\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 931.8420 - val_loss: 745.3420\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 741.5910 - val_loss: 582.6502\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 5ms/step - loss: 599.7570 - val_loss: 467.3729\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 480.6600 - val_loss: 377.1895\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 392.7919 - val_loss: 313.3718\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 330.4683 - val_loss: 264.8670\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 7ms/step - loss: 277.9862 - val_loss: 232.6951\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 237.1683 - val_loss: 203.1478\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 206.3777 - val_loss: 183.2984\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 183.8222 - val_loss: 168.7768\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 171.7475 - val_loss: 160.4739\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 158.2987 - val_loss: 151.8012\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.9370 - val_loss: 152.9490\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.9584 - val_loss: 143.7960\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 134.6791 - val_loss: 141.5142\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 131.6087 - val_loss: 140.4397\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 129.5312 - val_loss: 139.9424\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 128.7845 - val_loss: 143.9599\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 125.2356 - val_loss: 141.3956\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 124.0311 - val_loss: 142.3977\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 121.9279 - val_loss: 154.3530\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 123.9024 - val_loss: 144.4261\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 119.9838 - val_loss: 138.1437\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 7ms/step - loss: 120.7239 - val_loss: 137.9711\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 120.3902 - val_loss: 137.2951\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 119.1188 - val_loss: 142.1245\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 118.8408 - val_loss: 137.5560\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 119.3797 - val_loss: 137.9043\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 119.2138 - val_loss: 136.7592\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 117.6981 - val_loss: 136.3155\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 118.4041 - val_loss: 135.8636\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 116.8462 - val_loss: 147.2480\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 117.2560 - val_loss: 139.2139\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 117.4859 - val_loss: 137.7434\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 114.4441 - val_loss: 170.1940\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 126.2061 - val_loss: 138.6046\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 7ms/step - loss: 122.1002 - val_loss: 135.0201\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 116.2036 - val_loss: 141.0094\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 5ms/step - loss: 115.1866 - val_loss: 135.9798\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 43ms/step - loss: 674059.8125 - val_loss: 575729.9375\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 518526.2188 - val_loss: 443402.9688\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 401831.1562 - val_loss: 344484.0312\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 313840.3750 - val_loss: 269423.4688\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 246533.5469 - val_loss: 211631.6562\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 194394.7812 - val_loss: 166870.1250\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 5ms/step - loss: 153822.5312 - val_loss: 131804.4062\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 121983.6562 - val_loss: 104544.0391\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 97426.3281 - val_loss: 83612.2109\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 7ms/step - loss: 78817.0078 - val_loss: 68282.2578\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 65037.7695 - val_loss: 56462.2188\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 8ms/step - loss: 54304.7500 - val_loss: 47366.3594\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 11ms/step - loss: 46062.7695 - val_loss: 40480.0234\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 13ms/step - loss: 39589.1055 - val_loss: 34988.1211\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 7ms/step - loss: 34326.4844 - val_loss: 30362.5918\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 29891.4531 - val_loss: 26487.0918\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 12ms/step - loss: 26145.8281 - val_loss: 23148.7363\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 22922.5781 - val_loss: 20276.2852\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 20151.3574 - val_loss: 17814.3301\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 17769.4941 - val_loss: 15678.0791\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 15707.3525 - val_loss: 13846.1621\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 5ms/step - loss: 13921.9600 - val_loss: 12249.1006\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 12367.0762 - val_loss: 10852.9111\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 11000.8486 - val_loss: 9640.5225\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 9801.2529 - val_loss: 8575.3545\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 8752.8770 - val_loss: 7625.0581\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 7821.1450 - val_loss: 6801.1401\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 7005.3447 - val_loss: 6072.6450\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 7ms/step - loss: 6285.1094 - val_loss: 5425.5547\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 5643.5903 - val_loss: 4855.1450\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 5072.3589 - val_loss: 4353.6748\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 4567.1650 - val_loss: 3907.1072\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 4118.2866 - val_loss: 3509.1582\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 3718.5562 - val_loss: 3156.2283\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 3361.8591 - val_loss: 2847.1799\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 3046.7153 - val_loss: 2566.7180\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 2763.4995 - val_loss: 2321.5662\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 2513.3979 - val_loss: 2105.5994\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 2289.8042 - val_loss: 1914.0044\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 2091.4917 - val_loss: 1741.7897\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 1913.6445 - val_loss: 1591.2993\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 1756.7529 - val_loss: 1457.9762\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 1616.9780 - val_loss: 1340.3228\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 1492.6694 - val_loss: 1237.6080\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 1383.8297 - val_loss: 1145.4563\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 1284.8058 - val_loss: 1066.3600\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 1198.5330 - val_loss: 994.5921\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 1121.1139 - val_loss: 932.3068\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 1053.1930 - val_loss: 878.3590\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 992.6560 - val_loss: 831.8972\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1672.5892 - val_loss: 1542.0195\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1292.6736 - val_loss: 1175.6648\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1028.7568 - val_loss: 906.6505\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 816.0524 - val_loss: 734.3498\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 655.7903 - val_loss: 595.0229\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 527.4720 - val_loss: 482.9355\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 434.9032 - val_loss: 396.0397\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 355.6902 - val_loss: 335.1930\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 306.7089 - val_loss: 301.7769\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 258.1114 - val_loss: 245.2999\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 227.4889 - val_loss: 220.2652\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 195.8131 - val_loss: 192.5234\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 172.6471 - val_loss: 195.1099\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 163.5567 - val_loss: 162.0395\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.6235 - val_loss: 153.1246\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.2089 - val_loss: 144.4832\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 128.8993 - val_loss: 138.8694\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 125.4043 - val_loss: 136.9233\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 119.0745 - val_loss: 132.6391\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 117.1122 - val_loss: 130.7567\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 113.0462 - val_loss: 130.9353\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 5ms/step - loss: 114.3287 - val_loss: 133.6121\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 113.7479 - val_loss: 127.1942\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 113.1641 - val_loss: 126.0942\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 109.0668 - val_loss: 128.8427\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 112.3187 - val_loss: 131.1652\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 106.6049 - val_loss: 126.3491\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 107.2229 - val_loss: 125.3933\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 107.3766 - val_loss: 123.6453\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 107.2996 - val_loss: 124.5111\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 7ms/step - loss: 108.2573 - val_loss: 123.7416\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 105.1785 - val_loss: 124.0631\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 106.7487 - val_loss: 125.4020\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 107.0445 - val_loss: 122.4379\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 108.7902 - val_loss: 124.2072\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 105.5974 - val_loss: 123.0319\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 105.7636 - val_loss: 122.7726\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 12ms/step - loss: 112.5715 - val_loss: 123.2912\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 108.2081 - val_loss: 123.2476\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 109.0545 - val_loss: 123.0093\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 105.5393 - val_loss: 121.8209\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 107.5499 - val_loss: 122.6194\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 12ms/step - loss: 104.8763 - val_loss: 122.2901\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 105.6798 - val_loss: 123.2616\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 8ms/step - loss: 104.4363 - val_loss: 127.2320\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 11ms/step - loss: 107.6419 - val_loss: 122.5912\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 105.0155 - val_loss: 124.6388\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 13ms/step - loss: 104.5639 - val_loss: 124.0553\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 8ms/step - loss: 106.0848 - val_loss: 128.2740\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 9ms/step - loss: 107.7290 - val_loss: 122.5223\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 5263.6128 - val_loss: 1235.7013\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 601.6432 - val_loss: 391.6705\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 5ms/step - loss: 385.5473 - val_loss: 380.0962\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 5ms/step - loss: 350.5306 - val_loss: 343.2066\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 342.4928 - val_loss: 332.7359\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 330.5352 - val_loss: 322.4444\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 319.7568 - val_loss: 313.5097\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 5ms/step - loss: 310.2296 - val_loss: 298.4544\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 298.3944 - val_loss: 289.8302\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 288.8561 - val_loss: 277.5771\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 5ms/step - loss: 278.6009 - val_loss: 269.7764\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 270.7195 - val_loss: 258.4234\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 262.3062 - val_loss: 250.8011\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 253.3491 - val_loss: 241.7984\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 245.9650 - val_loss: 234.0273\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 238.5409 - val_loss: 226.3814\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 232.9782 - val_loss: 221.6275\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 225.1161 - val_loss: 214.9202\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 219.1959 - val_loss: 210.5785\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 214.0524 - val_loss: 202.5824\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 209.3752 - val_loss: 199.6975\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 203.5775 - val_loss: 194.4207\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 199.1365 - val_loss: 191.0043\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 195.1024 - val_loss: 186.6245\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 190.4426 - val_loss: 183.2109\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 186.9336 - val_loss: 181.5605\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 183.0461 - val_loss: 177.2014\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 179.7083 - val_loss: 175.5620\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 176.8614 - val_loss: 172.4957\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 173.2773 - val_loss: 169.3218\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 172.3468 - val_loss: 171.0970\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 167.6735 - val_loss: 163.3673\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 165.3090 - val_loss: 164.4888\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 163.5275 - val_loss: 159.5248\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 161.5792 - val_loss: 157.6217\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 158.9066 - val_loss: 157.1483\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 156.3549 - val_loss: 155.1701\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 153.2950 - val_loss: 155.4704\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 151.9415 - val_loss: 155.1839\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.0286 - val_loss: 150.4818\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 149.7241 - val_loss: 150.1745\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 145.6615 - val_loss: 147.8832\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 7ms/step - loss: 144.4862 - val_loss: 146.6797\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 142.4341 - val_loss: 147.1610\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.7953 - val_loss: 145.3468\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 138.9207 - val_loss: 142.8662\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 136.9724 - val_loss: 146.8486\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 136.7387 - val_loss: 141.1940\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 134.2961 - val_loss: 140.6667\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 134.1596 - val_loss: 139.1579\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 395494.9375 - val_loss: 259841.0938\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 190360.3594 - val_loss: 115954.8359\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 83464.2812 - val_loss: 47834.5117\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 34994.4453 - val_loss: 20136.2969\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 15942.2578 - val_loss: 10320.2529\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 9229.6094 - val_loss: 7549.3550\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 7411.3447 - val_loss: 6834.1416\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 6869.0303 - val_loss: 6649.5718\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 6625.5044 - val_loss: 6505.9185\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 6460.9370 - val_loss: 6339.9233\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 6294.0938 - val_loss: 6181.5718\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 6135.2124 - val_loss: 6008.7295\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 5970.1353 - val_loss: 5841.3970\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 5814.7310 - val_loss: 5684.5190\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 5658.9780 - val_loss: 5507.8032\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 13ms/step - loss: 5495.1392 - val_loss: 5380.2192\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 12ms/step - loss: 5346.8584 - val_loss: 5214.8623\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 5199.2207 - val_loss: 5065.3296\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 7ms/step - loss: 5056.7397 - val_loss: 4923.5410\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 4919.9468 - val_loss: 4777.6387\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 4777.6050 - val_loss: 4627.9692\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 7ms/step - loss: 4647.0908 - val_loss: 4512.0059\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 13ms/step - loss: 4512.6367 - val_loss: 4368.1724\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 4383.6694 - val_loss: 4245.2759\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 4261.1694 - val_loss: 4114.8628\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 7ms/step - loss: 4132.9346 - val_loss: 4013.1121\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 12ms/step - loss: 4016.7000 - val_loss: 3904.9526\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 3901.2305 - val_loss: 3762.4771\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 7ms/step - loss: 3788.4653 - val_loss: 3662.2253\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 3678.8018 - val_loss: 3550.5383\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 3578.8259 - val_loss: 3448.4041\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 3474.6294 - val_loss: 3360.3174\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 3378.6672 - val_loss: 3265.4944\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 3285.2466 - val_loss: 3153.2070\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 3191.2412 - val_loss: 3080.6755\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 3105.5068 - val_loss: 2989.6599\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 3021.6558 - val_loss: 2939.0903\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 2937.0132 - val_loss: 2809.9373\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 2853.9585 - val_loss: 2741.0835\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 2776.1689 - val_loss: 2678.0525\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 2703.1526 - val_loss: 2610.1934\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 2632.0540 - val_loss: 2529.0745\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 2560.2498 - val_loss: 2462.7336\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 2498.5894 - val_loss: 2390.6428\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 2427.8472 - val_loss: 2342.6663\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 2366.5667 - val_loss: 2270.3826\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 2305.9893 - val_loss: 2206.2566\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 2247.3311 - val_loss: 2169.9692\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 2189.4841 - val_loss: 2096.5667\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 2132.1895 - val_loss: 2071.4268\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 42ms/step - loss: 100516.7344 - val_loss: 53359.0859\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 32029.8477 - val_loss: 13660.7764\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 7416.2197 - val_loss: 4078.9724\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 3213.5479 - val_loss: 3664.7666\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 2852.4490 - val_loss: 3210.9724\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 5ms/step - loss: 2519.9719 - val_loss: 2863.8303\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 2258.9565 - val_loss: 2562.9092\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 2014.8062 - val_loss: 2315.4734\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1808.5791 - val_loss: 2077.2068\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1616.6810 - val_loss: 1863.4990\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1451.1790 - val_loss: 1675.3818\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1301.9436 - val_loss: 1509.4679\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 7ms/step - loss: 1169.8605 - val_loss: 1365.0493\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 5ms/step - loss: 1054.4048 - val_loss: 1228.0505\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 7ms/step - loss: 947.5623 - val_loss: 1113.0551\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 857.6403 - val_loss: 1013.9615\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 778.1481 - val_loss: 925.7157\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 710.1106 - val_loss: 850.1451\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 649.3322 - val_loss: 784.0343\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 597.2562 - val_loss: 726.1146\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 552.3590 - val_loss: 674.1605\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 512.8444 - val_loss: 627.4426\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 476.0562 - val_loss: 588.9880\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 444.4309 - val_loss: 552.6417\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 417.7795 - val_loss: 521.4609\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 393.7306 - val_loss: 493.1475\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 372.7216 - val_loss: 469.9231\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 355.9059 - val_loss: 448.4749\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 338.3286 - val_loss: 427.6925\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 324.8893 - val_loss: 410.5309\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 311.7314 - val_loss: 394.3746\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 301.4478 - val_loss: 380.5686\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 292.8594 - val_loss: 367.4729\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 283.6286 - val_loss: 355.5003\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 275.4466 - val_loss: 345.2790\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 268.8460 - val_loss: 336.2216\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 262.8387 - val_loss: 328.0452\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 258.3026 - val_loss: 320.6252\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 252.8000 - val_loss: 313.2762\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 248.8955 - val_loss: 306.5128\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 245.8121 - val_loss: 301.2060\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 242.1457 - val_loss: 295.8825\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 238.6143 - val_loss: 291.0214\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 235.6861 - val_loss: 287.4934\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 234.5871 - val_loss: 283.9706\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 8ms/step - loss: 231.2449 - val_loss: 279.1499\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 229.7112 - val_loss: 277.4467\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 229.9967 - val_loss: 274.2598\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 226.0420 - val_loss: 269.3125\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 5ms/step - loss: 224.4142 - val_loss: 266.9054\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 56ms/step - loss: 62387.8672 - val_loss: 27955.8926\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 19ms/step - loss: 17402.0078 - val_loss: 6429.3198\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 5ms/step - loss: 4880.3101 - val_loss: 2934.2524\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 3124.6714 - val_loss: 2793.6106\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 2917.1294 - val_loss: 2656.9795\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 2734.2554 - val_loss: 2381.9875\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 2370.6074 - val_loss: 1813.1248\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1567.0083 - val_loss: 1080.9355\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 1108.0776 - val_loss: 846.8297\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 838.4620 - val_loss: 683.3134\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 686.5704 - val_loss: 581.7148\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 574.3846 - val_loss: 510.9262\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 508.2475 - val_loss: 473.1263\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 460.8672 - val_loss: 450.4789\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 429.6568 - val_loss: 445.9052\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 403.0642 - val_loss: 412.2373\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 381.3960 - val_loss: 402.4280\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 367.2274 - val_loss: 390.6725\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 355.3250 - val_loss: 383.1969\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 348.8077 - val_loss: 375.4927\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 334.3544 - val_loss: 372.8653\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 326.2157 - val_loss: 364.0028\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 317.8059 - val_loss: 359.7227\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 309.1994 - val_loss: 354.3166\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 304.1273 - val_loss: 353.2842\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 296.0449 - val_loss: 350.0337\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 293.5378 - val_loss: 341.6182\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 287.2066 - val_loss: 342.6247\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 282.5829 - val_loss: 335.5870\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 277.0737 - val_loss: 330.9523\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 271.3648 - val_loss: 331.4730\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 267.8605 - val_loss: 324.2907\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 263.1303 - val_loss: 319.8559\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 258.7441 - val_loss: 318.2832\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 255.9708 - val_loss: 314.0405\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 253.4808 - val_loss: 325.3223\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 252.9647 - val_loss: 308.2307\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 245.2739 - val_loss: 309.5424\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 241.3803 - val_loss: 300.1020\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 239.1242 - val_loss: 296.1620\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 235.3684 - val_loss: 296.0068\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 232.9150 - val_loss: 292.1338\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 7ms/step - loss: 229.7402 - val_loss: 287.7355\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 5ms/step - loss: 228.4090 - val_loss: 292.3309\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 225.6486 - val_loss: 284.2207\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 222.4507 - val_loss: 281.7646\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 219.4387 - val_loss: 279.2043\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 217.0351 - val_loss: 273.6010\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 213.7395 - val_loss: 274.7781\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 210.5340 - val_loss: 269.2759\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 42ms/step - loss: 5226.6860 - val_loss: 4738.6895\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 3495.8633 - val_loss: 3576.7175\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 2655.8682 - val_loss: 2809.9275\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 2164.8491 - val_loss: 2329.5164\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1778.9670 - val_loss: 1951.2227\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1470.3977 - val_loss: 1621.6415\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1235.8510 - val_loss: 1365.8500\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1045.9388 - val_loss: 1165.8354\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 906.2875 - val_loss: 1010.2018\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 790.2549 - val_loss: 882.1162\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 692.9659 - val_loss: 772.6089\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 614.0503 - val_loss: 708.5576\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 559.0807 - val_loss: 591.7887\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 5ms/step - loss: 488.5231 - val_loss: 524.3732\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 432.8451 - val_loss: 468.3926\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 5ms/step - loss: 383.7572 - val_loss: 417.8050\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 5ms/step - loss: 340.1908 - val_loss: 378.7094\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 312.8680 - val_loss: 345.9668\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 287.5868 - val_loss: 313.6749\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 265.8156 - val_loss: 303.6364\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 246.5244 - val_loss: 272.5875\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 225.0956 - val_loss: 253.6942\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 218.6302 - val_loss: 248.9855\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 8ms/step - loss: 200.9496 - val_loss: 226.3076\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 12ms/step - loss: 189.5241 - val_loss: 215.7137\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 180.0727 - val_loss: 207.7141\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 172.6281 - val_loss: 198.9312\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.7685 - val_loss: 192.5745\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 7ms/step - loss: 161.4891 - val_loss: 187.6688\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 15ms/step - loss: 157.5953 - val_loss: 185.7048\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 152.1882 - val_loss: 182.0709\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.3923 - val_loss: 175.5294\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.5157 - val_loss: 170.6750\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.0678 - val_loss: 168.6075\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 14ms/step - loss: 138.6477 - val_loss: 164.9120\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 12ms/step - loss: 136.5089 - val_loss: 162.6421\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 134.6668 - val_loss: 161.0484\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 132.0669 - val_loss: 172.4021\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 135.4840 - val_loss: 158.6359\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 130.2321 - val_loss: 155.7344\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 129.1778 - val_loss: 153.1580\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 5ms/step - loss: 126.0286 - val_loss: 151.8522\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 124.8940 - val_loss: 153.3071\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 122.2197 - val_loss: 152.0375\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 121.2755 - val_loss: 150.9971\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 120.5986 - val_loss: 147.6036\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 120.9949 - val_loss: 147.5755\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 7ms/step - loss: 122.3444 - val_loss: 148.4913\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 123.1349 - val_loss: 145.3798\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 116.3874 - val_loss: 155.1943\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 70ms/step - loss: 653202.8750 - val_loss: 463715.7812\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 352450.2812 - val_loss: 228667.1250\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 167660.6250 - val_loss: 102180.5938\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 74497.6016 - val_loss: 46196.6875\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 36067.7695 - val_loss: 27359.6699\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 23624.3164 - val_loss: 22801.6660\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 20342.2129 - val_loss: 21771.8770\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 19430.6094 - val_loss: 21209.8984\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 18788.0938 - val_loss: 20513.9082\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 18138.0117 - val_loss: 19714.9980\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 17493.4043 - val_loss: 18971.5410\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 16834.5254 - val_loss: 18226.8730\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 16185.4053 - val_loss: 17427.6758\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 15523.7568 - val_loss: 16612.9609\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 7ms/step - loss: 14871.7090 - val_loss: 15820.0020\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 14221.0420 - val_loss: 15148.5342\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 5ms/step - loss: 13583.1445 - val_loss: 14409.1582\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 12967.0850 - val_loss: 13682.2656\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 12346.3760 - val_loss: 12995.1719\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 11767.3174 - val_loss: 12263.3975\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 11166.7021 - val_loss: 11640.0498\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 7ms/step - loss: 10622.4961 - val_loss: 11022.0127\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 10075.7959 - val_loss: 10407.1279\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 9567.8027 - val_loss: 9853.6729\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 9061.7979 - val_loss: 9315.9697\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 8589.9219 - val_loss: 8779.8320\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 8149.9341 - val_loss: 8270.1055\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 7741.4624 - val_loss: 7856.6416\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 7331.3794 - val_loss: 7303.1377\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 6935.8813 - val_loss: 6937.4541\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 6536.3418 - val_loss: 6484.5156\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 6177.6733 - val_loss: 6132.7749\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 5ms/step - loss: 5837.8989 - val_loss: 5715.8926\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 5499.5254 - val_loss: 5356.7930\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 5199.4756 - val_loss: 5051.8076\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 4893.2217 - val_loss: 4710.3013\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 4610.0630 - val_loss: 4408.7725\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 4339.6035 - val_loss: 4173.5107\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 4100.7695 - val_loss: 3896.0879\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 3852.0669 - val_loss: 3645.9138\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 3623.5583 - val_loss: 3376.2410\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 3409.8704 - val_loss: 3182.5857\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 3200.5256 - val_loss: 2953.0928\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 3008.7690 - val_loss: 2755.0278\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 2821.4690 - val_loss: 2555.8396\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 2658.4077 - val_loss: 2378.1279\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 2483.3333 - val_loss: 2232.3865\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 2321.6296 - val_loss: 2072.2329\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 2176.2708 - val_loss: 1918.4679\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 2035.8596 - val_loss: 1785.5570\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 59ms/step - loss: 412786.4688 - val_loss: 268216.4062\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 19ms/step - loss: 214204.2656 - val_loss: 125377.8359\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 13ms/step - loss: 98101.2344 - val_loss: 52466.3125\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 41709.6016 - val_loss: 22987.8613\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 5ms/step - loss: 19173.4688 - val_loss: 13678.6113\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 11892.8525 - val_loss: 11463.0293\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 9674.6133 - val_loss: 10942.2148\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 8854.0967 - val_loss: 10553.4971\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 8332.4248 - val_loss: 10015.7324\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 7905.6787 - val_loss: 9587.7344\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 7430.9912 - val_loss: 8982.5000\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 7033.8857 - val_loss: 8468.0615\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 6659.1680 - val_loss: 8021.5283\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 6299.8740 - val_loss: 7625.3340\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 5971.3315 - val_loss: 7229.0010\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 5663.6055 - val_loss: 6891.4043\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 5384.5679 - val_loss: 6525.4102\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 5124.8403 - val_loss: 6185.5562\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 4883.4712 - val_loss: 5850.4067\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 4658.4502 - val_loss: 5620.3535\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 4459.9448 - val_loss: 5384.5112\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 4285.7773 - val_loss: 5121.9800\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 4121.1987 - val_loss: 4863.5981\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 3963.3003 - val_loss: 4697.9106\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 3820.0596 - val_loss: 4538.0381\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 3680.6748 - val_loss: 4322.0806\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 3547.0312 - val_loss: 4170.7915\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 3426.7676 - val_loss: 3967.8652\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 3312.8562 - val_loss: 3844.2192\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 3205.5149 - val_loss: 3714.0066\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 3112.5710 - val_loss: 3552.2185\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 3026.8328 - val_loss: 3500.3579\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 2928.7607 - val_loss: 3329.3958\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 2838.7908 - val_loss: 3238.4097\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 2757.8853 - val_loss: 3138.9604\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 2679.2842 - val_loss: 3035.1641\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 2607.0349 - val_loss: 2917.4924\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 2539.1008 - val_loss: 2832.1111\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 2472.2783 - val_loss: 2748.9207\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 2407.9160 - val_loss: 2701.8555\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 2351.3245 - val_loss: 2613.0474\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 2288.0884 - val_loss: 2510.0505\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 2235.3760 - val_loss: 2481.9373\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 5ms/step - loss: 2180.8066 - val_loss: 2385.5984\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 2131.0566 - val_loss: 2321.0947\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 2079.3457 - val_loss: 2265.3779\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 2032.7438 - val_loss: 2216.4458\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 1989.3698 - val_loss: 2175.3508\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 1943.9459 - val_loss: 2091.3535\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 1899.1909 - val_loss: 2066.6558\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 43ms/step - loss: 83025.3828 - val_loss: 41541.4805\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 28028.5742 - val_loss: 16073.5049\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 13398.2246 - val_loss: 11547.4043\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 10402.4775 - val_loss: 10750.6816\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 9623.5537 - val_loss: 10075.5391\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 8910.4795 - val_loss: 9341.5547\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 8215.4648 - val_loss: 8593.1484\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 7ms/step - loss: 7548.6504 - val_loss: 7896.4629\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 6915.5508 - val_loss: 7239.6021\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 7ms/step - loss: 6357.1074 - val_loss: 6613.3164\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 5810.2109 - val_loss: 6058.8574\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 5323.5249 - val_loss: 5559.4365\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 4878.2759 - val_loss: 5080.7437\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 4471.2852 - val_loss: 4667.3828\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 7ms/step - loss: 4097.8457 - val_loss: 4242.8618\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 3748.9795 - val_loss: 3913.0850\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 5ms/step - loss: 3446.0930 - val_loss: 3571.6472\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 3159.8281 - val_loss: 3247.3040\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 2896.2566 - val_loss: 2981.5881\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 2655.2402 - val_loss: 2734.2798\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 2445.6047 - val_loss: 2477.8147\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 2249.2815 - val_loss: 2297.9600\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 2069.7341 - val_loss: 2090.3320\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1911.1027 - val_loss: 1901.5376\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 15ms/step - loss: 1765.5267 - val_loss: 1762.6893\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 11ms/step - loss: 1637.3365 - val_loss: 1614.4861\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 1519.2141 - val_loss: 1481.5214\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 1412.6354 - val_loss: 1373.7784\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 1317.2849 - val_loss: 1275.6686\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 1235.9847 - val_loss: 1172.8894\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 13ms/step - loss: 1156.5161 - val_loss: 1106.5681\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 1087.2236 - val_loss: 1010.0428\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 16ms/step - loss: 1023.4107 - val_loss: 953.4454\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 10ms/step - loss: 967.2764 - val_loss: 889.0537\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 11ms/step - loss: 914.7407 - val_loss: 825.4210\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 7ms/step - loss: 866.2203 - val_loss: 792.4935\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 821.8810 - val_loss: 738.0169\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 5ms/step - loss: 783.1769 - val_loss: 701.1136\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 745.8884 - val_loss: 666.2818\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 717.3646 - val_loss: 641.0164\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 683.0720 - val_loss: 595.4801\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 655.2849 - val_loss: 569.4665\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 7ms/step - loss: 623.4948 - val_loss: 546.8817\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 598.6359 - val_loss: 519.7523\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 577.3784 - val_loss: 493.9439\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 550.3477 - val_loss: 476.6919\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 529.7082 - val_loss: 453.1049\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 509.5011 - val_loss: 441.8810\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 488.6722 - val_loss: 417.1994\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 470.8153 - val_loss: 400.9394\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 47405.1758 - val_loss: 22207.8555\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 10925.4346 - val_loss: 3917.4050\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 2065.3728 - val_loss: 1440.6583\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 5ms/step - loss: 1313.2445 - val_loss: 1338.9617\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 5ms/step - loss: 1242.7584 - val_loss: 1269.0505\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1167.9009 - val_loss: 1195.6182\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1100.3921 - val_loss: 1112.8689\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1033.4655 - val_loss: 1042.8964\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 973.2436 - val_loss: 978.0425\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 912.1372 - val_loss: 906.2574\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 859.8701 - val_loss: 852.0919\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 806.2407 - val_loss: 788.8303\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 758.2112 - val_loss: 738.3197\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 714.6744 - val_loss: 694.4173\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 673.9584 - val_loss: 646.0095\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 637.0906 - val_loss: 602.6304\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 603.2729 - val_loss: 572.1719\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 572.8929 - val_loss: 532.4199\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 544.7234 - val_loss: 504.5808\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 520.4675 - val_loss: 478.5276\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 492.8218 - val_loss: 447.6737\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 468.3705 - val_loss: 423.6215\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 447.7767 - val_loss: 403.7538\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 428.6776 - val_loss: 383.7300\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 408.6768 - val_loss: 364.3385\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 391.2589 - val_loss: 348.5885\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 372.6097 - val_loss: 331.7080\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 357.9579 - val_loss: 318.1229\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 342.8218 - val_loss: 304.2950\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 328.9998 - val_loss: 291.3669\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 315.6549 - val_loss: 281.0837\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 302.2498 - val_loss: 267.4070\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 292.1616 - val_loss: 259.8098\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 280.4744 - val_loss: 250.1141\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 270.7051 - val_loss: 238.6208\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 259.1997 - val_loss: 233.5147\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 249.1773 - val_loss: 223.1908\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 241.0282 - val_loss: 217.8033\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 231.9426 - val_loss: 209.2383\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 224.2943 - val_loss: 203.2560\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 215.9212 - val_loss: 197.4859\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 209.6514 - val_loss: 193.7413\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 202.9378 - val_loss: 188.3583\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 197.0914 - val_loss: 182.7151\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 189.1980 - val_loss: 179.7401\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 184.8730 - val_loss: 175.0446\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 179.6240 - val_loss: 171.8637\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 173.9047 - val_loss: 167.9008\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 7ms/step - loss: 168.9285 - val_loss: 165.4868\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 165.0860 - val_loss: 162.3362\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 45ms/step - loss: 494490.2812 - val_loss: 380506.0000\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 19ms/step - loss: 313243.3438 - val_loss: 232123.1875\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 183883.7188 - val_loss: 129212.6875\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 95161.8203 - val_loss: 60041.0352\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 8ms/step - loss: 38399.3555 - val_loss: 19608.4199\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 12ms/step - loss: 11304.6875 - val_loss: 5234.7285\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 14ms/step - loss: 3630.7544 - val_loss: 2597.7363\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 12ms/step - loss: 2577.1313 - val_loss: 2348.3967\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 11ms/step - loss: 2444.9890 - val_loss: 2266.6396\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 2354.2637 - val_loss: 2189.8853\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 2263.7578 - val_loss: 2112.3655\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 2173.8542 - val_loss: 2035.3470\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 5ms/step - loss: 2086.7856 - val_loss: 1957.3864\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 5ms/step - loss: 1999.9211 - val_loss: 1884.7852\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1917.9376 - val_loss: 1807.1749\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 1835.2120 - val_loss: 1735.4967\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1753.2124 - val_loss: 1672.2279\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 7ms/step - loss: 1676.2037 - val_loss: 1602.2699\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 1602.0348 - val_loss: 1537.1796\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 1530.5276 - val_loss: 1474.6956\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 1460.0256 - val_loss: 1421.2394\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1393.5032 - val_loss: 1356.9908\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1328.0359 - val_loss: 1302.2278\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 1267.9806 - val_loss: 1250.7472\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 1212.3619 - val_loss: 1200.0168\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 1154.4489 - val_loss: 1152.8158\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 1104.9907 - val_loss: 1104.5325\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 7ms/step - loss: 1051.5098 - val_loss: 1055.1088\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 1003.3611 - val_loss: 1013.4449\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 958.5077 - val_loss: 974.4727\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 913.5220 - val_loss: 932.0914\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 870.9365 - val_loss: 894.8317\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 831.5629 - val_loss: 853.5474\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 794.9396 - val_loss: 819.8128\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 764.7908 - val_loss: 792.1386\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 724.6005 - val_loss: 754.8519\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 692.6937 - val_loss: 726.6745\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 661.1934 - val_loss: 694.7265\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 635.0695 - val_loss: 669.5995\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 606.8914 - val_loss: 642.9730\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 579.7516 - val_loss: 618.0776\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 5ms/step - loss: 556.8109 - val_loss: 594.8447\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 532.2188 - val_loss: 571.9915\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 510.8220 - val_loss: 554.2326\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 492.9164 - val_loss: 532.5759\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 473.8217 - val_loss: 514.6711\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 453.1997 - val_loss: 495.9582\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 436.4514 - val_loss: 479.7304\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 420.1913 - val_loss: 462.7050\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 405.3005 - val_loss: 450.0258\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 170153.3438 - val_loss: 100913.2266\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 69219.6328 - val_loss: 35990.8516\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 24306.1992 - val_loss: 12079.9834\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 8880.3184 - val_loss: 5253.6802\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 4593.5835 - val_loss: 3979.6643\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 3656.6592 - val_loss: 3757.6934\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 7ms/step - loss: 3403.7407 - val_loss: 3608.9575\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 3236.3806 - val_loss: 3433.3745\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 3065.0435 - val_loss: 3224.2278\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 2898.0183 - val_loss: 3034.6245\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 2734.9697 - val_loss: 2852.9409\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 2576.6782 - val_loss: 2673.6443\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 2424.1340 - val_loss: 2499.9248\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 2277.0906 - val_loss: 2334.3284\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 2133.0759 - val_loss: 2180.7671\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1998.4983 - val_loss: 2025.6448\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1863.9324 - val_loss: 1880.0532\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1742.7336 - val_loss: 1753.6696\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 1622.6554 - val_loss: 1622.5057\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 1512.6241 - val_loss: 1514.2957\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 1405.6687 - val_loss: 1404.0514\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 5ms/step - loss: 1305.4498 - val_loss: 1294.2985\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1211.1580 - val_loss: 1199.4299\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1118.5608 - val_loss: 1112.5118\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 1019.5303 - val_loss: 1012.0626\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 886.8008 - val_loss: 877.9100\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 760.1071 - val_loss: 779.0273\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 653.5579 - val_loss: 684.8661\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 565.9877 - val_loss: 597.5084\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 495.4778 - val_loss: 548.8467\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 437.5751 - val_loss: 481.0188\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 7ms/step - loss: 391.9486 - val_loss: 447.1929\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 357.9129 - val_loss: 412.9224\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 330.2385 - val_loss: 389.4673\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 309.0271 - val_loss: 369.3848\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 290.5674 - val_loss: 346.6900\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 274.0116 - val_loss: 335.0575\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 261.3942 - val_loss: 324.2426\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 251.5618 - val_loss: 312.1284\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 239.8015 - val_loss: 301.6978\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 230.4680 - val_loss: 288.9672\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 223.0551 - val_loss: 288.2194\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 13ms/step - loss: 217.2959 - val_loss: 272.8709\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 211.4932 - val_loss: 263.3306\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 205.3681 - val_loss: 257.5693\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 8ms/step - loss: 199.8837 - val_loss: 253.0467\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 11ms/step - loss: 196.1857 - val_loss: 246.4851\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 5ms/step - loss: 191.6234 - val_loss: 239.4167\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 187.1031 - val_loss: 235.2275\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 184.0284 - val_loss: 233.4664\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 41160.2695 - val_loss: 22031.1152\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 14485.9707 - val_loss: 10839.5674\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 9660.7070 - val_loss: 9409.0918\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 8555.5996 - val_loss: 8261.6328\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 7516.7256 - val_loss: 7246.6812\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 6597.1318 - val_loss: 6319.2646\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 5783.1675 - val_loss: 5487.7988\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 5039.2114 - val_loss: 4736.5605\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 4354.9370 - val_loss: 4068.0894\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 3756.1987 - val_loss: 3445.5652\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 3215.2964 - val_loss: 2896.9219\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 2724.3694 - val_loss: 2452.4702\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 7ms/step - loss: 2311.3599 - val_loss: 2069.2529\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1956.6451 - val_loss: 1719.7020\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1647.8387 - val_loss: 1431.2091\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 1389.4446 - val_loss: 1194.8571\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 1176.6217 - val_loss: 1011.8723\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 1016.7941 - val_loss: 880.7576\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 893.2119 - val_loss: 774.1973\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 800.3890 - val_loss: 697.3145\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 722.9680 - val_loss: 635.7000\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 660.1333 - val_loss: 593.6390\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 612.2246 - val_loss: 552.2835\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 570.6786 - val_loss: 521.3085\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 535.3900 - val_loss: 492.4474\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 504.9671 - val_loss: 471.0246\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 478.2156 - val_loss: 455.6390\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 455.4276 - val_loss: 436.4664\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 432.1173 - val_loss: 422.1952\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 413.6226 - val_loss: 407.8350\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 396.8868 - val_loss: 396.1747\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 381.2932 - val_loss: 382.5161\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 366.6964 - val_loss: 372.9453\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 356.3653 - val_loss: 365.4454\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 342.3262 - val_loss: 351.8452\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 331.3847 - val_loss: 348.3013\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 320.8924 - val_loss: 340.1206\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 311.5084 - val_loss: 331.1209\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 301.9491 - val_loss: 325.5197\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 295.1465 - val_loss: 316.0481\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 5ms/step - loss: 284.9747 - val_loss: 309.8520\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 276.9083 - val_loss: 307.3027\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 269.7686 - val_loss: 298.7596\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 262.9034 - val_loss: 293.7168\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 255.6053 - val_loss: 286.1812\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 249.2677 - val_loss: 280.3574\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 243.3527 - val_loss: 275.1865\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 5ms/step - loss: 239.2616 - val_loss: 269.4666\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 234.4368 - val_loss: 265.6429\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 5ms/step - loss: 227.3798 - val_loss: 263.1487\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 341497.2500 - val_loss: 188375.3594\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 114891.7188 - val_loss: 51278.0664\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 29865.9863 - val_loss: 15310.4609\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 12334.5156 - val_loss: 11279.4873\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 7ms/step - loss: 10904.2070 - val_loss: 10598.4980\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 10241.7500 - val_loss: 9840.5547\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 9546.8262 - val_loss: 9135.5557\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 8871.7256 - val_loss: 8449.5674\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 8245.9463 - val_loss: 7796.6060\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 7596.1812 - val_loss: 7150.5132\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 7000.3462 - val_loss: 6556.1201\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 7ms/step - loss: 6439.9688 - val_loss: 5983.7368\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 8ms/step - loss: 5889.4487 - val_loss: 5470.1641\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 5391.8188 - val_loss: 4974.7197\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 4922.1641 - val_loss: 4496.7563\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 4463.6025 - val_loss: 4073.5825\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 4055.2402 - val_loss: 3668.7283\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 3675.7725 - val_loss: 3307.5750\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 3313.6270 - val_loss: 2961.4358\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 2986.3467 - val_loss: 2659.6775\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 2679.5640 - val_loss: 2384.5386\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 2411.7542 - val_loss: 2133.4644\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 2157.4128 - val_loss: 1910.2615\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 13ms/step - loss: 1931.8031 - val_loss: 1697.6829\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 7ms/step - loss: 1724.5498 - val_loss: 1515.6832\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 13ms/step - loss: 1543.2620 - val_loss: 1356.7242\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 11ms/step - loss: 1384.2410 - val_loss: 1218.4879\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 1245.5811 - val_loss: 1097.3049\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 1121.8334 - val_loss: 992.1063\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 1015.6093 - val_loss: 905.8914\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 923.7399 - val_loss: 830.4953\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 847.4787 - val_loss: 769.6451\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 784.5648 - val_loss: 715.7657\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 730.6070 - val_loss: 673.2900\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 7ms/step - loss: 684.8991 - val_loss: 635.8840\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 646.4355 - val_loss: 605.3675\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 613.4587 - val_loss: 578.8562\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 7ms/step - loss: 584.0578 - val_loss: 556.3098\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 559.7129 - val_loss: 537.4860\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 539.3788 - val_loss: 520.4487\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 521.4728 - val_loss: 507.3943\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 503.7174 - val_loss: 496.1168\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 489.1261 - val_loss: 486.5370\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 476.6057 - val_loss: 478.5596\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 466.6701 - val_loss: 469.4305\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 456.1768 - val_loss: 462.1498\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 448.0470 - val_loss: 456.0502\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 5ms/step - loss: 439.4714 - val_loss: 451.1909\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 432.7047 - val_loss: 445.1413\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 425.5981 - val_loss: 442.7632\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 37086.0625 - val_loss: 22722.5312\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 14871.2109 - val_loss: 7690.2744\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 4367.9609 - val_loss: 1829.9988\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 943.4397 - val_loss: 484.8124\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 344.3347 - val_loss: 353.8269\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 7ms/step - loss: 301.1443 - val_loss: 345.6899\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 5ms/step - loss: 293.9561 - val_loss: 337.7257\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 286.6691 - val_loss: 328.8917\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 278.8919 - val_loss: 320.6634\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 271.6812 - val_loss: 312.3982\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 264.5544 - val_loss: 304.3070\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 257.4025 - val_loss: 296.6279\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 251.7042 - val_loss: 288.6554\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 244.3239 - val_loss: 281.5703\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 5ms/step - loss: 238.2166 - val_loss: 274.7652\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 232.5049 - val_loss: 268.0362\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 227.1660 - val_loss: 261.5918\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 221.5880 - val_loss: 255.4511\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 216.8550 - val_loss: 249.7983\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 212.3896 - val_loss: 244.1875\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 207.3446 - val_loss: 239.5964\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 203.3330 - val_loss: 235.2423\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 199.5760 - val_loss: 230.2922\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 195.8972 - val_loss: 226.2039\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 193.0291 - val_loss: 222.7820\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 189.6668 - val_loss: 218.3690\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 186.8284 - val_loss: 215.0762\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 183.6328 - val_loss: 211.4024\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 181.3115 - val_loss: 208.4377\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 178.0364 - val_loss: 205.5158\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 175.7560 - val_loss: 202.1279\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 173.5332 - val_loss: 199.2007\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 170.8980 - val_loss: 196.4111\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 168.7743 - val_loss: 193.5694\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 166.4795 - val_loss: 191.6960\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 164.5039 - val_loss: 188.6305\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 162.5330 - val_loss: 186.1197\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 160.6739 - val_loss: 184.3080\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 158.8931 - val_loss: 181.5554\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 157.1173 - val_loss: 179.4798\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 155.7151 - val_loss: 177.9968\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 154.1028 - val_loss: 175.6860\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 7ms/step - loss: 152.3585 - val_loss: 173.9799\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 150.9599 - val_loss: 171.8703\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.9896 - val_loss: 170.3685\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.7751 - val_loss: 168.7452\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 146.7471 - val_loss: 166.6024\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 13ms/step - loss: 145.3323 - val_loss: 165.3015\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.1956 - val_loss: 163.6154\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.5987 - val_loss: 162.1046\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 60ms/step - loss: 46119.8555 - val_loss: 33926.9844\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 17ms/step - loss: 23698.9844 - val_loss: 16613.5898\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 11057.3867 - val_loss: 7218.2021\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 4524.8457 - val_loss: 2838.3896\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1699.3403 - val_loss: 1054.2532\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 5ms/step - loss: 659.6843 - val_loss: 536.9042\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 396.4178 - val_loss: 433.8899\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 7ms/step - loss: 349.9516 - val_loss: 408.5646\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 336.2123 - val_loss: 392.8452\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 325.4671 - val_loss: 378.1707\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 314.8985 - val_loss: 364.2874\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 304.9484 - val_loss: 350.6416\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 295.7309 - val_loss: 337.0211\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 286.5146 - val_loss: 324.7894\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 277.9736 - val_loss: 313.6245\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 269.7939 - val_loss: 302.0695\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 261.8670 - val_loss: 291.9939\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 255.2117 - val_loss: 281.7872\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 248.5181 - val_loss: 273.2928\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 242.3973 - val_loss: 265.3798\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 237.0855 - val_loss: 257.2429\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 7ms/step - loss: 232.1041 - val_loss: 249.8805\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 227.5405 - val_loss: 243.6829\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 222.9229 - val_loss: 237.9682\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 219.2859 - val_loss: 232.3393\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 215.4730 - val_loss: 227.9981\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 212.7266 - val_loss: 222.9905\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 209.4369 - val_loss: 218.3223\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 206.0247 - val_loss: 213.8327\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 7ms/step - loss: 203.0303 - val_loss: 210.2741\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 200.6414 - val_loss: 206.1605\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 197.8192 - val_loss: 202.8601\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 195.3045 - val_loss: 199.1756\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 192.8262 - val_loss: 196.5662\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 190.5089 - val_loss: 193.3052\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 7ms/step - loss: 188.6016 - val_loss: 190.4590\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 186.8644 - val_loss: 188.1120\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 184.4452 - val_loss: 185.5643\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 182.8791 - val_loss: 183.0813\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 180.7762 - val_loss: 181.2812\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 179.3232 - val_loss: 178.9367\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 177.4252 - val_loss: 176.8318\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 175.8953 - val_loss: 174.9449\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 174.0710 - val_loss: 173.1743\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 172.5340 - val_loss: 171.1404\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 171.0734 - val_loss: 170.0027\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 169.6017 - val_loss: 167.7049\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 168.5611 - val_loss: 166.8849\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 166.8560 - val_loss: 164.9143\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 5ms/step - loss: 165.3128 - val_loss: 163.7008\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 200761.0312 - val_loss: 159841.9219\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 122690.5000 - val_loss: 91576.3281\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 64775.1797 - val_loss: 45467.6953\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 29614.7578 - val_loss: 20093.1934\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 12307.5381 - val_loss: 8843.5537\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 5857.2612 - val_loss: 4967.0898\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 3956.3994 - val_loss: 3986.6404\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 5ms/step - loss: 3582.4656 - val_loss: 3720.0012\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 3497.9375 - val_loss: 3607.3220\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 3455.5566 - val_loss: 3536.3442\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 7ms/step - loss: 3410.7295 - val_loss: 3499.9077\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 3359.8293 - val_loss: 3436.8542\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 5ms/step - loss: 3308.3208 - val_loss: 3394.0906\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 3233.2781 - val_loss: 3251.3667\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 2999.9622 - val_loss: 2882.7092\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 2645.2529 - val_loss: 2577.3862\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 2386.2373 - val_loss: 2281.1062\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 2166.4895 - val_loss: 2046.2673\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 1974.0182 - val_loss: 1849.8942\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 1774.3630 - val_loss: 1683.4865\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1601.4158 - val_loss: 1503.7236\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1448.0112 - val_loss: 1395.2081\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1306.1355 - val_loss: 1222.6753\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1168.7512 - val_loss: 1099.5026\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1045.4739 - val_loss: 1015.3964\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 932.1378 - val_loss: 897.1500\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 836.0682 - val_loss: 801.1263\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 13ms/step - loss: 742.9846 - val_loss: 731.5964\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 668.0168 - val_loss: 680.1932\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 590.6938 - val_loss: 580.4606\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 7ms/step - loss: 526.7787 - val_loss: 519.9323\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 470.5839 - val_loss: 472.7136\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 422.7890 - val_loss: 436.9971\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 13ms/step - loss: 380.1281 - val_loss: 389.9731\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 340.6503 - val_loss: 354.2005\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 14ms/step - loss: 306.6573 - val_loss: 318.6845\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 11ms/step - loss: 280.6464 - val_loss: 295.4529\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 256.1989 - val_loss: 273.6281\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 233.8631 - val_loss: 249.5053\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 213.8279 - val_loss: 229.8800\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 198.6974 - val_loss: 215.7707\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 185.6781 - val_loss: 209.8649\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 176.1474 - val_loss: 194.8650\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 165.9504 - val_loss: 184.8724\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 157.9897 - val_loss: 178.1704\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 151.1965 - val_loss: 171.8316\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 145.0534 - val_loss: 166.8321\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.0927 - val_loss: 162.0316\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 135.5583 - val_loss: 159.1367\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 134.5850 - val_loss: 156.2014\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 4870.0522 - val_loss: 2139.6975\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1822.2686 - val_loss: 1365.9196\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1205.9296 - val_loss: 1021.9899\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 5ms/step - loss: 940.0606 - val_loss: 881.5434\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 798.5038 - val_loss: 779.5328\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 707.2543 - val_loss: 708.2242\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 5ms/step - loss: 646.3638 - val_loss: 672.5451\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 595.3384 - val_loss: 602.8669\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 551.0696 - val_loss: 565.2908\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 7ms/step - loss: 510.7270 - val_loss: 521.6503\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 5ms/step - loss: 471.6127 - val_loss: 492.0390\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 438.5956 - val_loss: 472.2130\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 413.6003 - val_loss: 441.8483\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 385.5804 - val_loss: 409.9702\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 365.8858 - val_loss: 391.2405\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 344.1945 - val_loss: 364.2686\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 327.0768 - val_loss: 338.2470\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 308.7067 - val_loss: 316.8385\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 287.2216 - val_loss: 305.5044\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 271.4383 - val_loss: 288.6416\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 255.9936 - val_loss: 271.2263\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 245.3818 - val_loss: 254.3629\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 233.0662 - val_loss: 241.6792\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 218.7171 - val_loss: 230.9186\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 208.9427 - val_loss: 221.2837\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 199.9284 - val_loss: 213.3719\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 5ms/step - loss: 190.2019 - val_loss: 205.2110\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 187.1853 - val_loss: 196.1170\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 175.0090 - val_loss: 186.0450\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 169.1772 - val_loss: 180.0588\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 161.6691 - val_loss: 173.8714\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 156.0707 - val_loss: 170.7859\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 151.9850 - val_loss: 162.3327\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.9209 - val_loss: 157.7949\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 140.5854 - val_loss: 155.1871\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.3707 - val_loss: 147.1385\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 133.2709 - val_loss: 145.3544\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 129.0996 - val_loss: 143.4383\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 125.7312 - val_loss: 139.1116\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 122.4500 - val_loss: 135.0378\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 120.0061 - val_loss: 130.6169\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 5ms/step - loss: 118.6634 - val_loss: 127.4652\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 115.2075 - val_loss: 126.0769\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 113.9059 - val_loss: 127.4754\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 112.3274 - val_loss: 120.5729\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 110.6064 - val_loss: 118.9176\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 108.0171 - val_loss: 118.3002\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 7ms/step - loss: 106.4143 - val_loss: 119.0880\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 107.4191 - val_loss: 112.3337\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 103.4423 - val_loss: 111.0217\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 50ms/step - loss: 2914.5576 - val_loss: 2888.0325\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 6ms/step - loss: 2396.5898 - val_loss: 2300.8591\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1944.5718 - val_loss: 1875.7146\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1591.9686 - val_loss: 1531.4514\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 5ms/step - loss: 1312.8608 - val_loss: 1227.8407\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1074.8606 - val_loss: 984.1531\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 13ms/step - loss: 885.3166 - val_loss: 794.8173\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 13ms/step - loss: 710.8654 - val_loss: 640.7262\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 13ms/step - loss: 574.8159 - val_loss: 526.2468\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 11ms/step - loss: 481.4395 - val_loss: 426.5286\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 400.7035 - val_loss: 344.0024\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 336.6138 - val_loss: 302.1159\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 293.9156 - val_loss: 273.3383\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 266.8717 - val_loss: 238.0361\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 5ms/step - loss: 237.8863 - val_loss: 208.3065\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 218.3431 - val_loss: 194.6165\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 198.7870 - val_loss: 183.6520\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 187.7186 - val_loss: 175.1706\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 176.2858 - val_loss: 176.5620\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 169.2901 - val_loss: 163.4933\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 158.0641 - val_loss: 156.3392\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 150.0296 - val_loss: 158.7634\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 5ms/step - loss: 147.9481 - val_loss: 151.1102\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.0425 - val_loss: 146.4085\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 134.7692 - val_loss: 149.2343\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 133.2462 - val_loss: 144.0871\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 129.2501 - val_loss: 140.1366\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 124.7065 - val_loss: 142.5335\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 121.9833 - val_loss: 138.7066\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 119.8100 - val_loss: 135.0132\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 117.4832 - val_loss: 135.4178\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 115.5465 - val_loss: 137.1153\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 113.8924 - val_loss: 132.3976\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 113.5655 - val_loss: 130.4029\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 111.1396 - val_loss: 128.8484\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 111.1202 - val_loss: 132.5531\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 110.4696 - val_loss: 127.9847\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 108.3595 - val_loss: 128.6044\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 107.9736 - val_loss: 126.2656\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 106.8337 - val_loss: 126.0611\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 108.6777 - val_loss: 125.2774\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 105.3629 - val_loss: 127.7737\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 105.2768 - val_loss: 125.5813\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 104.2668 - val_loss: 125.7425\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 108.2769 - val_loss: 123.7762\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 105.6879 - val_loss: 126.3957\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 104.0265 - val_loss: 123.0207\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 103.8495 - val_loss: 125.9800\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 107.1630 - val_loss: 123.4156\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 106.9104 - val_loss: 122.0139\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 117237.2891 - val_loss: 58988.1172\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 37968.4375 - val_loss: 15839.7295\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 11293.4717 - val_loss: 5573.0107\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 7ms/step - loss: 5314.0381 - val_loss: 4115.2554\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 5ms/step - loss: 4332.8657 - val_loss: 3944.6760\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 4107.0757 - val_loss: 3772.1497\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 3884.0435 - val_loss: 3558.1958\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 3672.6162 - val_loss: 3351.3965\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 3464.6033 - val_loss: 3144.7903\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 5ms/step - loss: 3257.5166 - val_loss: 2968.5303\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 3063.8210 - val_loss: 2765.9961\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 2875.8088 - val_loss: 2577.9048\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 2697.9971 - val_loss: 2408.4661\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 2527.0774 - val_loss: 2259.8213\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 2370.1714 - val_loss: 2103.2034\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 2220.2375 - val_loss: 1963.9019\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 2085.6013 - val_loss: 1835.2441\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1954.3408 - val_loss: 1717.9554\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 1833.4589 - val_loss: 1599.7091\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1721.6228 - val_loss: 1501.2811\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 1615.2677 - val_loss: 1404.3496\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1520.3527 - val_loss: 1313.5741\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1430.2942 - val_loss: 1239.7103\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 1347.0898 - val_loss: 1165.9666\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1270.5966 - val_loss: 1095.0392\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 1195.9088 - val_loss: 1033.8304\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 1129.7812 - val_loss: 976.3568\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 1068.5695 - val_loss: 922.5491\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 1010.3376 - val_loss: 879.6401\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 956.4158 - val_loss: 826.7763\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 907.9491 - val_loss: 787.1679\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 8ms/step - loss: 859.5875 - val_loss: 754.4234\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 13ms/step - loss: 815.3495 - val_loss: 709.2844\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 776.4567 - val_loss: 681.5424\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 12ms/step - loss: 737.2061 - val_loss: 647.4087\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 13ms/step - loss: 703.4186 - val_loss: 621.2912\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 669.7158 - val_loss: 594.2382\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 638.3987 - val_loss: 567.0094\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 609.5305 - val_loss: 544.3840\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 12ms/step - loss: 581.9697 - val_loss: 522.0695\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 8ms/step - loss: 557.6344 - val_loss: 501.3373\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 7ms/step - loss: 530.7405 - val_loss: 479.8742\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 12ms/step - loss: 507.9159 - val_loss: 462.9245\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 490.2503 - val_loss: 445.5094\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 464.9185 - val_loss: 427.4178\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 445.6866 - val_loss: 411.1920\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 426.1207 - val_loss: 396.1027\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 409.8684 - val_loss: 381.7055\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 392.0461 - val_loss: 369.2722\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 376.4387 - val_loss: 357.1203\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 42ms/step - loss: 567884.9375 - val_loss: 427760.0625\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 342907.9062 - val_loss: 237870.8125\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 176248.7812 - val_loss: 106933.2422\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 72046.2109 - val_loss: 37175.8828\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 23115.9297 - val_loss: 10369.3760\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 6537.2339 - val_loss: 3507.3318\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 2687.2542 - val_loss: 2462.4783\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 5ms/step - loss: 2084.3718 - val_loss: 2322.6958\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1950.3889 - val_loss: 2207.8970\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1844.1407 - val_loss: 2081.5171\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1740.1305 - val_loss: 1955.6571\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1635.1000 - val_loss: 1839.2260\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1533.8396 - val_loss: 1720.2358\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1438.0872 - val_loss: 1600.3782\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1344.4968 - val_loss: 1486.6761\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 1254.4102 - val_loss: 1391.5385\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 1169.0298 - val_loss: 1287.6456\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 1086.4471 - val_loss: 1192.6182\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 1008.9705 - val_loss: 1105.2822\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 936.7060 - val_loss: 1019.4931\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 868.3964 - val_loss: 942.5311\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 806.0151 - val_loss: 867.1660\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 745.5025 - val_loss: 805.3964\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 690.9482 - val_loss: 740.2156\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 641.1736 - val_loss: 680.8065\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 594.0342 - val_loss: 629.5871\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 550.2264 - val_loss: 580.3126\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 511.5524 - val_loss: 534.8381\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 475.2585 - val_loss: 493.1526\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 442.4274 - val_loss: 459.2295\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 412.7906 - val_loss: 422.7849\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 386.5234 - val_loss: 393.9007\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 362.4540 - val_loss: 369.1794\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 340.7179 - val_loss: 342.5536\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 320.5069 - val_loss: 322.0426\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 302.8310 - val_loss: 302.7007\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 287.3586 - val_loss: 284.6107\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 272.5853 - val_loss: 269.9110\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 260.8835 - val_loss: 255.1315\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 248.7500 - val_loss: 242.3999\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 237.9794 - val_loss: 231.7513\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 228.7386 - val_loss: 222.1982\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 5ms/step - loss: 220.5141 - val_loss: 213.5011\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 212.8219 - val_loss: 205.4266\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 206.2945 - val_loss: 198.5635\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 199.9308 - val_loss: 192.7884\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 194.4767 - val_loss: 186.9917\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 189.3338 - val_loss: 182.6613\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 184.9455 - val_loss: 177.9897\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 180.5671 - val_loss: 174.3513\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 535772.1250 - val_loss: 419313.7500\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 341455.8125 - val_loss: 252045.3281\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 192010.4531 - val_loss: 125412.3125\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 79080.6641 - val_loss: 35303.1133\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 18271.1680 - val_loss: 6174.3618\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 5396.3511 - val_loss: 3773.8826\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 10ms/step - loss: 4759.5815 - val_loss: 3507.6643\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 10ms/step - loss: 4412.2383 - val_loss: 3275.4746\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 4114.2026 - val_loss: 3041.7234\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 3829.6311 - val_loss: 2828.4180\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 3571.8638 - val_loss: 2625.4419\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 3322.9307 - val_loss: 2436.7388\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 7ms/step - loss: 3091.9387 - val_loss: 2256.2942\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 13ms/step - loss: 2876.0554 - val_loss: 2107.4829\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 13ms/step - loss: 2679.7954 - val_loss: 1964.4871\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 13ms/step - loss: 2495.9412 - val_loss: 1830.6606\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 2325.4167 - val_loss: 1705.4254\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 11ms/step - loss: 2170.5894 - val_loss: 1597.3085\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 2027.2198 - val_loss: 1486.7573\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1891.9244 - val_loss: 1398.9670\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 1775.6691 - val_loss: 1315.7517\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1661.5267 - val_loss: 1247.5427\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 1556.8485 - val_loss: 1168.0139\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 1464.0735 - val_loss: 1098.9877\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1375.6503 - val_loss: 1044.5724\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 1292.2772 - val_loss: 987.9018\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 1218.0696 - val_loss: 941.0580\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 1150.0903 - val_loss: 892.5901\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 1086.6694 - val_loss: 856.3330\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 7ms/step - loss: 1027.9673 - val_loss: 811.7513\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 971.6174 - val_loss: 775.9943\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 920.4691 - val_loss: 740.5679\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 875.9150 - val_loss: 710.1275\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 833.0060 - val_loss: 684.6120\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 7ms/step - loss: 790.5978 - val_loss: 655.8494\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 753.3182 - val_loss: 628.0818\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 718.3502 - val_loss: 603.1186\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 5ms/step - loss: 685.8430 - val_loss: 583.0854\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 656.3291 - val_loss: 563.8162\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 628.5017 - val_loss: 542.2364\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 601.3008 - val_loss: 525.3344\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 578.1019 - val_loss: 510.6990\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 5ms/step - loss: 554.4074 - val_loss: 493.8807\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 533.9664 - val_loss: 477.0964\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 513.6078 - val_loss: 464.2428\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 495.9615 - val_loss: 449.4889\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 479.5194 - val_loss: 437.8425\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 462.6297 - val_loss: 428.8464\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 447.4704 - val_loss: 414.5594\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 435.1960 - val_loss: 402.4587\n",
            "Mean Squared Error: 561.9002375793457\n",
            "Standard Deviation of Mean Squared Error: 747.2113875499324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the mean and standard deviation of the mean squared errors\n",
        "mean_mse = np.mean(mean_squared_errors)\n",
        "std_mse = np.std(mean_squared_errors)\n",
        "\n",
        "print(\"Mean of Mean Squared Errors: {}\".format(mean_mse))\n",
        "print(\"Standard Deviation of Mean Squared Errors: {}\".format(std_mse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGStM2V4TR_7",
        "outputId": "a7ddf951-bf8e-4bbe-d64b-ebba8a65ce3d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of Mean Squared Errors: 561.9002375793457\n",
            "Standard Deviation of Mean Squared Errors: 747.2113875499324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B. Normalize the Data**"
      ],
      "metadata": {
        "id": "ef-myBa8VKug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = data.drop('Strength' ,axis=1)\n",
        "target = data['Strength']\n",
        "\n",
        "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
        "predictors_norm.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mO0HMCLmVT_w",
        "outputId": "dd9f8bc8-9cb2-49f8-f51a-a7f6ce8085d8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
              "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
              "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
              "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
              "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
              "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
              "\n",
              "   Coarse Aggregate  Fine Aggregate       Age  \n",
              "0          0.862735       -1.217079 -0.279597  \n",
              "1          1.055651       -1.217079 -0.279597  \n",
              "2         -0.526262       -2.239829  3.551340  \n",
              "3         -0.526262       -2.239829  5.055221  \n",
              "4          0.070492        0.647569  4.976069  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78c74aab-f8cb-4fb9-bdb7-728f806f4499\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>0.862735</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>1.055651</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>3.551340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>5.055221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.790075</td>\n",
              "      <td>0.678079</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>0.488555</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>0.070492</td>\n",
              "      <td>0.647569</td>\n",
              "      <td>4.976069</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78c74aab-f8cb-4fb9-bdb7-728f806f4499')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78c74aab-f8cb-4fb9-bdb7-728f806f4499 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78c74aab-f8cb-4fb9-bdb7-728f806f4499');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2892a790-f348-47d2-ac16-504c82608319\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2892a790-f348-47d2-ac16-504c82608319')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2892a790-f348-47d2-ac16-504c82608319 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "predictors_norm",
              "summary": "{\n  \"name\": \"predictors_norm\",\n  \"rows\": 1030,\n  \"fields\": [\n    {\n      \"column\": \"Cement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -1.7144205995851924,\n        \"max\": 2.476711702426229,\n        \"num_unique_values\": 278,\n        \"samples\": [\n          0.5428581904707304,\n          0.08642665895030859,\n          -0.18341336597371433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blast Furnace Slag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9999999999999999,\n        \"min\": -0.8564718244890963,\n        \"max\": 3.3090676049756658,\n        \"num_unique_values\": 185,\n        \"samples\": [\n          0.24112579368094536,\n          0.5227691106981788,\n          0.7232806079985139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fly Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -0.8467325968146493,\n        \"max\": 2.2799762647844055,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          0.6845890845282162,\n          1.3721212679882784,\n          2.200285034428808\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Water\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.798851260765261,\n        \"max\": 3.064158880238681,\n        \"num_unique_values\": 195,\n        \"samples\": [\n          0.647774509026194,\n          0.1045563170481933,\n          -2.541290911120519\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Superplasticizer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -1.0386382541022239,\n        \"max\": 4.351528287732031,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          1.4723088927149754,\n          3.681942381914111,\n          1.7234036073966954\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coarse Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.211063531411115,\n        \"max\": 2.213148774849662,\n        \"num_unique_values\": 284,\n        \"samples\": [\n          -1.553862226614819,\n          -0.7590473413621567,\n          -0.7577612331335922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fine Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.239829000131109,\n        \"max\": 2.7317347935640552,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          -0.7930116391962395,\n          -0.9751110656587321,\n          -0.05338862623556972\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -0.7070159638428309,\n        \"max\": 5.055221007679151,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.7177129576873293,\n          0.8601858498403454,\n          -0.27959728738378287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_cols = predictors_norm.shape[1]\n",
        "mean_squared_errors = []\n",
        "\n",
        "for i in range(50):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=1)\n",
        "    model = regression_model()\n",
        "    model.fit(x_train, y_train, validation_data=(x_test, y_test) ,epochs=50, verbose=2)\n",
        "\n",
        "    mse = model.evaluate(x_test, y_test, verbose=0)\n",
        "    mean_squared_errors.append(mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvx6kYCNVk4w",
        "outputId": "a819ec69-2111-488c-80c5-0b013b8fa115"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 43ms/step - loss: 1476.3915 - val_loss: 1504.4907\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1459.9310 - val_loss: 1487.0323\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1442.7245 - val_loss: 1469.2249\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1425.0298 - val_loss: 1449.8939\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1405.9824 - val_loss: 1429.7892\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 7ms/step - loss: 1385.6570 - val_loss: 1408.3506\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 5ms/step - loss: 1364.3057 - val_loss: 1385.1954\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1341.5663 - val_loss: 1360.8788\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1317.1534 - val_loss: 1335.8228\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1291.8346 - val_loss: 1309.2046\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 7ms/step - loss: 1265.1609 - val_loss: 1280.3131\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 1236.5919 - val_loss: 1251.1481\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1207.7341 - val_loss: 1220.5389\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1177.6973 - val_loss: 1188.8114\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1146.2227 - val_loss: 1156.5312\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1114.1451 - val_loss: 1123.8483\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1081.4633 - val_loss: 1089.6417\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 1047.6138 - val_loss: 1055.7142\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 1013.5901 - val_loss: 1020.9035\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 978.7423 - val_loss: 985.6230\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 943.3732 - val_loss: 951.0247\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 5ms/step - loss: 908.2772 - val_loss: 914.9775\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 872.3026 - val_loss: 879.2520\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 836.5555 - val_loss: 843.5302\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 7ms/step - loss: 801.1039 - val_loss: 808.5201\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 765.9887 - val_loss: 774.0787\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 5ms/step - loss: 731.5365 - val_loss: 740.3666\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 698.4421 - val_loss: 706.9006\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 665.5708 - val_loss: 675.8461\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 634.8855 - val_loss: 644.9026\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 604.3431 - val_loss: 616.0037\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 575.6972 - val_loss: 588.2856\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 548.2491 - val_loss: 561.2084\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 521.9347 - val_loss: 536.0464\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 497.4764 - val_loss: 512.0854\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 473.9653 - val_loss: 490.2491\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 452.2240 - val_loss: 469.1113\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 431.7576 - val_loss: 449.2054\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 412.4408 - val_loss: 430.7014\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 394.7463 - val_loss: 413.1124\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 378.1286 - val_loss: 396.5138\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 362.0729 - val_loss: 381.9091\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 347.6547 - val_loss: 368.0089\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 333.8125 - val_loss: 355.1529\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 321.1016 - val_loss: 343.2368\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 309.6455 - val_loss: 331.8290\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 298.5175 - val_loss: 321.7739\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 7ms/step - loss: 288.4315 - val_loss: 312.0321\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 278.9179 - val_loss: 303.3079\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 270.1809 - val_loss: 294.9375\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1537.0310 - val_loss: 1557.7013\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1519.8082 - val_loss: 1540.4724\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1502.5763 - val_loss: 1522.8755\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1485.0132 - val_loss: 1504.9615\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1467.0352 - val_loss: 1486.6512\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1448.5776 - val_loss: 1467.5469\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1429.6093 - val_loss: 1447.6429\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1409.7759 - val_loss: 1427.1230\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1389.2113 - val_loss: 1405.9453\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1367.8314 - val_loss: 1384.0098\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 7ms/step - loss: 1345.6047 - val_loss: 1361.0511\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1322.2870 - val_loss: 1337.1548\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1298.1057 - val_loss: 1312.1780\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1273.0157 - val_loss: 1286.4193\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 8ms/step - loss: 1247.0931 - val_loss: 1259.7501\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 12ms/step - loss: 1220.1143 - val_loss: 1232.3901\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 5ms/step - loss: 1192.1766 - val_loss: 1204.0734\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 8ms/step - loss: 1163.4249 - val_loss: 1174.5157\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 11ms/step - loss: 1133.9860 - val_loss: 1143.7383\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 1102.8561 - val_loss: 1113.1707\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 12ms/step - loss: 1071.4077 - val_loss: 1080.8806\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1038.8019 - val_loss: 1048.5533\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 13ms/step - loss: 1005.8682 - val_loss: 1015.2386\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 15ms/step - loss: 972.5645 - val_loss: 981.6089\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 10ms/step - loss: 938.5288 - val_loss: 948.0920\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 904.3962 - val_loss: 914.7836\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 870.6106 - val_loss: 880.2805\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 836.0430 - val_loss: 846.5845\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 802.3129 - val_loss: 812.8101\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 768.2845 - val_loss: 780.1384\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 5ms/step - loss: 735.2912 - val_loss: 747.3835\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 702.4830 - val_loss: 715.7206\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 670.7495 - val_loss: 683.7246\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 639.2972 - val_loss: 653.9388\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 7ms/step - loss: 609.2117 - val_loss: 624.6432\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 580.3975 - val_loss: 595.8708\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 551.9131 - val_loss: 568.9256\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 525.0796 - val_loss: 542.6749\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 499.3364 - val_loss: 517.3885\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 474.6458 - val_loss: 493.3327\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 450.8895 - val_loss: 470.9128\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 428.5726 - val_loss: 450.0891\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 407.9717 - val_loss: 429.4915\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 388.0034 - val_loss: 410.5787\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 369.2029 - val_loss: 393.0408\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 351.7824 - val_loss: 376.5224\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 335.6270 - val_loss: 361.0828\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 320.3653 - val_loss: 347.1442\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 7ms/step - loss: 306.4845 - val_loss: 333.8073\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 293.2968 - val_loss: 321.5342\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 44ms/step - loss: 1554.2273 - val_loss: 1579.8220\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 6ms/step - loss: 1537.0325 - val_loss: 1561.9849\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1519.9869 - val_loss: 1543.9297\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1502.9690 - val_loss: 1525.6672\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1485.4972 - val_loss: 1507.5525\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1467.9897 - val_loss: 1488.7766\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1449.8391 - val_loss: 1469.6643\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1430.9977 - val_loss: 1450.3466\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1412.1635 - val_loss: 1429.3972\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1392.0985 - val_loss: 1408.8562\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 5ms/step - loss: 1371.8147 - val_loss: 1387.6195\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1350.9030 - val_loss: 1365.7118\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1329.3237 - val_loss: 1343.0447\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1306.9233 - val_loss: 1320.0343\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1284.1029 - val_loss: 1295.9773\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1260.6682 - val_loss: 1271.7593\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1236.6748 - val_loss: 1247.1726\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1212.6350 - val_loss: 1221.2653\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1187.0950 - val_loss: 1196.0664\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 1161.9404 - val_loss: 1169.8590\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 1136.1394 - val_loss: 1142.9399\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 1110.1095 - val_loss: 1115.2389\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1083.5925 - val_loss: 1087.8195\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 1056.6290 - val_loss: 1060.6077\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1029.7810 - val_loss: 1032.9501\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 1002.7418 - val_loss: 1004.9489\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 975.4272 - val_loss: 976.8011\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 948.0168 - val_loss: 948.6100\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 920.8246 - val_loss: 920.1803\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 893.2125 - val_loss: 891.9532\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 865.7810 - val_loss: 863.5854\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 838.5289 - val_loss: 835.1454\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 811.1692 - val_loss: 807.2301\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 784.1100 - val_loss: 780.0100\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 757.5650 - val_loss: 752.9803\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 731.3049 - val_loss: 726.0903\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 8ms/step - loss: 705.3287 - val_loss: 699.9977\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 7ms/step - loss: 679.9823 - val_loss: 674.7375\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 655.4526 - val_loss: 649.2016\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 631.1566 - val_loss: 625.5782\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 12ms/step - loss: 608.0040 - val_loss: 601.9949\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 585.4308 - val_loss: 579.3942\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 563.5356 - val_loss: 557.1776\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 542.4211 - val_loss: 536.1913\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 15ms/step - loss: 521.7674 - val_loss: 516.2201\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 11ms/step - loss: 502.1024 - val_loss: 496.5103\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 13ms/step - loss: 482.9194 - val_loss: 477.9567\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 464.6983 - val_loss: 459.9240\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 447.1959 - val_loss: 442.4959\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 430.0470 - val_loss: 425.8915\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 43ms/step - loss: 1573.3523 - val_loss: 1596.7231\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1556.2588 - val_loss: 1579.7235\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1539.2009 - val_loss: 1562.5275\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1521.8481 - val_loss: 1545.2925\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1504.2917 - val_loss: 1527.3779\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1486.0803 - val_loss: 1508.5636\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1467.0420 - val_loss: 1488.9540\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1447.0413 - val_loss: 1468.4036\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1426.1708 - val_loss: 1446.7015\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1404.1372 - val_loss: 1423.5116\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1380.5958 - val_loss: 1399.4974\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1356.0889 - val_loss: 1373.2120\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1329.8068 - val_loss: 1346.0383\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1302.4884 - val_loss: 1317.1250\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1273.6084 - val_loss: 1287.1515\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1243.5459 - val_loss: 1256.5212\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 5ms/step - loss: 1213.0782 - val_loss: 1224.2500\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1181.4858 - val_loss: 1191.4651\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1149.4347 - val_loss: 1158.0071\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1116.6940 - val_loss: 1125.0442\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1083.7493 - val_loss: 1090.9080\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1050.3610 - val_loss: 1055.9995\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1016.5466 - val_loss: 1021.2437\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 982.5184 - val_loss: 986.8666\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 948.9810 - val_loss: 951.4753\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 915.0231 - val_loss: 916.8185\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 881.2595 - val_loss: 882.7449\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 847.8536 - val_loss: 848.9515\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 814.8500 - val_loss: 815.1571\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 7ms/step - loss: 781.8092 - val_loss: 782.8997\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 749.8994 - val_loss: 750.3459\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 718.0565 - val_loss: 718.5439\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 686.9225 - val_loss: 687.0747\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 656.5937 - val_loss: 657.1299\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 627.2878 - val_loss: 628.1145\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 7ms/step - loss: 598.5742 - val_loss: 600.6953\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 571.2858 - val_loss: 573.1594\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 544.4398 - val_loss: 546.6632\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 518.8215 - val_loss: 521.4306\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 493.5956 - val_loss: 498.2984\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 470.2698 - val_loss: 475.1694\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 447.4786 - val_loss: 453.5262\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 426.0234 - val_loss: 432.9872\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 405.2574 - val_loss: 414.1010\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 386.0242 - val_loss: 395.4550\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 367.5038 - val_loss: 378.8650\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 350.7373 - val_loss: 362.3306\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 334.0297 - val_loss: 347.7554\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 319.0939 - val_loss: 333.9354\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 305.2440 - val_loss: 320.9006\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 42ms/step - loss: 1563.7958 - val_loss: 1596.9934\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1548.2380 - val_loss: 1580.4628\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1532.5111 - val_loss: 1563.6625\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1516.7185 - val_loss: 1546.3439\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 7ms/step - loss: 1500.3040 - val_loss: 1528.7014\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1483.5409 - val_loss: 1510.2292\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1466.1870 - val_loss: 1490.7805\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1447.8293 - val_loss: 1470.9949\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 1428.7848 - val_loss: 1450.1035\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1408.8811 - val_loss: 1428.5875\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1388.1606 - val_loss: 1405.9548\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1366.5411 - val_loss: 1382.8044\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 8ms/step - loss: 1344.2842 - val_loss: 1358.6960\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 11ms/step - loss: 1321.0498 - val_loss: 1333.8994\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1297.1074 - val_loss: 1308.4614\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 1272.5333 - val_loss: 1282.1276\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1247.0656 - val_loss: 1255.3497\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 7ms/step - loss: 1221.2828 - val_loss: 1227.9584\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 14ms/step - loss: 1194.4978 - val_loss: 1200.9824\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 11ms/step - loss: 1167.6213 - val_loss: 1172.8005\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 8ms/step - loss: 1139.9374 - val_loss: 1144.4905\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 9ms/step - loss: 1111.6425 - val_loss: 1115.7812\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1083.1461 - val_loss: 1086.7084\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 1054.0665 - val_loss: 1057.6646\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 7ms/step - loss: 1024.7249 - val_loss: 1028.5527\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 995.5645 - val_loss: 999.0914\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 965.9734 - val_loss: 969.4940\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 935.8880 - val_loss: 940.7409\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 906.3527 - val_loss: 911.3243\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 877.2687 - val_loss: 882.1325\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 7ms/step - loss: 847.9086 - val_loss: 854.3142\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 819.3087 - val_loss: 826.3856\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 790.7217 - val_loss: 798.9698\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 762.4101 - val_loss: 772.4462\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 734.6753 - val_loss: 745.6403\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 706.8942 - val_loss: 720.1139\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 680.3516 - val_loss: 694.6465\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 653.5040 - val_loss: 670.1013\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 627.4634 - val_loss: 645.8716\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 601.8878 - val_loss: 622.5398\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 576.9210 - val_loss: 599.7646\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 552.7292 - val_loss: 578.4440\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 530.0914 - val_loss: 556.4539\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 507.4854 - val_loss: 536.1949\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 485.9358 - val_loss: 517.2957\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 465.8176 - val_loss: 498.5956\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 446.4929 - val_loss: 480.9020\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 427.7288 - val_loss: 464.5773\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 410.3720 - val_loss: 449.1510\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 394.1048 - val_loss: 434.1372\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1526.6670 - val_loss: 1552.1558\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1511.5402 - val_loss: 1536.2240\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1495.6470 - val_loss: 1519.9025\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1479.4799 - val_loss: 1502.4315\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1462.5581 - val_loss: 1484.1121\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1444.3967 - val_loss: 1464.9353\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1425.5758 - val_loss: 1443.7648\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1405.3278 - val_loss: 1421.4229\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1383.7260 - val_loss: 1397.7853\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1360.5121 - val_loss: 1372.6243\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1336.2905 - val_loss: 1345.5939\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1309.8555 - val_loss: 1317.9885\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1282.8882 - val_loss: 1287.5321\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1253.7887 - val_loss: 1256.1362\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1223.4064 - val_loss: 1223.6075\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1191.2593 - val_loss: 1190.8578\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1158.9137 - val_loss: 1156.0496\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1125.1356 - val_loss: 1120.6436\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1090.5122 - val_loss: 1084.5123\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 1055.2456 - val_loss: 1048.3833\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 1020.0189 - val_loss: 1011.0334\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 983.9932 - val_loss: 974.0625\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 947.7382 - val_loss: 937.6387\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 911.8055 - val_loss: 901.0558\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 875.5341 - val_loss: 865.4530\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 840.1089 - val_loss: 829.0925\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 804.3504 - val_loss: 794.4180\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 769.4561 - val_loss: 760.0836\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 735.3989 - val_loss: 726.2292\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 701.7825 - val_loss: 693.7829\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 669.3677 - val_loss: 662.1752\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 7ms/step - loss: 638.1219 - val_loss: 631.6348\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 607.4630 - val_loss: 602.9235\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 578.6065 - val_loss: 575.0586\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 550.5813 - val_loss: 548.7840\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 523.7944 - val_loss: 524.1045\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 498.5349 - val_loss: 500.2448\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 474.1604 - val_loss: 478.6852\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 451.8087 - val_loss: 457.6092\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 430.2374 - val_loss: 438.1723\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 410.1018 - val_loss: 420.0552\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 391.2731 - val_loss: 403.7318\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 8ms/step - loss: 373.9679 - val_loss: 387.9886\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 13ms/step - loss: 357.5031 - val_loss: 373.8575\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 342.4376 - val_loss: 360.7139\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 8ms/step - loss: 328.3603 - val_loss: 348.7563\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 11ms/step - loss: 315.5081 - val_loss: 337.6462\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 303.4584 - val_loss: 327.5348\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 7ms/step - loss: 292.3354 - val_loss: 318.3586\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 13ms/step - loss: 282.2462 - val_loss: 309.7336\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 52ms/step - loss: 1498.3470 - val_loss: 1522.9791\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1480.3359 - val_loss: 1505.1921\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 1461.7009 - val_loss: 1486.5989\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1442.2286 - val_loss: 1466.7620\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1421.3593 - val_loss: 1445.8779\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 5ms/step - loss: 1399.6320 - val_loss: 1423.4569\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1376.4424 - val_loss: 1399.6063\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1351.9299 - val_loss: 1374.7975\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1326.5934 - val_loss: 1348.2728\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1299.9297 - val_loss: 1320.6011\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1271.9412 - val_loss: 1292.4054\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1243.3442 - val_loss: 1262.6223\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1213.4116 - val_loss: 1232.3414\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1182.9642 - val_loss: 1199.9895\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 5ms/step - loss: 1151.2898 - val_loss: 1167.4277\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1119.4962 - val_loss: 1134.3936\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1086.9529 - val_loss: 1100.7123\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1053.6083 - val_loss: 1066.8374\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1020.0696 - val_loss: 1032.4377\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 986.3383 - val_loss: 996.8487\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 951.6085 - val_loss: 962.3639\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 5ms/step - loss: 917.5803 - val_loss: 927.4195\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 883.7696 - val_loss: 892.0004\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 849.2543 - val_loss: 857.6757\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 815.4250 - val_loss: 823.2632\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 7ms/step - loss: 781.9971 - val_loss: 788.9365\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 5ms/step - loss: 749.0452 - val_loss: 755.2548\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 716.2523 - val_loss: 723.2700\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 684.7980 - val_loss: 690.8847\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 653.7432 - val_loss: 659.1736\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 623.2664 - val_loss: 629.0789\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 593.9042 - val_loss: 600.3195\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 565.8054 - val_loss: 572.6130\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 539.0471 - val_loss: 544.8806\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 512.6494 - val_loss: 519.1422\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 487.5320 - val_loss: 495.1356\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 463.9395 - val_loss: 471.9270\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 441.3655 - val_loss: 450.5781\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 420.2914 - val_loss: 429.9640\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 400.2518 - val_loss: 410.9520\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 381.4280 - val_loss: 393.2916\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 363.9294 - val_loss: 376.7187\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 347.3543 - val_loss: 361.4798\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 332.1746 - val_loss: 347.4329\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 318.0691 - val_loss: 334.3381\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 304.8978 - val_loss: 322.7602\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 292.9474 - val_loss: 312.0994\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 281.9118 - val_loss: 301.8616\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 271.5314 - val_loss: 292.9714\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 262.2669 - val_loss: 284.7332\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1496.1371 - val_loss: 1519.2749\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1478.9948 - val_loss: 1501.7303\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1461.8986 - val_loss: 1483.7031\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1443.9021 - val_loss: 1465.0537\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1425.2130 - val_loss: 1445.3325\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1405.2664 - val_loss: 1424.2032\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1384.4391 - val_loss: 1401.9138\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1362.2838 - val_loss: 1378.7968\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1338.8680 - val_loss: 1354.3164\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1314.5249 - val_loss: 1328.0981\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1288.9054 - val_loss: 1301.2661\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1262.3118 - val_loss: 1273.5345\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1234.8856 - val_loss: 1244.6843\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1206.0411 - val_loss: 1215.5269\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1176.9843 - val_loss: 1184.5154\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 1146.6132 - val_loss: 1153.0527\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 8ms/step - loss: 1115.5100 - val_loss: 1121.4116\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 13ms/step - loss: 1084.0919 - val_loss: 1088.5087\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 1052.0623 - val_loss: 1055.5924\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1019.5986 - val_loss: 1022.2831\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 987.2358 - val_loss: 988.2607\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 9ms/step - loss: 953.6850 - val_loss: 955.2631\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 11ms/step - loss: 921.1130 - val_loss: 921.6398\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 887.9944 - val_loss: 888.5651\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 855.3641 - val_loss: 854.7740\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 13ms/step - loss: 822.4474 - val_loss: 821.9825\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 9ms/step - loss: 790.1611 - val_loss: 788.6606\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 11ms/step - loss: 757.9113 - val_loss: 757.4132\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 726.7928 - val_loss: 725.7626\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 695.7378 - val_loss: 695.0953\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 665.7172 - val_loss: 664.6216\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 635.9453 - val_loss: 635.4406\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 607.1207 - val_loss: 607.2625\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 579.5088 - val_loss: 579.2462\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 551.8464 - val_loss: 553.2711\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 525.9036 - val_loss: 527.6647\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 500.7214 - val_loss: 502.9954\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 7ms/step - loss: 476.5052 - val_loss: 480.2580\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 453.6041 - val_loss: 458.9107\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 432.1100 - val_loss: 437.8070\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 411.4205 - val_loss: 418.5204\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 391.9800 - val_loss: 400.3415\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 5ms/step - loss: 373.6486 - val_loss: 383.5149\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 356.4786 - val_loss: 367.9890\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 340.6125 - val_loss: 353.4293\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 325.8669 - val_loss: 339.9011\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 311.8546 - val_loss: 327.7322\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 299.0711 - val_loss: 317.0130\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 287.6315 - val_loss: 306.7664\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 5ms/step - loss: 276.6455 - val_loss: 297.4771\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1615.2809 - val_loss: 1643.8260\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1597.6250 - val_loss: 1625.7267\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1581.1309 - val_loss: 1608.8470\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1565.7743 - val_loss: 1592.6904\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1551.1993 - val_loss: 1577.3464\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1537.4424 - val_loss: 1562.2173\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 5ms/step - loss: 1523.8741 - val_loss: 1547.7968\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1510.8499 - val_loss: 1533.5298\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1497.9867 - val_loss: 1519.3712\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1484.9752 - val_loss: 1505.1161\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1471.8964 - val_loss: 1489.9668\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1458.1981 - val_loss: 1474.4166\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1444.1652 - val_loss: 1458.3711\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 5ms/step - loss: 1429.5425 - val_loss: 1441.8511\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1414.1044 - val_loss: 1424.6643\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1398.2081 - val_loss: 1406.6797\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 1381.4982 - val_loss: 1388.2228\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 1364.3201 - val_loss: 1369.0259\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 7ms/step - loss: 1346.3910 - val_loss: 1349.3771\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1327.7980 - val_loss: 1329.1355\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1308.5789 - val_loss: 1308.7291\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1289.0343 - val_loss: 1287.6981\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 1269.2576 - val_loss: 1265.6842\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1248.4652 - val_loss: 1244.4196\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1227.7163 - val_loss: 1222.6821\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 1206.8138 - val_loss: 1200.3995\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 1185.3132 - val_loss: 1178.1335\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 1163.9141 - val_loss: 1155.7231\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 1142.3452 - val_loss: 1133.3020\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 1120.8087 - val_loss: 1110.6840\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 1099.2018 - val_loss: 1088.4803\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 1077.5826 - val_loss: 1066.6063\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 1056.2953 - val_loss: 1044.4056\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 1034.7544 - val_loss: 1023.1995\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 1013.6547 - val_loss: 1001.8691\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 992.6424 - val_loss: 980.2415\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 971.4212 - val_loss: 959.8152\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 951.1409 - val_loss: 939.1335\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 930.6099 - val_loss: 918.7772\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 910.3366 - val_loss: 899.0460\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 890.4050 - val_loss: 879.5059\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 870.9103 - val_loss: 860.8135\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 852.0861 - val_loss: 841.3976\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 833.1114 - val_loss: 823.2983\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 814.5657 - val_loss: 805.5715\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 7ms/step - loss: 796.6573 - val_loss: 788.0652\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 778.8647 - val_loss: 771.1515\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 761.5666 - val_loss: 754.5791\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 744.7432 - val_loss: 738.3736\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 728.3502 - val_loss: 722.1719\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 58ms/step - loss: 1520.8826 - val_loss: 1545.1564\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1504.7666 - val_loss: 1527.4397\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 12ms/step - loss: 1488.5603 - val_loss: 1509.8313\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 11ms/step - loss: 1472.0121 - val_loss: 1491.7952\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1455.1503 - val_loss: 1473.0463\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1437.6857 - val_loss: 1453.7516\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1419.5160 - val_loss: 1433.7185\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1400.6917 - val_loss: 1412.6520\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1380.8859 - val_loss: 1390.8528\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1360.0405 - val_loss: 1368.1276\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1338.1738 - val_loss: 1343.7039\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 7ms/step - loss: 1314.7554 - val_loss: 1318.3738\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1290.1509 - val_loss: 1292.1528\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1264.3137 - val_loss: 1264.4229\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1236.8550 - val_loss: 1235.2679\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1208.2336 - val_loss: 1204.5376\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1177.9917 - val_loss: 1173.0115\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1146.4098 - val_loss: 1140.6431\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 1114.1018 - val_loss: 1106.8235\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 1079.9078 - val_loss: 1073.3381\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 1045.6288 - val_loss: 1038.0326\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1010.3220 - val_loss: 1001.7419\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 973.8553 - val_loss: 965.4869\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 937.1130 - val_loss: 929.1891\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 900.1863 - val_loss: 893.2115\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 863.9643 - val_loss: 856.0102\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 826.7484 - val_loss: 820.1658\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 790.1827 - val_loss: 784.4206\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 754.2585 - val_loss: 748.8091\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 7ms/step - loss: 718.4491 - val_loss: 714.8679\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 683.6089 - val_loss: 681.3934\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 649.3069 - val_loss: 648.8548\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 5ms/step - loss: 616.4575 - val_loss: 616.6326\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 584.0229 - val_loss: 586.3481\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 552.9854 - val_loss: 558.0422\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 7ms/step - loss: 524.0478 - val_loss: 529.8978\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 495.7151 - val_loss: 503.3128\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 468.7303 - val_loss: 478.5254\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 443.4616 - val_loss: 454.9482\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 419.6309 - val_loss: 433.1373\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 397.2154 - val_loss: 413.0533\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 376.4804 - val_loss: 393.6341\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 356.6581 - val_loss: 376.0637\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 338.8991 - val_loss: 359.5554\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 322.0477 - val_loss: 345.1509\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 7ms/step - loss: 306.9709 - val_loss: 331.8410\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 292.8644 - val_loss: 319.7906\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 280.1804 - val_loss: 308.3834\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 7ms/step - loss: 268.5178 - val_loss: 298.3468\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 258.1379 - val_loss: 288.7714\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1551.3008 - val_loss: 1581.2578\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1537.8481 - val_loss: 1566.8726\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1524.4216 - val_loss: 1552.1813\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1510.3380 - val_loss: 1536.9287\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1495.5967 - val_loss: 1520.8768\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1480.0826 - val_loss: 1503.7599\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1463.5759 - val_loss: 1485.4351\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1445.6083 - val_loss: 1466.1527\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 1426.6177 - val_loss: 1445.3174\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1406.0719 - val_loss: 1422.8029\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 7ms/step - loss: 1383.9266 - val_loss: 1398.7788\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 1360.3051 - val_loss: 1373.2222\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1335.0251 - val_loss: 1346.2727\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1308.3784 - val_loss: 1317.1376\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1279.9884 - val_loss: 1286.6864\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1250.4146 - val_loss: 1255.3489\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1219.6294 - val_loss: 1222.1394\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1187.8096 - val_loss: 1188.5840\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 1155.0100 - val_loss: 1154.2639\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 8ms/step - loss: 1121.8601 - val_loss: 1118.6360\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 1087.5187 - val_loss: 1082.1918\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 13ms/step - loss: 1052.2972 - val_loss: 1045.6792\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 1017.0724 - val_loss: 1008.0476\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 13ms/step - loss: 980.6136 - val_loss: 971.0186\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 944.7733 - val_loss: 933.0433\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 7ms/step - loss: 908.2336 - val_loss: 895.2948\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 871.6428 - val_loss: 857.6948\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 14ms/step - loss: 835.2853 - val_loss: 820.2604\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 12ms/step - loss: 799.1864 - val_loss: 783.6537\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 763.3315 - val_loss: 747.6874\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 12ms/step - loss: 728.1110 - val_loss: 712.4394\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 693.9783 - val_loss: 677.8741\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 660.5968 - val_loss: 644.6511\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 627.9992 - val_loss: 613.2012\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 597.1076 - val_loss: 582.4573\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 566.8680 - val_loss: 554.0532\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 538.1064 - val_loss: 527.1526\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 7ms/step - loss: 511.0476 - val_loss: 500.9102\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 484.9722 - val_loss: 476.5511\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 460.2171 - val_loss: 453.9615\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 437.1822 - val_loss: 432.7549\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 415.5251 - val_loss: 413.3173\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 395.5610 - val_loss: 395.0209\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 376.8119 - val_loss: 378.5239\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 359.2633 - val_loss: 364.0117\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 343.6857 - val_loss: 349.7915\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 328.6913 - val_loss: 337.3350\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 7ms/step - loss: 315.0483 - val_loss: 326.3699\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 302.7996 - val_loss: 315.9828\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 291.3781 - val_loss: 306.7293\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 1523.2174 - val_loss: 1551.2810\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1505.4448 - val_loss: 1532.7865\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 1487.8103 - val_loss: 1514.2947\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1470.0479 - val_loss: 1495.5465\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1452.0645 - val_loss: 1476.4873\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1433.8325 - val_loss: 1457.4443\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 5ms/step - loss: 1415.3762 - val_loss: 1437.9524\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1396.2584 - val_loss: 1418.3330\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1376.9797 - val_loss: 1397.7600\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1356.7748 - val_loss: 1376.7933\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1335.8380 - val_loss: 1355.0530\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1313.8599 - val_loss: 1332.3440\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1291.2101 - val_loss: 1308.2352\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1267.2207 - val_loss: 1283.0560\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 7ms/step - loss: 1241.9053 - val_loss: 1256.7656\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1215.5709 - val_loss: 1229.1476\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1188.4044 - val_loss: 1200.3477\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1160.2814 - val_loss: 1170.9399\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1130.8075 - val_loss: 1141.3563\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1101.2113 - val_loss: 1109.9592\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 1070.4359 - val_loss: 1078.0576\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1038.5181 - val_loss: 1046.4396\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 1006.6133 - val_loss: 1013.3933\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 973.6976 - val_loss: 980.2779\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 940.3281 - val_loss: 946.7582\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 7ms/step - loss: 906.9294 - val_loss: 911.6275\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 5ms/step - loss: 872.2430 - val_loss: 877.6855\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 837.7413 - val_loss: 843.6148\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 803.4435 - val_loss: 809.2853\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 769.2001 - val_loss: 774.8058\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 5ms/step - loss: 735.1967 - val_loss: 741.0030\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 701.5118 - val_loss: 708.8995\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 669.2258 - val_loss: 676.6876\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 637.2764 - val_loss: 646.0359\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 606.7125 - val_loss: 616.3889\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 577.1157 - val_loss: 587.3981\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 548.3818 - val_loss: 560.0071\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 521.2075 - val_loss: 533.3162\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 494.8900 - val_loss: 508.5026\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 470.0000 - val_loss: 484.9537\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 446.3458 - val_loss: 462.8307\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 424.0552 - val_loss: 441.6121\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 403.1255 - val_loss: 422.0174\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 383.4164 - val_loss: 403.7989\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 365.2794 - val_loss: 386.9633\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 7ms/step - loss: 348.3765 - val_loss: 371.4224\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 332.5667 - val_loss: 357.2576\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 5ms/step - loss: 318.0976 - val_loss: 344.5035\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 304.7809 - val_loss: 332.1984\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 292.5709 - val_loss: 321.0830\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 60ms/step - loss: 1572.1033 - val_loss: 1599.3966\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 17ms/step - loss: 1558.3140 - val_loss: 1585.2611\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 1544.9170 - val_loss: 1571.5342\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 12ms/step - loss: 1531.7819 - val_loss: 1557.5289\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 9ms/step - loss: 1518.4209 - val_loss: 1543.4484\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 9ms/step - loss: 1504.8518 - val_loss: 1528.8652\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1490.8597 - val_loss: 1513.6639\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1476.2372 - val_loss: 1497.8668\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1461.0387 - val_loss: 1480.8923\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1444.7701 - val_loss: 1463.0179\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1427.6438 - val_loss: 1443.9938\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1409.6200 - val_loss: 1423.8319\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1390.4137 - val_loss: 1402.8240\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 5ms/step - loss: 1370.2170 - val_loss: 1381.2424\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 7ms/step - loss: 1349.5684 - val_loss: 1357.8920\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 1327.5995 - val_loss: 1333.8964\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1304.9122 - val_loss: 1308.8170\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 7ms/step - loss: 1281.3080 - val_loss: 1283.4828\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 1257.1604 - val_loss: 1257.1870\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 1232.1255 - val_loss: 1230.0674\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1206.3572 - val_loss: 1202.5162\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1180.0925 - val_loss: 1174.4041\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 5ms/step - loss: 1153.1842 - val_loss: 1145.7898\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 1126.2106 - val_loss: 1116.2633\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1098.4117 - val_loss: 1087.0829\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 1070.3451 - val_loss: 1057.8235\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 1042.2559 - val_loss: 1027.6329\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 1013.1720 - val_loss: 998.4594\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 7ms/step - loss: 984.6170 - val_loss: 967.9186\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 955.1609 - val_loss: 937.6381\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 925.5502 - val_loss: 907.9147\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 895.9999 - val_loss: 877.5571\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 865.8734 - val_loss: 847.1970\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 835.3273 - val_loss: 816.9851\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 804.5828 - val_loss: 786.4670\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 773.4410 - val_loss: 755.9621\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 742.3058 - val_loss: 725.7505\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 710.8911 - val_loss: 695.3981\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 679.4496 - val_loss: 665.1623\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 648.3011 - val_loss: 635.1333\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 617.3362 - val_loss: 606.1168\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 587.6559 - val_loss: 577.9551\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 558.7510 - val_loss: 551.4851\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 531.2209 - val_loss: 525.6384\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 504.0635 - val_loss: 501.7857\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 478.7022 - val_loss: 478.3365\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 454.4873 - val_loss: 455.7763\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 431.0930 - val_loss: 435.1059\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 409.1363 - val_loss: 415.2118\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 388.3142 - val_loss: 396.8000\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 1548.7124 - val_loss: 1579.1169\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1534.9071 - val_loss: 1565.4923\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1521.6262 - val_loss: 1551.8361\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 7ms/step - loss: 1508.3433 - val_loss: 1538.0626\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 5ms/step - loss: 1494.7562 - val_loss: 1523.9316\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 5ms/step - loss: 1480.6139 - val_loss: 1508.9723\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1465.7034 - val_loss: 1492.8658\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 8ms/step - loss: 1449.5817 - val_loss: 1475.3600\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1431.9818 - val_loss: 1456.5129\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1412.8676 - val_loss: 1435.3475\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 7ms/step - loss: 1391.6030 - val_loss: 1412.7111\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 1368.6627 - val_loss: 1388.0861\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1343.6234 - val_loss: 1361.9393\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1317.4229 - val_loss: 1333.8513\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 7ms/step - loss: 1289.3485 - val_loss: 1304.8478\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1260.4642 - val_loss: 1273.9343\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1229.8240 - val_loss: 1242.8695\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1198.9896 - val_loss: 1210.3523\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1166.5018 - val_loss: 1177.7216\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1134.0624 - val_loss: 1143.5295\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1100.1111 - val_loss: 1109.3999\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 8ms/step - loss: 1066.5160 - val_loss: 1074.5085\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 12ms/step - loss: 1032.5453 - val_loss: 1039.3741\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 998.2003 - val_loss: 1005.3724\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 7ms/step - loss: 964.5181 - val_loss: 970.8875\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 12ms/step - loss: 930.8779 - val_loss: 936.4814\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 897.6353 - val_loss: 902.2708\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 7ms/step - loss: 864.0736 - val_loss: 869.2209\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 13ms/step - loss: 831.5712 - val_loss: 836.4420\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 13ms/step - loss: 799.9322 - val_loss: 803.8242\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 13ms/step - loss: 768.5356 - val_loss: 772.3208\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 738.3300 - val_loss: 741.6933\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 708.7628 - val_loss: 712.0248\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 680.2510 - val_loss: 682.8846\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 652.0549 - val_loss: 654.8065\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 625.3770 - val_loss: 627.2124\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 599.0871 - val_loss: 601.2971\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 574.3262 - val_loss: 576.1085\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 550.3783 - val_loss: 551.8504\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 527.1255 - val_loss: 529.1066\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 505.4617 - val_loss: 506.8686\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 484.5081 - val_loss: 486.2114\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 464.7195 - val_loss: 466.2852\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 445.8822 - val_loss: 447.7557\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 427.9905 - val_loss: 430.2941\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 411.4493 - val_loss: 413.6909\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 395.7029 - val_loss: 398.3392\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 5ms/step - loss: 381.0582 - val_loss: 384.3521\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 367.4611 - val_loss: 370.9931\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 5ms/step - loss: 354.6109 - val_loss: 358.8195\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 1516.0995 - val_loss: 1542.7965\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1501.2949 - val_loss: 1527.5824\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1486.5524 - val_loss: 1511.8867\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1471.4600 - val_loss: 1496.1084\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 5ms/step - loss: 1455.8911 - val_loss: 1480.0466\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 5ms/step - loss: 1439.7701 - val_loss: 1463.0244\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1422.7679 - val_loss: 1444.9500\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 5ms/step - loss: 1404.6490 - val_loss: 1425.7164\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 1385.3136 - val_loss: 1405.1012\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 5ms/step - loss: 1364.4683 - val_loss: 1383.0261\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1342.1631 - val_loss: 1359.1614\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1318.2783 - val_loss: 1333.6146\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1292.5396 - val_loss: 1306.7186\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1265.4414 - val_loss: 1277.7881\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1236.5094 - val_loss: 1247.7437\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1206.4738 - val_loss: 1216.0630\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1174.7555 - val_loss: 1183.1707\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1142.0454 - val_loss: 1148.6875\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1108.1693 - val_loss: 1113.0547\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 1072.6895 - val_loss: 1077.3264\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 1036.6514 - val_loss: 1040.7473\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 7ms/step - loss: 999.9980 - val_loss: 1002.7811\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 962.8098 - val_loss: 965.1832\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 925.6204 - val_loss: 927.4926\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 888.3954 - val_loss: 889.7679\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 851.2713 - val_loss: 852.8630\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 814.1772 - val_loss: 816.1279\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 778.2352 - val_loss: 779.1059\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 742.1714 - val_loss: 743.9611\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 707.1969 - val_loss: 709.7567\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 673.3024 - val_loss: 676.9515\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 640.9753 - val_loss: 644.3638\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 609.1722 - val_loss: 613.1719\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 578.9321 - val_loss: 583.5745\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 549.8939 - val_loss: 555.6081\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 521.9843 - val_loss: 529.6888\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 496.2998 - val_loss: 503.7375\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 471.3543 - val_loss: 479.6739\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 447.6047 - val_loss: 457.0455\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 425.4893 - val_loss: 435.2920\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 404.3053 - val_loss: 415.4889\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 384.8946 - val_loss: 396.6890\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 366.5994 - val_loss: 379.3040\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 349.5169 - val_loss: 363.2961\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 333.7879 - val_loss: 348.1889\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 318.9992 - val_loss: 334.7475\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 305.5346 - val_loss: 322.1351\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 292.9791 - val_loss: 310.3526\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 281.4793 - val_loss: 299.6938\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 8ms/step - loss: 270.8448 - val_loss: 289.7270\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 58ms/step - loss: 1545.3564 - val_loss: 1581.1787\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 6ms/step - loss: 1529.4514 - val_loss: 1565.0549\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1513.5111 - val_loss: 1549.0244\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1497.1781 - val_loss: 1533.0396\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 8ms/step - loss: 1480.5273 - val_loss: 1516.2787\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 13ms/step - loss: 1463.0576 - val_loss: 1498.7798\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 10ms/step - loss: 1444.7507 - val_loss: 1480.3474\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 7ms/step - loss: 1425.5824 - val_loss: 1460.5562\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1405.1171 - val_loss: 1440.2316\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 7ms/step - loss: 1383.6364 - val_loss: 1418.6157\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 5ms/step - loss: 1361.1113 - val_loss: 1395.6031\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1337.2439 - val_loss: 1372.0975\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1312.8795 - val_loss: 1347.2815\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1287.3059 - val_loss: 1321.1788\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1260.9263 - val_loss: 1294.6195\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 1233.5138 - val_loss: 1267.0693\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1205.3481 - val_loss: 1238.4689\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 1176.3193 - val_loss: 1208.8352\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 1146.6595 - val_loss: 1178.4940\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 1116.7053 - val_loss: 1147.6938\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 1086.0076 - val_loss: 1117.1936\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1055.2415 - val_loss: 1086.0806\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1024.2391 - val_loss: 1054.1731\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 993.1053 - val_loss: 1022.4263\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 7ms/step - loss: 961.9946 - val_loss: 990.3111\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 930.6135 - val_loss: 959.1667\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 899.7189 - val_loss: 927.7924\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 868.8967 - val_loss: 896.3145\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 7ms/step - loss: 838.4381 - val_loss: 865.1790\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 808.0585 - val_loss: 835.1322\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 778.8760 - val_loss: 805.1377\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 749.9804 - val_loss: 775.8466\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 721.4783 - val_loss: 747.0703\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 693.7106 - val_loss: 719.0605\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 666.9051 - val_loss: 691.7932\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 640.8018 - val_loss: 665.6882\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 615.5610 - val_loss: 640.4851\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 591.0895 - val_loss: 615.7635\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 567.5297 - val_loss: 592.2654\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 544.9437 - val_loss: 569.7820\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 5ms/step - loss: 523.3405 - val_loss: 548.1207\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 502.7195 - val_loss: 527.6686\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 482.9380 - val_loss: 508.2130\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 464.3640 - val_loss: 489.5053\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 446.6638 - val_loss: 471.8147\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 429.6379 - val_loss: 455.6714\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 413.8995 - val_loss: 440.0160\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 398.7008 - val_loss: 425.4760\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 384.5690 - val_loss: 411.1783\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 370.8664 - val_loss: 398.0318\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 1549.2833 - val_loss: 1587.9293\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1532.7578 - val_loss: 1571.1600\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1516.5480 - val_loss: 1554.9584\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1500.8444 - val_loss: 1538.6261\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1484.8923 - val_loss: 1522.7202\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1469.1626 - val_loss: 1506.6310\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1453.2292 - val_loss: 1490.4839\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1436.8752 - val_loss: 1473.9755\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1419.9349 - val_loss: 1457.2374\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 7ms/step - loss: 1402.7104 - val_loss: 1439.6722\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1384.5181 - val_loss: 1421.6108\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1365.7540 - val_loss: 1402.3748\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1345.8778 - val_loss: 1382.3662\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1324.8918 - val_loss: 1361.6357\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1303.3623 - val_loss: 1339.7615\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 5ms/step - loss: 1280.5383 - val_loss: 1317.3217\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1256.7875 - val_loss: 1293.5624\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 1232.1467 - val_loss: 1268.6312\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1206.6965 - val_loss: 1243.1896\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 1180.3832 - val_loss: 1216.3558\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1152.9241 - val_loss: 1188.5687\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 5ms/step - loss: 1124.3833 - val_loss: 1159.5380\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1094.9336 - val_loss: 1129.1017\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 7ms/step - loss: 1064.0731 - val_loss: 1098.5302\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1032.6173 - val_loss: 1066.4967\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 1000.4301 - val_loss: 1032.7120\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 13ms/step - loss: 966.6824 - val_loss: 999.0015\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 932.7752 - val_loss: 963.5802\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 7ms/step - loss: 897.9263 - val_loss: 928.2506\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 7ms/step - loss: 862.9404 - val_loss: 892.8128\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 828.0173 - val_loss: 857.6591\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 793.1625 - val_loss: 822.1196\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 758.3776 - val_loss: 786.5954\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 724.1491 - val_loss: 751.0958\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 690.0147 - val_loss: 716.3762\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 656.6873 - val_loss: 682.0444\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 13ms/step - loss: 623.9802 - val_loss: 648.4129\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 592.3892 - val_loss: 616.1912\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 561.6398 - val_loss: 585.1048\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 11ms/step - loss: 532.3692 - val_loss: 554.5450\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 504.0560 - val_loss: 525.0328\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 477.1182 - val_loss: 497.1401\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 451.5102 - val_loss: 471.0671\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 427.3647 - val_loss: 446.3069\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 404.7502 - val_loss: 422.3251\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 382.8871 - val_loss: 400.9651\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 363.1937 - val_loss: 380.1708\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 343.9492 - val_loss: 362.4425\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 327.4344 - val_loss: 344.4638\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 311.2833 - val_loss: 328.9006\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1583.2987 - val_loss: 1606.0416\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1565.7817 - val_loss: 1588.2347\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1548.6348 - val_loss: 1571.0077\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1532.2771 - val_loss: 1553.4896\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1515.6849 - val_loss: 1536.4669\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1499.4480 - val_loss: 1519.1748\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 7ms/step - loss: 1482.9558 - val_loss: 1501.9875\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 5ms/step - loss: 1466.4723 - val_loss: 1484.5988\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1449.8265 - val_loss: 1467.0431\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1432.8601 - val_loss: 1449.0006\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1415.7352 - val_loss: 1430.1185\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1397.9875 - val_loss: 1411.3408\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1379.9817 - val_loss: 1392.2910\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1361.6857 - val_loss: 1372.4176\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1342.4989 - val_loss: 1352.7445\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1323.4093 - val_loss: 1332.1321\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1303.5312 - val_loss: 1311.0134\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1283.1350 - val_loss: 1289.6902\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 1262.3927 - val_loss: 1267.5256\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 1240.9806 - val_loss: 1245.4521\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 1219.3910 - val_loss: 1222.8759\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1197.5779 - val_loss: 1199.6343\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 1174.9956 - val_loss: 1176.4064\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 5ms/step - loss: 1152.2692 - val_loss: 1152.7424\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1129.0050 - val_loss: 1129.1639\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 1105.7451 - val_loss: 1104.8330\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 5ms/step - loss: 1081.4839 - val_loss: 1080.2679\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 1057.2399 - val_loss: 1055.4236\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 1032.5280 - val_loss: 1029.9055\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 1007.2737 - val_loss: 1005.0233\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 982.5728 - val_loss: 979.6773\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 957.3439 - val_loss: 955.0964\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 932.7869 - val_loss: 929.8680\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 907.5670 - val_loss: 905.1660\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 882.5913 - val_loss: 880.2964\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 857.7818 - val_loss: 855.4976\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 833.0400 - val_loss: 830.9232\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 807.7941 - val_loss: 806.3767\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 782.9521 - val_loss: 781.3649\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 757.6258 - val_loss: 756.8066\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 732.5914 - val_loss: 731.9144\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 5ms/step - loss: 706.8193 - val_loss: 707.6255\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 681.4763 - val_loss: 682.7552\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 655.9220 - val_loss: 658.1094\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 630.6812 - val_loss: 634.0159\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 605.5924 - val_loss: 610.4993\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 581.0645 - val_loss: 586.7753\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 556.3750 - val_loss: 564.4488\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 532.5298 - val_loss: 542.2188\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 509.2459 - val_loss: 520.6184\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 47ms/step - loss: 1514.8287 - val_loss: 1549.9512\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 18ms/step - loss: 1497.5928 - val_loss: 1532.4481\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 13ms/step - loss: 1479.8635 - val_loss: 1514.2963\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 7ms/step - loss: 1461.4261 - val_loss: 1495.3213\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 13ms/step - loss: 1442.3412 - val_loss: 1474.9438\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 7ms/step - loss: 1421.7969 - val_loss: 1453.9945\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 13ms/step - loss: 1400.3330 - val_loss: 1431.8057\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 11ms/step - loss: 1377.5742 - val_loss: 1407.8726\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1353.5181 - val_loss: 1382.2792\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 3ms/step - loss: 1327.7257 - val_loss: 1356.3694\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1301.2258 - val_loss: 1328.1288\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1273.0626 - val_loss: 1299.4214\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1244.1637 - val_loss: 1268.8652\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1213.5779 - val_loss: 1237.9602\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1182.2516 - val_loss: 1205.6088\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 1150.2858 - val_loss: 1172.3090\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1117.1411 - val_loss: 1138.6155\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 7ms/step - loss: 1083.6420 - val_loss: 1103.9796\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1049.1627 - val_loss: 1069.4926\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1014.7717 - val_loss: 1033.7560\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 979.7776 - val_loss: 997.6620\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 944.5067 - val_loss: 961.4592\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 909.0756 - val_loss: 925.3849\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 874.0726 - val_loss: 889.8644\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 839.4153 - val_loss: 853.9277\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 7ms/step - loss: 805.0973 - val_loss: 818.7082\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 771.3620 - val_loss: 784.2933\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 738.6381 - val_loss: 750.6207\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 705.6970 - val_loss: 717.9563\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 674.3584 - val_loss: 685.2698\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 643.4133 - val_loss: 654.4730\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 614.0114 - val_loss: 623.7994\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 585.3145 - val_loss: 594.7178\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 557.7141 - val_loss: 566.9897\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 531.3226 - val_loss: 540.6683\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 506.0986 - val_loss: 515.1005\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 481.9873 - val_loss: 490.7300\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 459.1070 - val_loss: 467.6978\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 437.5724 - val_loss: 446.4518\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 417.2106 - val_loss: 426.4813\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 398.3324 - val_loss: 407.1656\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 380.1623 - val_loss: 389.4108\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 363.2267 - val_loss: 373.1245\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 347.5306 - val_loss: 358.0244\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 332.8039 - val_loss: 343.6862\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 7ms/step - loss: 319.3338 - val_loss: 330.3103\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 306.2491 - val_loss: 318.3873\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 294.2021 - val_loss: 307.0484\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 7ms/step - loss: 283.1629 - val_loss: 296.2517\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 272.6796 - val_loss: 287.0515\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1552.2784 - val_loss: 1575.8192\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1535.6819 - val_loss: 1559.9907\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1519.5707 - val_loss: 1544.0410\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1503.1127 - val_loss: 1528.1519\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1486.6030 - val_loss: 1511.8268\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1469.7462 - val_loss: 1494.8751\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1452.2965 - val_loss: 1477.5623\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1434.2261 - val_loss: 1459.3584\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1415.2377 - val_loss: 1440.2847\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 5ms/step - loss: 1395.7765 - val_loss: 1419.9240\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 7ms/step - loss: 1374.8093 - val_loss: 1399.1254\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1353.2241 - val_loss: 1376.6406\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1330.2626 - val_loss: 1353.1761\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 1306.3136 - val_loss: 1328.1713\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1281.0251 - val_loss: 1302.8210\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 1255.3485 - val_loss: 1275.2819\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1227.9489 - val_loss: 1247.1384\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1199.5645 - val_loss: 1218.2806\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1170.7373 - val_loss: 1188.9902\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1141.4062 - val_loss: 1158.3412\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1111.1637 - val_loss: 1127.6652\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 1080.6305 - val_loss: 1096.2350\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 1049.3615 - val_loss: 1064.5857\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 1018.2047 - val_loss: 1032.3291\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 986.6516 - val_loss: 1000.5259\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 955.2032 - val_loss: 968.2012\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 923.5035 - val_loss: 936.1860\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 7ms/step - loss: 892.0965 - val_loss: 904.7629\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 861.1494 - val_loss: 873.1299\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 830.0576 - val_loss: 842.2607\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 799.4953 - val_loss: 811.8687\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 7ms/step - loss: 769.9233 - val_loss: 781.7405\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 12ms/step - loss: 740.3855 - val_loss: 752.9609\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 712.0745 - val_loss: 723.6294\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 7ms/step - loss: 683.8804 - val_loss: 695.5463\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 656.5104 - val_loss: 668.5070\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 8ms/step - loss: 630.1315 - val_loss: 642.1049\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 11ms/step - loss: 604.5568 - val_loss: 616.3610\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 15ms/step - loss: 579.3651 - val_loss: 591.8919\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 11ms/step - loss: 555.8226 - val_loss: 567.5055\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 532.4146 - val_loss: 545.1455\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 510.4317 - val_loss: 524.0128\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 489.4370 - val_loss: 503.2855\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 469.4348 - val_loss: 483.2539\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 450.0061 - val_loss: 464.4601\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 7ms/step - loss: 431.7275 - val_loss: 446.8799\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 414.2753 - val_loss: 429.6455\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 397.5923 - val_loss: 413.8638\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 382.1665 - val_loss: 398.3052\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 367.1980 - val_loss: 384.3527\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1540.5701 - val_loss: 1572.1440\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1525.0956 - val_loss: 1556.3604\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1509.3944 - val_loss: 1540.2926\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1493.4747 - val_loss: 1523.6886\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 7ms/step - loss: 1476.9628 - val_loss: 1506.5757\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1459.9141 - val_loss: 1489.0367\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1442.3871 - val_loss: 1470.4650\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1423.9834 - val_loss: 1451.3304\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1404.7815 - val_loss: 1431.5637\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 7ms/step - loss: 1384.8822 - val_loss: 1410.9740\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 5ms/step - loss: 1364.2616 - val_loss: 1389.3713\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1342.5896 - val_loss: 1366.8334\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1320.0447 - val_loss: 1343.0056\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1296.3000 - val_loss: 1318.5155\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 5ms/step - loss: 1271.8351 - val_loss: 1293.1761\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 5ms/step - loss: 1246.6830 - val_loss: 1266.5754\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1220.5355 - val_loss: 1239.2260\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1193.7581 - val_loss: 1210.8579\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1166.1827 - val_loss: 1182.0178\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1137.6432 - val_loss: 1153.1440\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1108.8887 - val_loss: 1122.7679\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1079.3260 - val_loss: 1091.8945\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 1049.2737 - val_loss: 1061.0153\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 7ms/step - loss: 1019.0852 - val_loss: 1029.9510\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 988.7249 - val_loss: 998.4547\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 958.0167 - val_loss: 966.8324\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 927.3685 - val_loss: 935.1995\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 896.4570 - val_loss: 903.3738\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 865.5506 - val_loss: 871.8870\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 834.8657 - val_loss: 841.1633\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 5ms/step - loss: 804.7218 - val_loss: 810.4276\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 774.8391 - val_loss: 779.7695\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 744.8185 - val_loss: 750.3761\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 715.7064 - val_loss: 720.9724\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 687.3130 - val_loss: 692.5939\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 659.5508 - val_loss: 664.9692\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 632.6805 - val_loss: 637.5942\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 7ms/step - loss: 606.2280 - val_loss: 612.0588\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 580.9077 - val_loss: 587.3734\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 556.8069 - val_loss: 563.0395\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 533.2321 - val_loss: 540.1789\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 510.9052 - val_loss: 518.1484\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 489.3642 - val_loss: 497.0092\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 468.5294 - val_loss: 477.4655\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 449.1767 - val_loss: 457.7500\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 430.3022 - val_loss: 439.1062\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 412.2712 - val_loss: 422.0463\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 395.3850 - val_loss: 405.4558\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 379.1593 - val_loss: 390.3296\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 364.0989 - val_loss: 375.4854\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 90ms/step - loss: 1529.1565 - val_loss: 1567.9615\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 6ms/step - loss: 1509.6195 - val_loss: 1548.6842\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 8ms/step - loss: 1489.3010 - val_loss: 1528.7356\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 12ms/step - loss: 1468.5717 - val_loss: 1507.7197\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 14ms/step - loss: 1446.7997 - val_loss: 1486.2321\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 13ms/step - loss: 1424.4941 - val_loss: 1463.3231\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 11ms/step - loss: 1401.2802 - val_loss: 1439.1796\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 5ms/step - loss: 1376.8501 - val_loss: 1414.5033\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1351.6890 - val_loss: 1388.8276\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1325.8469 - val_loss: 1361.9694\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1298.8452 - val_loss: 1334.1849\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 1271.1455 - val_loss: 1305.8883\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1242.7089 - val_loss: 1276.6025\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1213.2095 - val_loss: 1246.2035\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 5ms/step - loss: 1182.8584 - val_loss: 1215.0375\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 5ms/step - loss: 1151.8024 - val_loss: 1183.3688\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1119.9412 - val_loss: 1151.0609\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1087.9648 - val_loss: 1117.6160\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1055.3867 - val_loss: 1084.0648\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 1022.2489 - val_loss: 1050.4438\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 988.7657 - val_loss: 1016.7486\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 955.5128 - val_loss: 982.1801\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 921.8441 - val_loss: 947.8136\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 5ms/step - loss: 888.3936 - val_loss: 913.1201\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 854.3387 - val_loss: 879.4202\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 821.4106 - val_loss: 845.5482\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 789.0754 - val_loss: 812.2031\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 756.5807 - val_loss: 780.7005\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 725.5789 - val_loss: 748.6315\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 694.8981 - val_loss: 717.5028\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 7ms/step - loss: 664.7365 - val_loss: 687.7925\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 635.6364 - val_loss: 659.1551\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 607.6519 - val_loss: 630.7078\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 580.1636 - val_loss: 603.6052\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 553.8481 - val_loss: 576.9445\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 528.0850 - val_loss: 552.1958\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 503.8984 - val_loss: 528.1143\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 480.7898 - val_loss: 504.6342\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 458.4367 - val_loss: 482.9287\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 437.3073 - val_loss: 462.5064\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 417.4372 - val_loss: 443.0279\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 398.5575 - val_loss: 424.7886\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 380.9363 - val_loss: 407.6858\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 364.1242 - val_loss: 391.7249\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 348.4489 - val_loss: 376.6634\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 334.0097 - val_loss: 362.7697\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 320.0448 - val_loss: 350.2281\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 5ms/step - loss: 307.5863 - val_loss: 338.0270\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 295.5262 - val_loss: 327.2048\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 284.4709 - val_loss: 316.6817\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 43ms/step - loss: 1568.0800 - val_loss: 1603.9648\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1550.9980 - val_loss: 1586.0955\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1534.2802 - val_loss: 1568.7246\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 7ms/step - loss: 1517.9558 - val_loss: 1551.7483\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 5ms/step - loss: 1501.8374 - val_loss: 1534.8389\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1485.9723 - val_loss: 1517.7715\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1469.8040 - val_loss: 1500.9125\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1453.4709 - val_loss: 1483.7747\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 5ms/step - loss: 1436.6138 - val_loss: 1466.2609\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1419.5710 - val_loss: 1447.6967\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1401.4984 - val_loss: 1428.8884\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1382.9999 - val_loss: 1409.2515\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1363.8829 - val_loss: 1388.6095\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1343.7164 - val_loss: 1367.7352\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1323.1158 - val_loss: 1346.1145\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1301.6550 - val_loss: 1323.7418\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1279.7445 - val_loss: 1300.0909\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 7ms/step - loss: 1256.8566 - val_loss: 1276.4023\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1233.6470 - val_loss: 1251.8182\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1209.7239 - val_loss: 1226.7061\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 1185.2096 - val_loss: 1201.1501\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 5ms/step - loss: 1160.1290 - val_loss: 1175.0745\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 1134.7827 - val_loss: 1147.8392\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 5ms/step - loss: 1108.4492 - val_loss: 1120.6074\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1082.2140 - val_loss: 1092.8845\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 1055.2603 - val_loss: 1065.1161\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 13ms/step - loss: 1028.2959 - val_loss: 1036.7556\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 7ms/step - loss: 1000.9303 - val_loss: 1007.8433\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 972.9400 - val_loss: 978.9796\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 944.8369 - val_loss: 949.2782\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 916.3069 - val_loss: 919.5629\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 887.6254 - val_loss: 889.1518\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 13ms/step - loss: 858.5576 - val_loss: 858.6050\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 12ms/step - loss: 828.9697 - val_loss: 828.7728\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 8ms/step - loss: 799.8963 - val_loss: 798.5518\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 7ms/step - loss: 770.5456 - val_loss: 768.2734\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 8ms/step - loss: 740.9036 - val_loss: 738.1180\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 8ms/step - loss: 711.5811 - val_loss: 707.7970\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 10ms/step - loss: 682.5974 - val_loss: 677.7498\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 653.4902 - val_loss: 649.2360\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 625.3630 - val_loss: 620.9531\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 597.6469 - val_loss: 593.2668\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 7ms/step - loss: 570.5297 - val_loss: 566.6524\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 5ms/step - loss: 544.2490 - val_loss: 541.5117\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 519.1696 - val_loss: 517.2644\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 495.3372 - val_loss: 493.4572\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 471.8253 - val_loss: 471.9588\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 7ms/step - loss: 449.8299 - val_loss: 451.1127\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 428.6608 - val_loss: 431.2217\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 408.4618 - val_loss: 413.0293\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 43ms/step - loss: 1569.4619 - val_loss: 1592.5962\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1548.1234 - val_loss: 1570.8761\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 1527.1769 - val_loss: 1549.1675\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1506.2148 - val_loss: 1527.4387\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1485.1682 - val_loss: 1505.6974\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 7ms/step - loss: 1463.8956 - val_loss: 1483.4437\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1442.3265 - val_loss: 1460.8582\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 8ms/step - loss: 1420.4176 - val_loss: 1437.9718\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 5ms/step - loss: 1398.2494 - val_loss: 1414.3593\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1375.4346 - val_loss: 1390.5173\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1352.1196 - val_loss: 1366.1781\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1328.5636 - val_loss: 1341.1241\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1304.3884 - val_loss: 1316.0684\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1279.9843 - val_loss: 1290.2778\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1254.7894 - val_loss: 1264.2155\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 1229.1652 - val_loss: 1237.1779\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 5ms/step - loss: 1203.1543 - val_loss: 1209.7179\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1176.2815 - val_loss: 1182.4236\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 1149.4766 - val_loss: 1154.5291\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1122.3785 - val_loss: 1125.8231\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1094.3079 - val_loss: 1097.5449\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 1066.5806 - val_loss: 1068.5969\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 1038.6117 - val_loss: 1039.4441\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1009.9479 - val_loss: 1010.7298\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 981.7313 - val_loss: 981.2316\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 953.2042 - val_loss: 952.0132\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 924.5736 - val_loss: 923.3439\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 896.3582 - val_loss: 894.7540\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 868.2280 - val_loss: 866.2719\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 840.2741 - val_loss: 837.8398\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 5ms/step - loss: 812.4175 - val_loss: 809.9713\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 784.8911 - val_loss: 782.2844\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 757.7104 - val_loss: 754.6750\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 730.6586 - val_loss: 728.3429\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 704.4673 - val_loss: 701.7119\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 678.6396 - val_loss: 675.8290\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 653.3579 - val_loss: 651.0096\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 628.8076 - val_loss: 626.6952\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 604.8385 - val_loss: 602.6746\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 581.3100 - val_loss: 579.4442\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 558.2251 - val_loss: 557.3225\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 536.2061 - val_loss: 535.5334\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 514.8207 - val_loss: 514.6424\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 494.2059 - val_loss: 494.1207\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 474.0519 - val_loss: 474.5903\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 454.7047 - val_loss: 455.8185\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 436.1946 - val_loss: 438.2716\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 418.5739 - val_loss: 421.3017\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 401.5011 - val_loss: 405.1531\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 385.4556 - val_loss: 390.0851\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 55ms/step - loss: 1578.9266 - val_loss: 1609.3594\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 6ms/step - loss: 1566.9065 - val_loss: 1596.5792\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1555.1323 - val_loss: 1583.3381\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 7ms/step - loss: 1543.1699 - val_loss: 1569.5061\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 13ms/step - loss: 1530.9152 - val_loss: 1555.3234\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 13ms/step - loss: 1518.2158 - val_loss: 1540.3444\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 13ms/step - loss: 1504.8619 - val_loss: 1524.6125\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 11ms/step - loss: 1490.5869 - val_loss: 1508.0186\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1475.5520 - val_loss: 1489.9889\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1459.3965 - val_loss: 1470.6104\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1442.0603 - val_loss: 1450.0271\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1423.7334 - val_loss: 1427.8258\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1403.9047 - val_loss: 1404.3156\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1382.5312 - val_loss: 1379.5750\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1359.9667 - val_loss: 1353.0734\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1336.1155 - val_loss: 1324.7014\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1310.5631 - val_loss: 1295.7905\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1284.0090 - val_loss: 1265.0941\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 1256.1527 - val_loss: 1233.5299\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1227.5500 - val_loss: 1200.3817\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1197.3567 - val_loss: 1167.8264\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 1166.7916 - val_loss: 1133.4674\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 1135.2162 - val_loss: 1099.0436\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1103.1653 - val_loss: 1063.9827\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1070.6855 - val_loss: 1028.7715\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 1037.6227 - val_loss: 994.1323\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 1004.7499 - val_loss: 958.7375\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 971.2692 - val_loss: 923.8554\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 7ms/step - loss: 937.5339 - val_loss: 889.4737\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 904.4134 - val_loss: 855.1313\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 870.8961 - val_loss: 821.1131\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 837.8311 - val_loss: 787.5479\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 804.8459 - val_loss: 754.7929\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 772.0380 - val_loss: 722.9659\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 740.2494 - val_loss: 692.3324\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 709.1411 - val_loss: 661.9907\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 678.8649 - val_loss: 633.0816\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 649.2818 - val_loss: 605.6664\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 621.1308 - val_loss: 578.1688\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 593.0546 - val_loss: 552.9120\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 566.6974 - val_loss: 528.2947\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 7ms/step - loss: 541.1653 - val_loss: 505.3855\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 517.0544 - val_loss: 483.4667\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 493.7007 - val_loss: 463.1190\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 471.7330 - val_loss: 443.5048\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 450.6957 - val_loss: 425.2223\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 430.9141 - val_loss: 408.0113\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 412.0303 - val_loss: 392.1831\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 394.3878 - val_loss: 377.2635\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 377.7093 - val_loss: 363.1605\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1539.2668 - val_loss: 1562.8439\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1521.2107 - val_loss: 1544.1777\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1503.6548 - val_loss: 1525.6041\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1486.1002 - val_loss: 1507.0764\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1468.3370 - val_loss: 1488.2565\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1450.4083 - val_loss: 1469.1554\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1432.0712 - val_loss: 1449.2802\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1413.0741 - val_loss: 1429.2672\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1393.7980 - val_loss: 1408.4502\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 7ms/step - loss: 1373.9176 - val_loss: 1387.0433\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1353.3241 - val_loss: 1365.1625\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1332.2250 - val_loss: 1342.3143\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1310.3595 - val_loss: 1318.8077\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 1287.8080 - val_loss: 1294.4521\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 5ms/step - loss: 1264.1610 - val_loss: 1269.6816\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1240.0193 - val_loss: 1243.7609\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1214.7990 - val_loss: 1216.9329\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 7ms/step - loss: 1188.9103 - val_loss: 1189.0969\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1161.7999 - val_loss: 1161.0492\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 1134.1445 - val_loss: 1131.8008\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1105.4418 - val_loss: 1102.0181\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1076.1049 - val_loss: 1071.6234\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1046.1172 - val_loss: 1039.8871\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1014.8671 - val_loss: 1007.7066\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 983.3636 - val_loss: 974.8331\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 7ms/step - loss: 951.2242 - val_loss: 942.4885\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 13ms/step - loss: 919.0406 - val_loss: 909.3325\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 13ms/step - loss: 886.8843 - val_loss: 875.6945\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 853.7869 - val_loss: 843.1993\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 821.4199 - val_loss: 809.8537\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 13ms/step - loss: 788.6237 - val_loss: 776.9211\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 756.2626 - val_loss: 744.3907\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 13ms/step - loss: 724.0808 - val_loss: 712.4885\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 692.5942 - val_loss: 680.6947\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 7ms/step - loss: 661.0134 - val_loss: 650.0311\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 7ms/step - loss: 630.3582 - val_loss: 619.8329\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 12ms/step - loss: 600.6790 - val_loss: 589.9358\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 571.0399 - val_loss: 562.2162\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 543.0077 - val_loss: 535.0314\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 515.8435 - val_loss: 508.6414\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 489.5236 - val_loss: 484.1679\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 464.5236 - val_loss: 460.8416\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 441.0303 - val_loss: 437.8871\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 417.9633 - val_loss: 417.3701\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 397.1527 - val_loss: 397.8936\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 377.3321 - val_loss: 380.0531\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 358.8655 - val_loss: 363.3020\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 341.8120 - val_loss: 347.8788\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 325.5042 - val_loss: 334.1827\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 310.7838 - val_loss: 321.1774\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 46ms/step - loss: 1473.7920 - val_loss: 1502.5117\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 5ms/step - loss: 1455.1359 - val_loss: 1483.4781\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1435.7717 - val_loss: 1463.5198\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1415.5352 - val_loss: 1442.6288\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1394.2173 - val_loss: 1420.5945\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1371.7711 - val_loss: 1397.2866\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1348.2765 - val_loss: 1372.3346\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1323.3723 - val_loss: 1346.6257\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 1297.4646 - val_loss: 1319.3040\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1270.5620 - val_loss: 1290.7429\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1242.3779 - val_loss: 1261.6217\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1213.4797 - val_loss: 1231.2388\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1183.2279 - val_loss: 1200.2258\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1152.5737 - val_loss: 1167.3929\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1120.2621 - val_loss: 1134.4181\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 1087.7148 - val_loss: 1100.5781\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1054.1562 - val_loss: 1066.3126\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1020.4672 - val_loss: 1031.2114\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 986.3509 - val_loss: 996.1150\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 951.8582 - val_loss: 960.7720\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 917.2496 - val_loss: 925.6995\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 882.5693 - val_loss: 890.8961\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 848.4301 - val_loss: 854.8063\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 813.8196 - val_loss: 820.5597\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 780.4241 - val_loss: 785.8071\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 746.5607 - val_loss: 752.6162\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 714.1209 - val_loss: 718.4666\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 681.2233 - val_loss: 686.6499\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 650.1459 - val_loss: 655.2714\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 619.6630 - val_loss: 624.5385\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 589.9683 - val_loss: 595.2538\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 561.2245 - val_loss: 567.1719\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 533.6577 - val_loss: 539.9056\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 507.4650 - val_loss: 512.9482\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 481.6241 - val_loss: 488.2504\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 457.2109 - val_loss: 464.0601\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 433.6481 - val_loss: 441.3060\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 411.1644 - val_loss: 420.7933\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 390.8466 - val_loss: 399.7613\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 370.8425 - val_loss: 381.3789\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 352.3935 - val_loss: 364.1660\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 335.2324 - val_loss: 347.9846\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 319.0259 - val_loss: 332.9155\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 304.3302 - val_loss: 319.2022\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 290.5843 - val_loss: 306.7528\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 278.2058 - val_loss: 295.3880\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 266.7796 - val_loss: 285.5855\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 256.6257 - val_loss: 276.2953\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 247.1527 - val_loss: 268.1481\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 238.8110 - val_loss: 260.6853\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 52ms/step - loss: 1564.3972 - val_loss: 1591.4019\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 6ms/step - loss: 1548.4382 - val_loss: 1575.3201\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 5ms/step - loss: 1533.4475 - val_loss: 1559.8566\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1518.9171 - val_loss: 1544.9977\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1504.8925 - val_loss: 1530.3212\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1491.0193 - val_loss: 1515.9697\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1477.2571 - val_loss: 1501.4640\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 8ms/step - loss: 1463.4324 - val_loss: 1486.9930\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 10ms/step - loss: 1449.5745 - val_loss: 1472.2085\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1435.3005 - val_loss: 1457.6229\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 8ms/step - loss: 1421.1039 - val_loss: 1442.0262\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 7ms/step - loss: 1406.1727 - val_loss: 1426.4802\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1391.0731 - val_loss: 1410.0851\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 13ms/step - loss: 1375.3606 - val_loss: 1393.3741\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 5ms/step - loss: 1359.2743 - val_loss: 1376.0720\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 1342.3622 - val_loss: 1358.4022\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 5ms/step - loss: 1324.9391 - val_loss: 1340.0320\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1306.6680 - val_loss: 1320.5934\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 7ms/step - loss: 1287.6444 - val_loss: 1300.0817\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1267.4955 - val_loss: 1278.9288\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1246.6984 - val_loss: 1256.5988\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1224.6722 - val_loss: 1233.4780\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 1201.9266 - val_loss: 1209.6660\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1178.3442 - val_loss: 1184.6918\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1153.5295 - val_loss: 1158.7843\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 1127.7643 - val_loss: 1131.8881\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 1101.0781 - val_loss: 1103.8882\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 1073.5034 - val_loss: 1075.2047\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 1044.8683 - val_loss: 1045.2881\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 1015.5757 - val_loss: 1014.7739\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 985.0649 - val_loss: 983.9083\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 954.2498 - val_loss: 952.3392\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 922.8646 - val_loss: 919.2757\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 890.2877 - val_loss: 886.2389\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 857.4348 - val_loss: 853.1573\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 824.6048 - val_loss: 819.1653\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 790.8842 - val_loss: 785.2343\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 757.4196 - val_loss: 750.9432\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 723.5743 - val_loss: 717.7892\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 690.3746 - val_loss: 685.1066\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 657.8266 - val_loss: 653.1707\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 626.0555 - val_loss: 621.2579\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 594.7096 - val_loss: 590.4155\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 564.0736 - val_loss: 561.3483\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 535.2277 - val_loss: 532.9860\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 507.0002 - val_loss: 505.8137\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 479.9269 - val_loss: 480.1793\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 454.4049 - val_loss: 455.1170\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 429.5981 - val_loss: 431.8533\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 406.1982 - val_loss: 410.4632\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1557.5544 - val_loss: 1578.4186\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1539.2032 - val_loss: 1560.0487\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1521.6865 - val_loss: 1541.8881\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1504.3243 - val_loss: 1524.1724\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1487.3387 - val_loss: 1506.2817\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1470.1348 - val_loss: 1488.5988\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1453.3295 - val_loss: 1470.6919\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1436.0160 - val_loss: 1452.9650\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 1418.7329 - val_loss: 1434.5009\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1400.9336 - val_loss: 1415.5511\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1382.5967 - val_loss: 1396.4871\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1364.1085 - val_loss: 1376.5481\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1345.0399 - val_loss: 1355.7585\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1325.1586 - val_loss: 1334.9922\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1304.9246 - val_loss: 1313.0725\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1284.0234 - val_loss: 1290.6750\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 1262.5093 - val_loss: 1267.9224\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1240.4204 - val_loss: 1244.6749\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 1218.1653 - val_loss: 1220.6814\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 1195.0632 - val_loss: 1196.6212\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 1171.6431 - val_loss: 1172.4524\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 1147.6475 - val_loss: 1147.2847\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 1123.6128 - val_loss: 1120.9587\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1098.3583 - val_loss: 1095.6437\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1073.4869 - val_loss: 1069.5073\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 1047.8639 - val_loss: 1043.4282\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 1021.9406 - val_loss: 1016.6335\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 995.5139 - val_loss: 989.9265\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 7ms/step - loss: 969.1801 - val_loss: 962.3750\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 942.2447 - val_loss: 935.4632\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 7ms/step - loss: 915.2117 - val_loss: 908.5622\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 888.3435 - val_loss: 880.6423\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 860.6919 - val_loss: 853.5659\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 12ms/step - loss: 833.4740 - val_loss: 826.4042\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 806.3217 - val_loss: 799.5386\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 779.0352 - val_loss: 773.6927\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 752.8686 - val_loss: 746.8329\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 7ms/step - loss: 725.9924 - val_loss: 721.7074\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 700.0553 - val_loss: 696.6809\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 674.5910 - val_loss: 671.6947\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 13ms/step - loss: 649.3247 - val_loss: 648.1507\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 625.0339 - val_loss: 625.5145\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 601.2977 - val_loss: 603.6057\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 578.6063 - val_loss: 581.9515\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 12ms/step - loss: 556.4648 - val_loss: 561.2546\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 7ms/step - loss: 535.0021 - val_loss: 541.8418\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 514.3969 - val_loss: 522.9099\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 11ms/step - loss: 494.7372 - val_loss: 504.7915\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 475.7812 - val_loss: 487.4118\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 457.3565 - val_loss: 471.3039\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1491.3317 - val_loss: 1523.8523\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1474.5165 - val_loss: 1506.5743\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1456.9655 - val_loss: 1489.3153\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 7ms/step - loss: 1439.0969 - val_loss: 1471.1173\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1420.1583 - val_loss: 1452.1432\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1400.4772 - val_loss: 1432.3350\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 7ms/step - loss: 1379.7971 - val_loss: 1411.7003\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 5ms/step - loss: 1358.3314 - val_loss: 1390.0734\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1336.0022 - val_loss: 1367.8993\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1312.8019 - val_loss: 1345.0295\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1288.7733 - val_loss: 1321.0718\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1264.1727 - val_loss: 1296.6514\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1239.1195 - val_loss: 1271.5034\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1213.2343 - val_loss: 1246.4110\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1187.3813 - val_loss: 1220.5565\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1160.6046 - val_loss: 1195.1217\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1134.3776 - val_loss: 1169.0182\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1107.4984 - val_loss: 1143.0016\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 1080.7600 - val_loss: 1116.9932\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 1053.8503 - val_loss: 1091.0221\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 1027.2938 - val_loss: 1064.6753\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1000.5223 - val_loss: 1038.7429\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 974.4610 - val_loss: 1012.6058\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 948.1366 - val_loss: 987.7380\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 922.4252 - val_loss: 963.2054\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 897.3124 - val_loss: 937.8469\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 871.8399 - val_loss: 912.9698\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 846.7502 - val_loss: 888.5122\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 821.7628 - val_loss: 863.6083\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 797.1719 - val_loss: 838.4583\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 7ms/step - loss: 772.2399 - val_loss: 813.3743\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 747.4165 - val_loss: 788.7430\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 723.0264 - val_loss: 763.9066\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 699.0669 - val_loss: 738.9450\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 675.0917 - val_loss: 714.1026\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 651.2532 - val_loss: 689.8990\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 628.1660 - val_loss: 665.6446\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 7ms/step - loss: 605.2756 - val_loss: 641.3907\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 583.0487 - val_loss: 617.3937\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 560.8597 - val_loss: 593.8525\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 539.5246 - val_loss: 570.7340\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 7ms/step - loss: 518.5090 - val_loss: 548.1623\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 497.9968 - val_loss: 525.9427\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 478.0487 - val_loss: 504.1222\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 458.6243 - val_loss: 483.2004\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 439.8690 - val_loss: 462.7130\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 421.5886 - val_loss: 443.5694\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 404.4082 - val_loss: 424.6234\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 387.4831 - val_loss: 406.8242\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 371.6035 - val_loss: 389.2422\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 1601.9056 - val_loss: 1639.5341\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 5ms/step - loss: 1584.8466 - val_loss: 1621.8293\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1568.8870 - val_loss: 1605.3939\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1553.9233 - val_loss: 1589.9639\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1539.8485 - val_loss: 1575.3064\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1526.5107 - val_loss: 1561.2181\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1513.6141 - val_loss: 1547.4661\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1501.1874 - val_loss: 1534.1182\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1488.9719 - val_loss: 1521.0349\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1476.7076 - val_loss: 1508.1013\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1464.3062 - val_loss: 1495.1154\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 13ms/step - loss: 1451.7325 - val_loss: 1481.2933\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1438.5155 - val_loss: 1466.7555\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1424.3546 - val_loss: 1451.6013\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1409.6332 - val_loss: 1435.2581\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 1393.7715 - val_loss: 1418.3551\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1376.9912 - val_loss: 1400.4227\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 13ms/step - loss: 1359.6257 - val_loss: 1380.9160\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1340.5883 - val_loss: 1360.8351\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1320.9440 - val_loss: 1339.3806\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 13ms/step - loss: 1300.0126 - val_loss: 1316.8170\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 8ms/step - loss: 1277.7567 - val_loss: 1293.5383\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 10ms/step - loss: 1254.8046 - val_loss: 1268.7969\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 1230.8081 - val_loss: 1243.3978\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 1206.1670 - val_loss: 1216.6689\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 1180.2039 - val_loss: 1190.1044\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 1154.2311 - val_loss: 1162.1595\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 1127.2588 - val_loss: 1134.7719\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 1100.7566 - val_loss: 1105.9989\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 1073.0101 - val_loss: 1078.0975\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 1045.8577 - val_loss: 1049.3604\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 1017.9247 - val_loss: 1020.9808\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 990.1188 - val_loss: 992.8958\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 962.7712 - val_loss: 964.1522\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 935.1980 - val_loss: 935.6301\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 907.3169 - val_loss: 908.4843\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 880.5974 - val_loss: 880.6136\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 853.5272 - val_loss: 853.7637\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 826.8654 - val_loss: 827.3434\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 800.7343 - val_loss: 800.8024\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 774.6976 - val_loss: 775.7665\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 749.5437 - val_loss: 750.3398\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 724.4413 - val_loss: 726.0844\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 700.3046 - val_loss: 701.9847\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 676.5501 - val_loss: 679.1189\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 653.5512 - val_loss: 656.5934\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 631.1554 - val_loss: 634.8458\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 609.1174 - val_loss: 614.4698\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 588.1751 - val_loss: 594.3196\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 567.5178 - val_loss: 574.8898\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1504.5288 - val_loss: 1524.5289\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1486.4022 - val_loss: 1506.3110\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1468.4454 - val_loss: 1487.5485\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1450.0696 - val_loss: 1468.6954\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1431.5752 - val_loss: 1449.1719\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1412.6124 - val_loss: 1429.3666\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1393.2715 - val_loss: 1409.3446\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1373.4524 - val_loss: 1388.9314\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 1353.2010 - val_loss: 1367.7607\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1332.3611 - val_loss: 1345.9895\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1310.9080 - val_loss: 1323.4550\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 7ms/step - loss: 1288.7079 - val_loss: 1300.0347\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 5ms/step - loss: 1265.7474 - val_loss: 1275.7396\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1241.9023 - val_loss: 1251.3381\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1217.7375 - val_loss: 1225.6677\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1192.3209 - val_loss: 1200.1364\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1166.7449 - val_loss: 1173.3239\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 1140.4059 - val_loss: 1146.0366\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 7ms/step - loss: 1113.4523 - val_loss: 1118.1021\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1085.8621 - val_loss: 1089.1146\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 1057.3740 - val_loss: 1059.8438\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1028.3645 - val_loss: 1030.2253\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 998.8536 - val_loss: 999.3057\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 7ms/step - loss: 968.6664 - val_loss: 967.7829\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 937.5239 - val_loss: 936.5115\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 906.3521 - val_loss: 903.9857\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 874.2330 - val_loss: 872.1254\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 841.8562 - val_loss: 839.8185\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 809.3572 - val_loss: 807.2098\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 777.2300 - val_loss: 773.5803\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 744.6170 - val_loss: 741.2895\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 712.5339 - val_loss: 709.7816\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 681.3041 - val_loss: 678.7319\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 650.8397 - val_loss: 648.8602\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 621.2861 - val_loss: 619.8287\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 592.7307 - val_loss: 591.6373\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 564.9745 - val_loss: 564.6519\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 538.4609 - val_loss: 538.8439\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 513.0910 - val_loss: 514.2479\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 489.1240 - val_loss: 490.5996\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 465.9751 - val_loss: 468.7420\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 444.3553 - val_loss: 447.9685\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 423.6907 - val_loss: 428.3531\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 5ms/step - loss: 404.4395 - val_loss: 409.3112\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 385.8831 - val_loss: 391.9575\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 7ms/step - loss: 368.6343 - val_loss: 375.8245\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 352.6451 - val_loss: 360.4250\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 337.4940 - val_loss: 346.1731\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 323.2969 - val_loss: 332.6708\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 309.8269 - val_loss: 320.2067\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 57ms/step - loss: 1590.4493 - val_loss: 1621.4480\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 19ms/step - loss: 1576.2905 - val_loss: 1607.0569\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 5ms/step - loss: 1562.5098 - val_loss: 1593.3217\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 5ms/step - loss: 1549.0450 - val_loss: 1579.6632\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 5ms/step - loss: 1535.5269 - val_loss: 1565.8593\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1521.7479 - val_loss: 1551.9122\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1507.8372 - val_loss: 1537.0726\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1493.1881 - val_loss: 1521.9937\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1478.2600 - val_loss: 1506.1838\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1462.2983 - val_loss: 1489.6754\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1445.7394 - val_loss: 1471.3169\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1427.6405 - val_loss: 1452.4504\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1408.6039 - val_loss: 1432.2170\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1388.4098 - val_loss: 1410.8180\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1366.9600 - val_loss: 1387.9268\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1344.0764 - val_loss: 1363.9264\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 1320.1892 - val_loss: 1338.4530\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1295.1215 - val_loss: 1311.5425\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1268.9519 - val_loss: 1283.2343\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1241.3787 - val_loss: 1254.7614\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 1213.4281 - val_loss: 1224.8888\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1183.9436 - val_loss: 1194.4100\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 1153.8290 - val_loss: 1162.2850\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1122.9741 - val_loss: 1129.1252\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 1091.4948 - val_loss: 1094.9730\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 1058.8036 - val_loss: 1061.6448\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 1026.2079 - val_loss: 1027.3506\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 993.0400 - val_loss: 992.2779\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 959.5266 - val_loss: 957.4076\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 926.0299 - val_loss: 921.9038\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 892.2184 - val_loss: 887.0740\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 858.8480 - val_loss: 851.6912\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 824.8821 - val_loss: 816.9343\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 791.3263 - val_loss: 782.5436\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 758.4711 - val_loss: 747.2059\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 724.9286 - val_loss: 713.2319\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 692.1919 - val_loss: 680.3204\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 660.1768 - val_loss: 647.7165\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 628.8235 - val_loss: 616.4004\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 598.4219 - val_loss: 585.7012\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 568.7822 - val_loss: 556.5355\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 540.4587 - val_loss: 528.8032\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 513.6557 - val_loss: 502.0778\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 487.3422 - val_loss: 477.6182\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 463.1727 - val_loss: 453.7839\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 439.9104 - val_loss: 431.8107\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 417.7080 - val_loss: 411.9635\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 397.4397 - val_loss: 392.5880\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 378.0404 - val_loss: 375.0229\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 360.2953 - val_loss: 358.4116\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 1579.7625 - val_loss: 1611.4701\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1565.2765 - val_loss: 1595.7516\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1551.7217 - val_loss: 1580.8092\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1538.7155 - val_loss: 1566.1803\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1525.9332 - val_loss: 1551.7549\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1513.3322 - val_loss: 1537.0010\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1500.5272 - val_loss: 1522.2341\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1487.5223 - val_loss: 1506.8883\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1473.9423 - val_loss: 1491.0458\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 7ms/step - loss: 1459.7346 - val_loss: 1474.3131\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1444.3171 - val_loss: 1456.6600\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1427.9674 - val_loss: 1437.4307\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1410.1746 - val_loss: 1416.9661\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1390.9980 - val_loss: 1395.2412\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1370.3583 - val_loss: 1372.3040\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 5ms/step - loss: 1348.6128 - val_loss: 1347.1472\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1324.9885 - val_loss: 1321.0286\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1300.0925 - val_loss: 1293.6770\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1273.4963 - val_loss: 1264.6554\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 1246.0680 - val_loss: 1233.9552\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 1216.7180 - val_loss: 1202.5104\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 7ms/step - loss: 1186.8784 - val_loss: 1169.8324\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1155.9795 - val_loss: 1136.8394\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1124.3248 - val_loss: 1103.1869\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 1091.9418 - val_loss: 1068.8115\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 7ms/step - loss: 1058.9498 - val_loss: 1034.4204\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 1025.2849 - val_loss: 1000.4597\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 992.2803 - val_loss: 964.3365\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 958.6337 - val_loss: 929.3656\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 924.9808 - val_loss: 894.9820\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 9ms/step - loss: 891.8239 - val_loss: 861.1452\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 859.4329 - val_loss: 827.6876\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 826.8887 - val_loss: 795.5523\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 13ms/step - loss: 795.7626 - val_loss: 763.8115\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 764.8653 - val_loss: 733.2648\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 734.8618 - val_loss: 704.5505\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 706.2673 - val_loss: 676.2446\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 678.0896 - val_loss: 648.8609\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 650.8612 - val_loss: 622.9389\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 15ms/step - loss: 625.2572 - val_loss: 598.0817\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 5ms/step - loss: 600.2529 - val_loss: 574.5479\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 576.2844 - val_loss: 552.6927\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 553.5764 - val_loss: 531.7323\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 531.9675 - val_loss: 511.9872\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 511.4716 - val_loss: 493.4794\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 491.8875 - val_loss: 475.9695\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 473.2981 - val_loss: 459.6729\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 455.6903 - val_loss: 444.4434\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 439.0755 - val_loss: 430.1634\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 423.2677 - val_loss: 416.7088\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 1583.9352 - val_loss: 1611.2169\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1567.5250 - val_loss: 1595.1343\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 1551.5829 - val_loss: 1579.7605\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 5ms/step - loss: 1535.8309 - val_loss: 1564.4471\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1520.4440 - val_loss: 1548.8252\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1504.7429 - val_loss: 1533.3381\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 5ms/step - loss: 1489.2239 - val_loss: 1517.4670\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1473.0887 - val_loss: 1501.8262\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 1456.9700 - val_loss: 1485.4280\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1440.3815 - val_loss: 1468.6174\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1423.2664 - val_loss: 1451.5101\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1405.6331 - val_loss: 1433.7772\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1387.5308 - val_loss: 1415.4016\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1368.7172 - val_loss: 1396.3033\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1349.3822 - val_loss: 1376.3643\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 1329.2830 - val_loss: 1356.3866\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1308.8497 - val_loss: 1335.5542\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1287.7631 - val_loss: 1314.1586\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1265.9825 - val_loss: 1292.4159\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1243.8942 - val_loss: 1269.6584\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 1221.2623 - val_loss: 1246.9478\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1198.2512 - val_loss: 1223.4780\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 1174.5691 - val_loss: 1200.2113\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1150.8488 - val_loss: 1175.7886\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 1126.5436 - val_loss: 1151.3887\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 1101.9974 - val_loss: 1126.7186\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 1077.0276 - val_loss: 1102.2061\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 1052.1039 - val_loss: 1077.4731\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 1027.1447 - val_loss: 1052.2783\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 1001.7892 - val_loss: 1026.9832\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 976.4954 - val_loss: 1001.8277\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 950.8476 - val_loss: 977.1583\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 5ms/step - loss: 925.4634 - val_loss: 951.8501\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 900.1143 - val_loss: 926.8228\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 874.9664 - val_loss: 901.8496\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 849.7539 - val_loss: 877.6260\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 824.9486 - val_loss: 852.9669\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 799.7609 - val_loss: 828.9017\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 775.6207 - val_loss: 804.6568\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 750.6849 - val_loss: 781.7206\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 726.8628 - val_loss: 758.1744\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 702.9379 - val_loss: 734.8064\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 679.7404 - val_loss: 711.2666\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 656.2637 - val_loss: 689.7953\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 634.0228 - val_loss: 668.2190\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 612.3892 - val_loss: 646.3042\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 590.4274 - val_loss: 625.4264\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 569.6005 - val_loss: 604.9077\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 549.2557 - val_loss: 585.1124\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 529.4399 - val_loss: 565.6831\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1506.1505 - val_loss: 1535.3248\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1488.7356 - val_loss: 1517.3480\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1471.2723 - val_loss: 1499.5671\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1453.6718 - val_loss: 1481.1488\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1435.4861 - val_loss: 1462.1405\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1416.7008 - val_loss: 1442.5563\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 13ms/step - loss: 1397.0121 - val_loss: 1422.0648\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1376.3920 - val_loss: 1400.8451\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1355.0337 - val_loss: 1378.2670\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1332.5853 - val_loss: 1355.2278\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 5ms/step - loss: 1309.4203 - val_loss: 1330.7546\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 1284.9667 - val_loss: 1305.4282\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1259.8457 - val_loss: 1278.9436\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 13ms/step - loss: 1233.2986 - val_loss: 1252.1981\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 14ms/step - loss: 1206.7566 - val_loss: 1223.7467\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1178.4609 - val_loss: 1195.1436\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1149.8402 - val_loss: 1165.9055\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1120.3177 - val_loss: 1135.7963\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1090.1698 - val_loss: 1104.7700\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 11ms/step - loss: 1059.2394 - val_loss: 1072.6278\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 1027.9180 - val_loss: 1040.3927\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 995.9565 - val_loss: 1007.8192\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 963.6841 - val_loss: 974.7916\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 930.5676 - val_loss: 941.4837\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 897.8444 - val_loss: 907.2743\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 863.8719 - val_loss: 873.1544\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 829.9911 - val_loss: 838.6758\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 796.0654 - val_loss: 803.7702\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 7ms/step - loss: 761.9433 - val_loss: 769.7206\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 728.1764 - val_loss: 736.5864\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 695.2570 - val_loss: 703.1847\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 662.8591 - val_loss: 670.9278\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 631.0582 - val_loss: 639.7323\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 600.2203 - val_loss: 609.9971\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 570.4288 - val_loss: 581.0998\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 542.0877 - val_loss: 553.4185\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 514.3887 - val_loss: 527.8442\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 488.7215 - val_loss: 502.9841\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 463.8916 - val_loss: 480.1914\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 440.9539 - val_loss: 458.6818\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 419.1413 - val_loss: 438.9795\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 398.9008 - val_loss: 420.3298\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 379.9546 - val_loss: 403.6728\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 362.4721 - val_loss: 387.9782\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 346.2873 - val_loss: 373.4264\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 331.4953 - val_loss: 360.3793\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 317.8047 - val_loss: 348.7182\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 5ms/step - loss: 305.1673 - val_loss: 338.5427\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 294.1995 - val_loss: 328.2158\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 283.2937 - val_loss: 319.9188\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 42ms/step - loss: 1522.9984 - val_loss: 1549.6287\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1506.1472 - val_loss: 1531.8051\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1488.9233 - val_loss: 1513.7323\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1471.4014 - val_loss: 1494.5923\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1452.9836 - val_loss: 1475.2246\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1433.9424 - val_loss: 1454.4930\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1414.2405 - val_loss: 1432.8455\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1393.4279 - val_loss: 1410.8171\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1371.8506 - val_loss: 1387.4313\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1349.0593 - val_loss: 1362.9943\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1325.4368 - val_loss: 1337.2454\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1300.8286 - val_loss: 1310.2224\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1274.9939 - val_loss: 1282.2906\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 1248.1105 - val_loss: 1253.4698\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1220.3784 - val_loss: 1223.6622\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 1192.0131 - val_loss: 1193.3418\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1162.3995 - val_loss: 1162.5244\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1132.5232 - val_loss: 1130.3522\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1101.7336 - val_loss: 1097.7527\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1070.0824 - val_loss: 1064.7043\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1037.9857 - val_loss: 1030.1331\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 1005.0745 - val_loss: 995.4680\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 971.1825 - val_loss: 960.5874\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 937.1353 - val_loss: 923.6296\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 901.5266 - val_loss: 887.6962\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 865.6135 - val_loss: 850.6534\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 829.3769 - val_loss: 812.2562\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 792.2390 - val_loss: 775.0735\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 755.5267 - val_loss: 738.0780\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 719.1950 - val_loss: 701.4371\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 683.4344 - val_loss: 665.5631\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 648.3165 - val_loss: 631.2094\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 614.0874 - val_loss: 597.9099\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 581.0401 - val_loss: 565.6656\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 549.1657 - val_loss: 535.3570\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 518.8104 - val_loss: 506.3471\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 489.8821 - val_loss: 479.4649\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 462.3546 - val_loss: 454.3757\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 436.9555 - val_loss: 430.0351\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 412.6311 - val_loss: 407.9634\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 390.0179 - val_loss: 387.4035\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 5ms/step - loss: 368.9244 - val_loss: 368.9893\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 349.4724 - val_loss: 351.8443\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 331.7136 - val_loss: 336.1391\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 315.2219 - val_loss: 321.6841\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 8ms/step - loss: 299.9196 - val_loss: 308.8764\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 12ms/step - loss: 286.0927 - val_loss: 297.4229\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 8ms/step - loss: 273.6348 - val_loss: 286.9947\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 11ms/step - loss: 262.2236 - val_loss: 277.8406\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 251.9955 - val_loss: 269.3687\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 53ms/step - loss: 1530.9541 - val_loss: 1566.5242\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1517.4789 - val_loss: 1552.9176\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1503.4047 - val_loss: 1539.0775\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1488.8254 - val_loss: 1524.5382\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1473.6646 - val_loss: 1509.1779\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 5ms/step - loss: 1457.4858 - val_loss: 1493.0087\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 5ms/step - loss: 1440.2860 - val_loss: 1475.8109\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1422.0234 - val_loss: 1456.9249\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1402.2271 - val_loss: 1436.9471\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1381.0183 - val_loss: 1415.3127\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1358.4221 - val_loss: 1391.3920\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1333.7020 - val_loss: 1365.9846\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1307.1609 - val_loss: 1339.2114\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1279.3590 - val_loss: 1310.1053\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1249.7557 - val_loss: 1279.2920\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 1218.6687 - val_loss: 1246.8468\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1186.0520 - val_loss: 1212.6899\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1152.1299 - val_loss: 1177.8756\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1117.2242 - val_loss: 1142.4266\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 1081.7668 - val_loss: 1105.7130\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1045.3864 - val_loss: 1068.9602\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1009.0074 - val_loss: 1030.8086\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 971.7236 - val_loss: 993.8214\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 935.0745 - val_loss: 956.5787\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 898.4305 - val_loss: 918.4147\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 861.6576 - val_loss: 881.0261\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 5ms/step - loss: 825.5439 - val_loss: 843.9482\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 789.4715 - val_loss: 808.4940\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 754.9637 - val_loss: 772.4749\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 720.3133 - val_loss: 737.4119\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 686.2051 - val_loss: 703.5969\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 653.2711 - val_loss: 669.6962\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 620.8835 - val_loss: 637.4695\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 590.0016 - val_loss: 606.3913\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 560.1034 - val_loss: 575.9946\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 531.0403 - val_loss: 547.8710\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 503.9566 - val_loss: 520.7563\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 477.8994 - val_loss: 495.1795\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 453.5918 - val_loss: 470.8674\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 430.2380 - val_loss: 448.8292\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 408.6858 - val_loss: 427.6022\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 388.7099 - val_loss: 407.3848\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 5ms/step - loss: 369.4870 - val_loss: 390.1068\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 352.2447 - val_loss: 374.1905\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 336.4774 - val_loss: 358.2999\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 321.2269 - val_loss: 344.7673\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 307.7945 - val_loss: 332.0702\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 295.1082 - val_loss: 320.9352\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 283.7964 - val_loss: 310.1842\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 5ms/step - loss: 272.9920 - val_loss: 300.4281\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1546.4520 - val_loss: 1570.7769\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1529.3809 - val_loss: 1553.6506\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1512.7313 - val_loss: 1536.4166\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1496.1003 - val_loss: 1519.2534\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1479.6542 - val_loss: 1502.1437\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1463.0393 - val_loss: 1484.9117\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1446.6603 - val_loss: 1467.1586\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1429.7081 - val_loss: 1449.5021\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 5ms/step - loss: 1412.7361 - val_loss: 1431.5817\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1395.3895 - val_loss: 1413.0957\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1377.6888 - val_loss: 1394.2786\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 1359.6733 - val_loss: 1375.0879\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1341.2784 - val_loss: 1355.3522\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1322.2444 - val_loss: 1336.0869\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1303.4585 - val_loss: 1315.3812\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1283.8984 - val_loss: 1294.9867\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1264.4021 - val_loss: 1274.0869\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1244.5289 - val_loss: 1253.1101\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 1224.0723 - val_loss: 1232.5408\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 8ms/step - loss: 1203.9641 - val_loss: 1210.7246\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1183.2900 - val_loss: 1188.6299\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 13ms/step - loss: 1162.0125 - val_loss: 1167.5481\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1141.3047 - val_loss: 1145.7941\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1120.2535 - val_loss: 1124.3375\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1099.2738 - val_loss: 1102.6698\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 1078.0896 - val_loss: 1081.3484\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 1057.0717 - val_loss: 1060.7362\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 7ms/step - loss: 1036.5240 - val_loss: 1039.3923\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 12ms/step - loss: 1015.5536 - val_loss: 1018.7477\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 994.8152 - val_loss: 998.7090\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 8ms/step - loss: 974.4020 - val_loss: 978.3621\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 13ms/step - loss: 953.9744 - val_loss: 958.2816\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 11ms/step - loss: 933.5847 - val_loss: 938.8887\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 913.5449 - val_loss: 919.2914\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 893.3745 - val_loss: 899.8516\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 872.7795 - val_loss: 881.5046\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 853.0239 - val_loss: 862.0292\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 832.6161 - val_loss: 842.9328\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 812.5463 - val_loss: 824.0874\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 792.3542 - val_loss: 805.2596\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 772.2556 - val_loss: 785.8683\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 751.6078 - val_loss: 766.5051\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 730.9216 - val_loss: 746.5004\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 709.6176 - val_loss: 725.8073\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 687.8154 - val_loss: 704.5599\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 665.2777 - val_loss: 681.8584\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 641.6862 - val_loss: 658.5813\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 617.6263 - val_loss: 634.2924\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 593.1290 - val_loss: 610.4061\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 568.9188 - val_loss: 585.5831\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1526.4395 - val_loss: 1555.8134\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1508.7585 - val_loss: 1538.8895\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1490.5144 - val_loss: 1521.3046\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1471.6746 - val_loss: 1502.6294\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1451.9473 - val_loss: 1483.1262\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 5ms/step - loss: 1431.2927 - val_loss: 1462.4708\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1409.6270 - val_loss: 1441.0042\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1386.7405 - val_loss: 1418.6848\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1363.4352 - val_loss: 1394.4001\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1338.5135 - val_loss: 1369.5190\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1312.3082 - val_loss: 1343.9287\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1285.7000 - val_loss: 1316.5620\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1257.6165 - val_loss: 1288.3827\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 5ms/step - loss: 1228.5221 - val_loss: 1258.6483\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 5ms/step - loss: 1198.3268 - val_loss: 1228.2269\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1167.4769 - val_loss: 1196.1322\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1135.1348 - val_loss: 1163.2019\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1102.1715 - val_loss: 1129.1494\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1068.1835 - val_loss: 1094.6415\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 1033.3738 - val_loss: 1058.8477\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 998.0501 - val_loss: 1022.1128\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 961.7044 - val_loss: 985.9197\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 926.2219 - val_loss: 948.7065\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 890.3018 - val_loss: 912.4432\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 854.7227 - val_loss: 876.5494\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 819.9783 - val_loss: 840.5571\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 785.0023 - val_loss: 806.0410\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 751.2877 - val_loss: 771.2084\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 718.1470 - val_loss: 737.6479\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 685.9140 - val_loss: 705.3707\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 654.6954 - val_loss: 673.9598\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 624.6860 - val_loss: 644.0207\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 596.0035 - val_loss: 615.3757\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 568.6041 - val_loss: 587.6282\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 542.0842 - val_loss: 562.0163\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 517.1921 - val_loss: 537.0603\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 493.6241 - val_loss: 513.1862\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 471.0881 - val_loss: 491.0905\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 450.3018 - val_loss: 469.6729\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 429.9450 - val_loss: 450.5547\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 411.2910 - val_loss: 432.4544\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 393.7542 - val_loss: 415.1682\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 7ms/step - loss: 377.2995 - val_loss: 399.2821\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 361.8152 - val_loss: 384.6168\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 347.6419 - val_loss: 370.5173\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 333.7465 - val_loss: 357.7602\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 321.3166 - val_loss: 345.8898\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 309.6316 - val_loss: 334.8258\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 298.6250 - val_loss: 324.7491\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 288.7316 - val_loss: 315.3553\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 55ms/step - loss: 1573.9706 - val_loss: 1607.4943\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 20ms/step - loss: 1556.7289 - val_loss: 1589.3524\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 12ms/step - loss: 1539.7992 - val_loss: 1571.6564\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1523.1959 - val_loss: 1554.0599\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1506.6500 - val_loss: 1536.2374\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 7ms/step - loss: 1489.7773 - val_loss: 1518.5018\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 12ms/step - loss: 1472.6051 - val_loss: 1500.5756\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 5ms/step - loss: 1455.3464 - val_loss: 1482.3054\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1437.8820 - val_loss: 1463.5425\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1419.4912 - val_loss: 1444.5803\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1401.0215 - val_loss: 1424.7107\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1381.6488 - val_loss: 1404.8300\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1361.7858 - val_loss: 1384.2257\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1341.4054 - val_loss: 1362.1440\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1319.8214 - val_loss: 1340.1129\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 5ms/step - loss: 1297.9615 - val_loss: 1317.0723\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1275.1173 - val_loss: 1294.2563\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1252.2484 - val_loss: 1270.0590\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1228.4127 - val_loss: 1245.5829\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 1204.0123 - val_loss: 1220.4083\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1179.0480 - val_loss: 1194.9808\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1153.7166 - val_loss: 1168.5476\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 1127.5521 - val_loss: 1142.1429\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1101.1438 - val_loss: 1115.1323\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1073.9401 - val_loss: 1087.7896\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 1046.3336 - val_loss: 1059.3585\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 5ms/step - loss: 1017.7478 - val_loss: 1030.5338\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 7ms/step - loss: 988.8767 - val_loss: 1001.0753\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 959.2100 - val_loss: 971.1129\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 929.7812 - val_loss: 941.0474\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 899.7302 - val_loss: 911.7646\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 870.1761 - val_loss: 881.8066\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 840.6146 - val_loss: 852.3492\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 811.2622 - val_loss: 823.4232\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 782.5591 - val_loss: 794.6003\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 754.3808 - val_loss: 766.1365\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 726.3885 - val_loss: 739.3560\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 699.7355 - val_loss: 712.1385\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 673.2368 - val_loss: 686.7098\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 647.6064 - val_loss: 661.6254\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 622.9437 - val_loss: 636.8808\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 598.7390 - val_loss: 613.8768\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 575.5638 - val_loss: 591.3500\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 5ms/step - loss: 553.1193 - val_loss: 569.6853\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 531.5953 - val_loss: 548.8000\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 510.7789 - val_loss: 528.6929\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 490.7722 - val_loss: 509.5211\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 471.8722 - val_loss: 490.6143\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 453.2667 - val_loss: 473.3681\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 436.2373 - val_loss: 456.2997\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1549.1156 - val_loss: 1583.7542\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1533.5227 - val_loss: 1568.0848\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1518.3647 - val_loss: 1552.4510\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1503.2323 - val_loss: 1536.8567\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1488.1350 - val_loss: 1521.1440\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1472.8076 - val_loss: 1504.9652\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1457.2014 - val_loss: 1488.7700\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1441.0953 - val_loss: 1472.0779\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1424.5448 - val_loss: 1454.3934\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1407.1033 - val_loss: 1435.8456\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 8ms/step - loss: 1388.7346 - val_loss: 1416.7534\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1369.5293 - val_loss: 1396.6097\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 7ms/step - loss: 1349.2192 - val_loss: 1375.3455\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1327.6765 - val_loss: 1352.5981\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1304.9094 - val_loss: 1328.8757\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1281.2642 - val_loss: 1304.1515\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1256.4102 - val_loss: 1278.9225\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1231.1935 - val_loss: 1252.8464\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1204.6958 - val_loss: 1226.1003\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 1177.3792 - val_loss: 1198.0612\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 1149.6769 - val_loss: 1169.1058\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 1120.9219 - val_loss: 1140.3990\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1092.0663 - val_loss: 1110.8173\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 1062.7284 - val_loss: 1080.8434\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1032.9640 - val_loss: 1051.3027\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 1003.6981 - val_loss: 1021.1136\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 974.0829 - val_loss: 991.1154\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 9ms/step - loss: 944.4247 - val_loss: 961.4923\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 10ms/step - loss: 915.1274 - val_loss: 931.8295\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 885.5891 - val_loss: 902.2994\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 856.4588 - val_loss: 872.7786\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 827.7574 - val_loss: 843.1149\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 798.8304 - val_loss: 814.5599\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 771.1035 - val_loss: 785.6045\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 13ms/step - loss: 742.7966 - val_loss: 758.6646\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 716.1521 - val_loss: 731.0118\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 689.2822 - val_loss: 704.6956\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 14ms/step - loss: 663.5821 - val_loss: 679.1045\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 638.7232 - val_loss: 653.8173\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 614.2427 - val_loss: 629.8386\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 5ms/step - loss: 590.8628 - val_loss: 606.7907\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 568.2211 - val_loss: 584.2882\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 546.3331 - val_loss: 562.7408\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 525.4041 - val_loss: 541.8159\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 505.0198 - val_loss: 522.4028\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 7ms/step - loss: 485.9120 - val_loss: 503.2525\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 467.2335 - val_loss: 485.8447\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 449.7608 - val_loss: 468.2288\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 432.6886 - val_loss: 452.0906\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 416.9198 - val_loss: 436.6236\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1523.3882 - val_loss: 1546.3651\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1505.9679 - val_loss: 1528.3218\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1488.3378 - val_loss: 1510.1743\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1470.5315 - val_loss: 1491.4526\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1452.3578 - val_loss: 1472.2777\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 5ms/step - loss: 1433.8309 - val_loss: 1452.5996\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1414.8936 - val_loss: 1432.1163\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1395.3588 - val_loss: 1411.6359\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 1375.5494 - val_loss: 1390.0798\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 5ms/step - loss: 1354.8503 - val_loss: 1367.6801\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1333.3824 - val_loss: 1344.4310\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1311.5436 - val_loss: 1320.2418\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1288.7638 - val_loss: 1296.0828\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1265.5397 - val_loss: 1271.4674\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1241.9789 - val_loss: 1245.1525\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1217.3896 - val_loss: 1218.6230\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1191.9818 - val_loss: 1191.6281\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 7ms/step - loss: 1166.0148 - val_loss: 1164.1436\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1139.8662 - val_loss: 1136.0276\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 1113.3689 - val_loss: 1107.4827\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1085.8135 - val_loss: 1079.4227\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 1058.2648 - val_loss: 1050.6135\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1030.5417 - val_loss: 1021.4409\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1002.5844 - val_loss: 993.3143\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 974.7040 - val_loss: 964.9877\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 946.9359 - val_loss: 936.4203\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 919.3462 - val_loss: 908.1616\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 891.9587 - val_loss: 880.8163\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 864.7085 - val_loss: 853.6766\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 7ms/step - loss: 837.4788 - val_loss: 826.9181\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 810.8486 - val_loss: 799.7983\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 783.6204 - val_loss: 773.7389\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 756.9998 - val_loss: 747.6786\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 731.0646 - val_loss: 721.0793\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 7ms/step - loss: 704.1631 - val_loss: 696.1409\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 678.1932 - val_loss: 671.3821\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 652.5164 - val_loss: 646.8788\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 627.3607 - val_loss: 622.2820\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 602.3055 - val_loss: 598.1750\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 577.8239 - val_loss: 575.2604\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 553.7190 - val_loss: 552.6775\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 530.2230 - val_loss: 530.8793\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 7ms/step - loss: 507.4996 - val_loss: 509.3026\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 484.7683 - val_loss: 489.2034\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 462.9958 - val_loss: 468.9911\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 442.2575 - val_loss: 449.4974\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 421.7430 - val_loss: 431.3493\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 402.5413 - val_loss: 414.4127\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 384.4097 - val_loss: 398.3528\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 367.3139 - val_loss: 382.9253\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1518.6051 - val_loss: 1541.5554\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1501.9741 - val_loss: 1525.0190\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1485.2810 - val_loss: 1508.2838\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 7ms/step - loss: 1468.6840 - val_loss: 1491.0449\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 13ms/step - loss: 1451.3097 - val_loss: 1473.6194\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 13ms/step - loss: 1433.4337 - val_loss: 1455.0292\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 5ms/step - loss: 1414.5863 - val_loss: 1435.4868\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1394.7412 - val_loss: 1415.2502\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 5ms/step - loss: 1374.0825 - val_loss: 1393.8817\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 7ms/step - loss: 1352.2437 - val_loss: 1371.3136\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 13ms/step - loss: 1329.1012 - val_loss: 1347.9622\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 13ms/step - loss: 1305.4592 - val_loss: 1323.1412\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 13ms/step - loss: 1280.4539 - val_loss: 1297.9956\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1254.8444 - val_loss: 1271.8700\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1228.4709 - val_loss: 1244.7994\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 5ms/step - loss: 1201.6072 - val_loss: 1217.1189\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1173.7583 - val_loss: 1189.4784\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1145.7223 - val_loss: 1160.9805\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1117.0381 - val_loss: 1132.1719\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 1088.0033 - val_loss: 1102.7888\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 1058.3792 - val_loss: 1073.8301\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1029.1470 - val_loss: 1044.3229\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 999.5610 - val_loss: 1014.2235\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 969.6551 - val_loss: 984.6638\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 939.6293 - val_loss: 955.8211\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 910.0414 - val_loss: 926.5131\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 880.3892 - val_loss: 896.9207\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 850.8282 - val_loss: 868.0016\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 821.2776 - val_loss: 839.6382\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 7ms/step - loss: 792.2896 - val_loss: 810.8783\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 763.1279 - val_loss: 782.6077\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 7ms/step - loss: 734.1172 - val_loss: 754.9389\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 706.1655 - val_loss: 727.0764\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 677.9958 - val_loss: 699.9529\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 650.4523 - val_loss: 673.8180\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 623.4705 - val_loss: 648.1430\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 596.7920 - val_loss: 622.7403\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 570.9471 - val_loss: 597.8719\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 545.6740 - val_loss: 573.6786\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 521.1285 - val_loss: 550.5961\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 497.3243 - val_loss: 529.0732\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 474.9933 - val_loss: 507.6751\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 453.1092 - val_loss: 487.2587\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 432.3875 - val_loss: 468.1906\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 412.6481 - val_loss: 450.0733\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 394.1250 - val_loss: 432.7576\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 376.7500 - val_loss: 415.9466\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 7ms/step - loss: 359.8025 - val_loss: 401.4896\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 344.6234 - val_loss: 387.1401\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 329.9301 - val_loss: 373.8619\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1577.2850 - val_loss: 1592.0884\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1559.1302 - val_loss: 1573.4546\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1541.4326 - val_loss: 1555.4211\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1524.2092 - val_loss: 1537.7045\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1507.3115 - val_loss: 1519.7223\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1490.5627 - val_loss: 1501.7645\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1473.7001 - val_loss: 1483.6343\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 5ms/step - loss: 1456.4316 - val_loss: 1465.6353\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1439.2711 - val_loss: 1446.6957\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1421.3901 - val_loss: 1427.7906\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1403.2512 - val_loss: 1408.4535\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1384.8466 - val_loss: 1388.1506\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1365.6174 - val_loss: 1367.7821\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 1345.9706 - val_loss: 1346.2520\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1325.6945 - val_loss: 1324.5106\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 1304.5573 - val_loss: 1302.1421\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1283.4696 - val_loss: 1278.4631\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 1261.0138 - val_loss: 1254.9717\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 1238.0977 - val_loss: 1230.8729\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 1214.4640 - val_loss: 1205.8732\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 1190.1724 - val_loss: 1180.0190\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1164.8331 - val_loss: 1154.1487\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 1139.3187 - val_loss: 1127.9915\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 1113.2996 - val_loss: 1101.2733\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 7ms/step - loss: 1086.9684 - val_loss: 1073.8075\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 1059.7137 - val_loss: 1046.9872\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 1033.0424 - val_loss: 1019.4288\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 1005.6706 - val_loss: 992.7563\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 978.7931 - val_loss: 965.5123\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 951.3561 - val_loss: 938.5178\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 5ms/step - loss: 924.6522 - val_loss: 911.7568\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 897.8319 - val_loss: 886.1572\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 871.8981 - val_loss: 860.3348\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 845.5392 - val_loss: 835.6344\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 820.3060 - val_loss: 810.6649\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 795.0129 - val_loss: 786.2988\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 770.2143 - val_loss: 762.9956\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 746.1812 - val_loss: 739.9473\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 722.7739 - val_loss: 716.9664\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 699.6031 - val_loss: 695.7370\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 8ms/step - loss: 677.4655 - val_loss: 675.1984\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 656.0052 - val_loss: 654.7712\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 5ms/step - loss: 635.0225 - val_loss: 635.3928\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 614.8232 - val_loss: 616.6420\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 595.3213 - val_loss: 598.8188\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 7ms/step - loss: 576.6563 - val_loss: 581.4822\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 558.5522 - val_loss: 564.9774\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 7ms/step - loss: 541.1676 - val_loss: 549.4874\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 12ms/step - loss: 524.8325 - val_loss: 534.4579\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 509.0078 - val_loss: 520.2063\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 101ms/step - loss: 1564.1404 - val_loss: 1594.4210\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1546.5333 - val_loss: 1578.3611\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1529.6151 - val_loss: 1562.1139\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1512.9248 - val_loss: 1546.1029\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1495.8370 - val_loss: 1530.4508\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1479.0773 - val_loss: 1513.7927\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1461.6055 - val_loss: 1496.5475\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1443.4187 - val_loss: 1478.9539\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1424.7538 - val_loss: 1459.9208\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1404.8744 - val_loss: 1440.0253\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 7ms/step - loss: 1384.0825 - val_loss: 1418.9933\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 1362.0426 - val_loss: 1396.5966\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1338.9746 - val_loss: 1372.8871\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 5ms/step - loss: 1314.5575 - val_loss: 1348.3198\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1289.0048 - val_loss: 1322.7711\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 1262.5638 - val_loss: 1295.1451\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1234.7629 - val_loss: 1266.4462\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1205.7445 - val_loss: 1237.6516\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 1176.0347 - val_loss: 1207.5875\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 1145.6436 - val_loss: 1176.2875\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 1114.0007 - val_loss: 1144.6613\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1082.1641 - val_loss: 1112.2599\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 5ms/step - loss: 1049.7740 - val_loss: 1079.5693\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 7ms/step - loss: 1017.0204 - val_loss: 1046.6177\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 984.2087 - val_loss: 1013.3419\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 951.1964 - val_loss: 979.9273\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 918.1326 - val_loss: 946.5208\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 885.2103 - val_loss: 913.4958\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 852.5152 - val_loss: 880.3622\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 820.0934 - val_loss: 847.1256\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 787.4959 - val_loss: 814.8544\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 755.6749 - val_loss: 783.3613\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 724.3168 - val_loss: 751.6579\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 693.2277 - val_loss: 720.5812\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 662.7973 - val_loss: 690.2826\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 633.2511 - val_loss: 660.3837\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 604.0078 - val_loss: 631.9310\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 5ms/step - loss: 575.9523 - val_loss: 603.2463\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 548.3983 - val_loss: 576.3009\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 522.1767 - val_loss: 550.1333\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 496.9997 - val_loss: 524.5444\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 472.4073 - val_loss: 501.3020\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 449.8554 - val_loss: 478.0844\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 5ms/step - loss: 427.6468 - val_loss: 457.1843\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 407.5827 - val_loss: 436.9150\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 388.0700 - val_loss: 418.8585\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 370.4359 - val_loss: 401.2863\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 353.6632 - val_loss: 385.3532\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 7ms/step - loss: 338.4502 - val_loss: 370.5267\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 324.1390 - val_loss: 357.2437\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 42ms/step - loss: 1575.1664 - val_loss: 1604.1323\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 5ms/step - loss: 1560.5773 - val_loss: 1589.9310\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 5ms/step - loss: 1546.1263 - val_loss: 1575.7758\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1531.8156 - val_loss: 1561.0375\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1517.1056 - val_loss: 1546.3118\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 7ms/step - loss: 1502.1434 - val_loss: 1530.8549\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1486.6855 - val_loss: 1514.6799\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1470.6279 - val_loss: 1497.7727\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 5ms/step - loss: 1453.9457 - val_loss: 1480.1500\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1436.4596 - val_loss: 1461.8324\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 5ms/step - loss: 1418.3229 - val_loss: 1442.5275\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1399.4958 - val_loss: 1421.9901\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1379.6666 - val_loss: 1400.7906\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 8ms/step - loss: 1359.1692 - val_loss: 1378.7445\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 12ms/step - loss: 1337.8435 - val_loss: 1355.8846\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 1315.8683 - val_loss: 1331.4935\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1292.5900 - val_loss: 1306.9869\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 13ms/step - loss: 1268.7318 - val_loss: 1281.0995\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1243.8610 - val_loss: 1254.5549\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 13ms/step - loss: 1218.3770 - val_loss: 1227.1292\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 13ms/step - loss: 1191.9111 - val_loss: 1199.2179\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1164.7573 - val_loss: 1170.6151\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1136.8401 - val_loss: 1140.8340\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 13ms/step - loss: 1107.9409 - val_loss: 1110.3947\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 12ms/step - loss: 1077.9557 - val_loss: 1078.8896\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 1047.6106 - val_loss: 1046.6426\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 1016.2908 - val_loss: 1013.4543\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 984.1337 - val_loss: 980.5887\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 951.6837 - val_loss: 947.4124\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 919.3524 - val_loss: 913.3399\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 886.3289 - val_loss: 879.9895\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 853.4274 - val_loss: 847.3323\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 821.2358 - val_loss: 815.0810\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 789.3226 - val_loss: 782.7089\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 7ms/step - loss: 757.9549 - val_loss: 751.3457\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 726.8641 - val_loss: 721.5732\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 697.2311 - val_loss: 692.1285\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 668.0135 - val_loss: 663.9883\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 639.8303 - val_loss: 636.8989\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 612.6431 - val_loss: 610.2788\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 586.3858 - val_loss: 585.0114\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 7ms/step - loss: 560.8621 - val_loss: 561.3149\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 536.8707 - val_loss: 537.9793\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 513.2006 - val_loss: 516.2886\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 491.1973 - val_loss: 495.3110\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 469.6112 - val_loss: 475.5703\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 449.4292 - val_loss: 456.8809\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 5ms/step - loss: 430.2123 - val_loss: 438.9493\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 411.6947 - val_loss: 422.6323\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 394.5306 - val_loss: 406.6845\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 43ms/step - loss: 1545.6835 - val_loss: 1581.1550\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1532.3037 - val_loss: 1567.6465\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1519.2961 - val_loss: 1554.5092\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1506.4185 - val_loss: 1541.5504\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1493.3763 - val_loss: 1528.6506\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1480.2751 - val_loss: 1515.0410\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1466.5573 - val_loss: 1501.1807\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1452.6458 - val_loss: 1486.4791\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1437.6580 - val_loss: 1471.4620\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1422.0497 - val_loss: 1455.2167\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 5ms/step - loss: 1405.1042 - val_loss: 1437.9047\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1386.9948 - val_loss: 1419.4476\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 8ms/step - loss: 1367.4603 - val_loss: 1399.4858\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1346.8389 - val_loss: 1377.8356\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1324.4945 - val_loss: 1355.2220\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1301.1344 - val_loss: 1330.7880\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1276.2777 - val_loss: 1305.5564\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1250.3936 - val_loss: 1278.6875\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1223.3066 - val_loss: 1250.8848\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 1195.7405 - val_loss: 1221.6467\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 1166.5193 - val_loss: 1191.9513\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 1136.8640 - val_loss: 1161.8971\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 1106.8586 - val_loss: 1131.1025\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 1076.8037 - val_loss: 1099.5364\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 1045.5533 - val_loss: 1069.1187\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 1015.4467 - val_loss: 1036.8242\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 983.9827 - val_loss: 1005.7428\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 953.3909 - val_loss: 974.7526\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 922.9963 - val_loss: 943.0713\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 7ms/step - loss: 892.5707 - val_loss: 911.7161\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 862.1324 - val_loss: 881.0565\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 831.8989 - val_loss: 849.4891\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 801.0984 - val_loss: 817.3731\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 769.6956 - val_loss: 785.3411\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 738.1357 - val_loss: 753.6292\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 7ms/step - loss: 707.0744 - val_loss: 720.9741\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 675.9125 - val_loss: 688.6817\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 644.9753 - val_loss: 657.8523\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 615.5851 - val_loss: 627.6467\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 586.9367 - val_loss: 598.2325\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 558.8788 - val_loss: 571.3775\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 533.0001 - val_loss: 544.6541\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 7ms/step - loss: 507.2816 - val_loss: 519.9225\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 483.2348 - val_loss: 496.3520\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 13ms/step - loss: 460.3186 - val_loss: 474.0365\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 438.4362 - val_loss: 453.6001\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 418.1393 - val_loss: 434.2024\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 14ms/step - loss: 398.9457 - val_loss: 416.3656\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 13ms/step - loss: 380.9857 - val_loss: 400.0977\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 13ms/step - loss: 364.3252 - val_loss: 384.6148\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 50ms/step - loss: 1517.7654 - val_loss: 1542.8110\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1502.7958 - val_loss: 1527.3636\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1487.4275 - val_loss: 1511.3234\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 5ms/step - loss: 1471.3429 - val_loss: 1494.5392\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1454.7181 - val_loss: 1476.7473\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1436.8945 - val_loss: 1457.9512\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 7ms/step - loss: 1417.9824 - val_loss: 1438.0432\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1398.0729 - val_loss: 1416.5188\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 5ms/step - loss: 1376.7858 - val_loss: 1394.0312\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1354.3702 - val_loss: 1370.3146\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1330.8425 - val_loss: 1344.8517\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1306.0143 - val_loss: 1318.4213\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1280.0551 - val_loss: 1290.8989\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1252.7958 - val_loss: 1263.1235\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 1225.0457 - val_loss: 1233.6942\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1195.7164 - val_loss: 1203.5840\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1165.6864 - val_loss: 1172.6035\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1135.0031 - val_loss: 1140.3052\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 1103.2982 - val_loss: 1108.5687\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 1071.6959 - val_loss: 1075.5698\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1039.2914 - val_loss: 1042.3199\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1006.5002 - val_loss: 1009.4896\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 974.0514 - val_loss: 975.6873\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 940.8676 - val_loss: 942.5861\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 908.2843 - val_loss: 909.6008\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 875.8263 - val_loss: 876.6068\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 843.6318 - val_loss: 844.2042\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 812.1209 - val_loss: 811.8956\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 780.7686 - val_loss: 780.9876\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 750.0668 - val_loss: 750.4847\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 720.3182 - val_loss: 720.0274\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 690.5583 - val_loss: 691.0604\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 662.4564 - val_loss: 662.4734\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 634.8506 - val_loss: 635.8272\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 608.4467 - val_loss: 609.7325\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 582.8970 - val_loss: 584.6755\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 558.1171 - val_loss: 560.5317\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 7ms/step - loss: 534.3581 - val_loss: 538.3824\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 511.9745 - val_loss: 516.2706\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 490.5415 - val_loss: 495.7505\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 469.9561 - val_loss: 476.4139\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 450.5795 - val_loss: 457.7770\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 431.8945 - val_loss: 440.4823\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 414.2619 - val_loss: 424.3824\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 397.5663 - val_loss: 409.2123\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 381.8546 - val_loss: 394.5612\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 366.7622 - val_loss: 381.4214\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 352.9605 - val_loss: 368.7721\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 339.5554 - val_loss: 357.4650\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 327.2029 - val_loss: 346.3966\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1622.7867 - val_loss: 1643.3689\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1606.4617 - val_loss: 1627.8818\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 5ms/step - loss: 1591.3287 - val_loss: 1612.5265\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1576.5151 - val_loss: 1597.5929\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 5ms/step - loss: 1561.7609 - val_loss: 1582.9999\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 5ms/step - loss: 1547.0049 - val_loss: 1567.8121\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1532.1010 - val_loss: 1552.2841\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 7ms/step - loss: 1516.7076 - val_loss: 1536.6069\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1501.0199 - val_loss: 1520.1185\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1484.6254 - val_loss: 1503.2296\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1467.6027 - val_loss: 1485.2684\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1449.7474 - val_loss: 1466.8258\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1431.2670 - val_loss: 1447.3020\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1411.7460 - val_loss: 1427.3234\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1391.7188 - val_loss: 1405.9795\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 5ms/step - loss: 1370.4274 - val_loss: 1384.4515\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 1348.5791 - val_loss: 1361.3541\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 7ms/step - loss: 1325.5016 - val_loss: 1337.3860\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 15ms/step - loss: 1301.5603 - val_loss: 1312.4637\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 1276.8099 - val_loss: 1286.4606\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 1250.9236 - val_loss: 1260.0928\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 1224.4430 - val_loss: 1232.5981\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 1196.9637 - val_loss: 1204.4618\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 1169.0088 - val_loss: 1175.1426\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 8ms/step - loss: 1139.8290 - val_loss: 1145.7261\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 12ms/step - loss: 1110.4191 - val_loss: 1115.7683\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 1080.7142 - val_loss: 1084.9650\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 13ms/step - loss: 1050.1678 - val_loss: 1054.0392\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 1019.6927 - val_loss: 1022.5362\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 8ms/step - loss: 988.2972 - val_loss: 991.2363\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 957.2219 - val_loss: 959.4988\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 925.7982 - val_loss: 928.1351\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 894.5810 - val_loss: 896.7216\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 863.1493 - val_loss: 865.2629\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 832.0118 - val_loss: 834.4443\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 801.2706 - val_loss: 804.6409\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 771.2386 - val_loss: 775.0128\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 5ms/step - loss: 741.4851 - val_loss: 746.4128\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 713.0317 - val_loss: 717.5462\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 684.1978 - val_loss: 690.4302\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 657.1532 - val_loss: 663.4617\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 630.1055 - val_loss: 638.0410\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 604.2945 - val_loss: 613.6029\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 579.6362 - val_loss: 589.6627\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 555.7980 - val_loss: 566.9379\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 533.0087 - val_loss: 545.4197\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 511.3094 - val_loss: 524.6425\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 490.2242 - val_loss: 504.6140\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 470.4969 - val_loss: 485.5836\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 451.3698 - val_loss: 468.4734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the mean and standard deviation of the mean squared errors\n",
        "mean_mse = np.mean(mean_squared_errors)\n",
        "std_mse = np.std(mean_squared_errors)\n",
        "\n",
        "print(\"Mean of Mean Squared Errors: {}\".format(mean_mse))\n",
        "print(\"Standard Deviation of Mean Squared Errors: {}\".format(std_mse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYcjTKWmV9B9",
        "outputId": "dbf3283e-e683-450a-a8c4-a07ceb5a4ee6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of Mean Squared Errors: 383.2719982910156\n",
            "Standard Deviation of Mean Squared Errors: 92.9439025403317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**C. Increasr the no. of Epoch**"
      ],
      "metadata": {
        "id": "bNxJ0mXMX7zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = data.drop('Strength' ,axis=1)\n",
        "target = data['Strength']\n",
        "\n",
        "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
        "predictors_norm.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Hpii0f3GY8IZ",
        "outputId": "01e44167-896a-49e3-a888-de93fca6fc81"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
              "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
              "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
              "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
              "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
              "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
              "\n",
              "   Coarse Aggregate  Fine Aggregate       Age  \n",
              "0          0.862735       -1.217079 -0.279597  \n",
              "1          1.055651       -1.217079 -0.279597  \n",
              "2         -0.526262       -2.239829  3.551340  \n",
              "3         -0.526262       -2.239829  5.055221  \n",
              "4          0.070492        0.647569  4.976069  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf050877-c6f5-4755-8224-6dea3fd25fc0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>0.862735</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>1.055651</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>3.551340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>5.055221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.790075</td>\n",
              "      <td>0.678079</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>0.488555</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>0.070492</td>\n",
              "      <td>0.647569</td>\n",
              "      <td>4.976069</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf050877-c6f5-4755-8224-6dea3fd25fc0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf050877-c6f5-4755-8224-6dea3fd25fc0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf050877-c6f5-4755-8224-6dea3fd25fc0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-76b6710a-b8f1-40d5-bb81-ae8392195802\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76b6710a-b8f1-40d5-bb81-ae8392195802')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-76b6710a-b8f1-40d5-bb81-ae8392195802 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "predictors_norm",
              "summary": "{\n  \"name\": \"predictors_norm\",\n  \"rows\": 1030,\n  \"fields\": [\n    {\n      \"column\": \"Cement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -1.7144205995851924,\n        \"max\": 2.476711702426229,\n        \"num_unique_values\": 278,\n        \"samples\": [\n          0.5428581904707304,\n          0.08642665895030859,\n          -0.18341336597371433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blast Furnace Slag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9999999999999999,\n        \"min\": -0.8564718244890963,\n        \"max\": 3.3090676049756658,\n        \"num_unique_values\": 185,\n        \"samples\": [\n          0.24112579368094536,\n          0.5227691106981788,\n          0.7232806079985139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fly Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -0.8467325968146493,\n        \"max\": 2.2799762647844055,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          0.6845890845282162,\n          1.3721212679882784,\n          2.200285034428808\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Water\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.798851260765261,\n        \"max\": 3.064158880238681,\n        \"num_unique_values\": 195,\n        \"samples\": [\n          0.647774509026194,\n          0.1045563170481933,\n          -2.541290911120519\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Superplasticizer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -1.0386382541022239,\n        \"max\": 4.351528287732031,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          1.4723088927149754,\n          3.681942381914111,\n          1.7234036073966954\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coarse Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.211063531411115,\n        \"max\": 2.213148774849662,\n        \"num_unique_values\": 284,\n        \"samples\": [\n          -1.553862226614819,\n          -0.7590473413621567,\n          -0.7577612331335922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fine Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.239829000131109,\n        \"max\": 2.7317347935640552,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          -0.7930116391962395,\n          -0.9751110656587321,\n          -0.05338862623556972\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -0.7070159638428309,\n        \"max\": 5.055221007679151,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.7177129576873293,\n          0.8601858498403454,\n          -0.27959728738378287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_cols = predictors_norm.shape[1]\n",
        "mean_squared_errors = []\n",
        "\n",
        "for i in range(50):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(predictors_norm, target,test_size=0.3, random_state=i)\n",
        "    model = regression_model()\n",
        "    model.fit(x_train, y_train, validation_data=(x_test, y_test) ,epochs=100, verbose=2)\n",
        "    mse = model.evaluate(x_test, y_test, verbose=0)\n",
        "    mean_squared_errors.append(mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxYXnDCDZORC",
        "outputId": "69be5df6-5d2b-4afc-ed16-b45961c357da"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 42ms/step - loss: 1542.3672 - val_loss: 1494.7559\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1524.2167 - val_loss: 1477.7223\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1505.8386 - val_loss: 1459.6432\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1486.6550 - val_loss: 1440.8828\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 7ms/step - loss: 1466.7079 - val_loss: 1421.0665\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1445.4988 - val_loss: 1400.7988\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1423.6337 - val_loss: 1378.9657\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1400.7035 - val_loss: 1356.1681\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1376.7534 - val_loss: 1332.2302\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 7ms/step - loss: 1351.6388 - val_loss: 1306.8892\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1325.1434 - val_loss: 1280.9031\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1297.7524 - val_loss: 1253.8928\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 1269.3073 - val_loss: 1225.7695\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1240.2445 - val_loss: 1196.1669\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 7ms/step - loss: 1209.4373 - val_loss: 1166.3909\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 1178.3802 - val_loss: 1135.6898\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 1146.4031 - val_loss: 1104.2775\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1113.8563 - val_loss: 1072.0789\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1080.9645 - val_loss: 1040.0576\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1047.7352 - val_loss: 1007.8146\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1014.3196 - val_loss: 974.9232\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 8ms/step - loss: 980.6135 - val_loss: 942.5145\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 947.2912 - val_loss: 909.6898\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 913.9913 - val_loss: 876.5831\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 7ms/step - loss: 880.4026 - val_loss: 844.6511\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 847.4328 - val_loss: 812.6530\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 12ms/step - loss: 814.8522 - val_loss: 781.2828\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 13ms/step - loss: 782.7077 - val_loss: 750.5965\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 5ms/step - loss: 751.3895 - val_loss: 720.2972\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 720.7599 - val_loss: 690.8453\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 13ms/step - loss: 691.3235 - val_loss: 661.9731\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 661.9551 - val_loss: 634.5834\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 9ms/step - loss: 633.9691 - val_loss: 607.7600\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 11ms/step - loss: 606.9332 - val_loss: 581.7604\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 581.0079 - val_loss: 556.3021\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 555.7882 - val_loss: 532.0448\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 531.6743 - val_loss: 509.1221\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 508.5680 - val_loss: 486.8872\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 486.4621 - val_loss: 465.7946\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 465.4132 - val_loss: 445.4579\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 445.3886 - val_loss: 425.5696\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 426.3986 - val_loss: 406.8143\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 7ms/step - loss: 408.0337 - val_loss: 389.8554\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 391.2137 - val_loss: 373.1623\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 375.1884 - val_loss: 357.3298\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 360.0190 - val_loss: 342.8101\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 345.9155 - val_loss: 328.6291\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 332.5490 - val_loss: 315.5064\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 319.8917 - val_loss: 303.2269\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 308.2957 - val_loss: 291.4942\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 297.2351 - val_loss: 280.6261\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 286.9394 - val_loss: 270.7373\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 277.6063 - val_loss: 261.4230\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 268.7723 - val_loss: 252.5733\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 260.6536 - val_loss: 244.3647\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 253.0402 - val_loss: 236.9055\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 5ms/step - loss: 246.0233 - val_loss: 230.0323\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 239.6105 - val_loss: 223.3929\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 233.5327 - val_loss: 217.3924\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 228.0213 - val_loss: 211.7350\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 222.8427 - val_loss: 206.6656\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 218.1698 - val_loss: 201.7548\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 213.7256 - val_loss: 197.3786\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 209.5486 - val_loss: 193.4855\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.6923 - val_loss: 189.5719\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.2336 - val_loss: 185.7510\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.7868 - val_loss: 182.5213\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.7785 - val_loss: 179.5545\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.0438 - val_loss: 176.6213\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.3527 - val_loss: 174.1841\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.9955 - val_loss: 171.8642\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.7946 - val_loss: 169.6023\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.7292 - val_loss: 167.4547\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 181.8157 - val_loss: 165.6188\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 180.0143 - val_loss: 164.0509\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.4059 - val_loss: 162.5453\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.9095 - val_loss: 160.7757\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 175.3750 - val_loss: 159.4227\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 174.0363 - val_loss: 158.1496\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 172.6577 - val_loss: 156.9700\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.4676 - val_loss: 155.8491\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.2934 - val_loss: 154.6865\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.2235 - val_loss: 153.7460\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.2343 - val_loss: 152.7055\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.2628 - val_loss: 151.8072\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.3131 - val_loss: 150.9417\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.4311 - val_loss: 150.2030\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.5507 - val_loss: 149.5406\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.7111 - val_loss: 148.7084\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.9326 - val_loss: 147.9007\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 162.1742 - val_loss: 147.3085\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.5131 - val_loss: 146.6357\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.8177 - val_loss: 145.9133\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.1969 - val_loss: 145.3254\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.5502 - val_loss: 144.7324\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 7ms/step - loss: 158.8279 - val_loss: 143.9918\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 158.2460 - val_loss: 143.5211\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.5626 - val_loss: 142.9472\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.9490 - val_loss: 142.2888\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.3488 - val_loss: 141.7814\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1562.3197 - val_loss: 1584.5663\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 1543.5574 - val_loss: 1565.3441\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1525.5990 - val_loss: 1546.3749\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 1507.7240 - val_loss: 1527.9597\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 7ms/step - loss: 1490.7690 - val_loss: 1509.4036\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 12ms/step - loss: 1473.4861 - val_loss: 1491.3647\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1456.6847 - val_loss: 1473.4545\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 7ms/step - loss: 1439.9136 - val_loss: 1455.4468\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 1423.0125 - val_loss: 1436.7029\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1405.5857 - val_loss: 1418.0114\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 13ms/step - loss: 1388.1094 - val_loss: 1398.7302\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1370.0784 - val_loss: 1379.0972\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1351.7247 - val_loss: 1359.1664\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 15ms/step - loss: 1332.9250 - val_loss: 1338.6797\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1313.7086 - val_loss: 1317.3558\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1293.7113 - val_loss: 1295.9189\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1273.2379 - val_loss: 1273.7358\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1252.2390 - val_loss: 1250.8362\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1230.7788 - val_loss: 1227.2031\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 1208.6705 - val_loss: 1203.4390\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1186.0874 - val_loss: 1179.7373\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1163.3016 - val_loss: 1154.9335\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1140.0804 - val_loss: 1129.5096\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 1116.1174 - val_loss: 1104.7484\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1092.4944 - val_loss: 1079.1832\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 1068.2316 - val_loss: 1053.9032\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 1043.8068 - val_loss: 1028.4631\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 1019.4070 - val_loss: 1002.7347\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 994.5996 - val_loss: 977.4077\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 970.2845 - val_loss: 951.6580\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 945.4075 - val_loss: 926.7516\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 920.9322 - val_loss: 901.3710\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 896.4509 - val_loss: 876.3662\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 872.1451 - val_loss: 851.8913\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 848.3395 - val_loss: 827.6534\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 824.6700 - val_loss: 803.7179\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 801.1318 - val_loss: 780.4473\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 777.9910 - val_loss: 757.4957\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 755.3502 - val_loss: 734.7289\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 732.7189 - val_loss: 712.7664\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 710.6172 - val_loss: 690.8053\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 688.7406 - val_loss: 669.1431\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 5ms/step - loss: 667.0280 - val_loss: 648.2687\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 646.0066 - val_loss: 627.2157\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 624.8015 - val_loss: 607.3559\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 603.9694 - val_loss: 587.6951\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 583.5829 - val_loss: 567.6310\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 5ms/step - loss: 563.1164 - val_loss: 548.4340\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 543.2130 - val_loss: 529.6977\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 5ms/step - loss: 523.6729 - val_loss: 511.1642\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 504.5630 - val_loss: 493.2570\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 485.4687 - val_loss: 476.5541\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 467.5281 - val_loss: 459.6468\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 449.7775 - val_loss: 443.9192\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 433.0476 - val_loss: 428.6596\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 416.7767 - val_loss: 414.7947\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 401.5750 - val_loss: 401.1990\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 386.9080 - val_loss: 388.6462\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 373.0757 - val_loss: 377.0188\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 360.2630 - val_loss: 365.9409\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 7ms/step - loss: 348.1762 - val_loss: 355.9302\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 336.9890 - val_loss: 346.3094\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 326.2395 - val_loss: 337.7670\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 316.4582 - val_loss: 329.3415\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 307.2982 - val_loss: 321.5439\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 298.5766 - val_loss: 314.4803\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 290.5611 - val_loss: 307.8393\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 283.1985 - val_loss: 301.6302\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 276.0963 - val_loss: 295.9128\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 269.6940 - val_loss: 290.5324\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 263.5874 - val_loss: 285.4203\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 258.0908 - val_loss: 280.6209\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 252.6382 - val_loss: 276.2685\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 247.6573 - val_loss: 271.9645\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 243.0201 - val_loss: 268.0242\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 238.6012 - val_loss: 264.2269\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 234.5506 - val_loss: 260.6633\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 230.5956 - val_loss: 257.0823\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 7ms/step - loss: 226.9819 - val_loss: 253.8533\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 223.4598 - val_loss: 250.6957\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 220.1886 - val_loss: 247.7791\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 5ms/step - loss: 217.1443 - val_loss: 244.9590\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 214.1155 - val_loss: 242.2745\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 211.4319 - val_loss: 239.6594\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.7505 - val_loss: 237.0110\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.1674 - val_loss: 234.5227\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.0799 - val_loss: 232.0411\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 201.4973 - val_loss: 229.8125\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 199.2939 - val_loss: 227.7958\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 197.2542 - val_loss: 225.5084\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.2441 - val_loss: 223.3605\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.2545 - val_loss: 221.3113\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 8ms/step - loss: 191.3284 - val_loss: 219.4619\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 189.5114 - val_loss: 217.6013\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 11ms/step - loss: 187.7977 - val_loss: 215.7973\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.1054 - val_loss: 213.9423\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.4634 - val_loss: 212.1692\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.9417 - val_loss: 210.3494\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.2711 - val_loss: 208.7110\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.7192 - val_loss: 207.0420\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 55ms/step - loss: 1602.5623 - val_loss: 1539.5551\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1588.9319 - val_loss: 1526.8915\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1575.9572 - val_loss: 1514.6785\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1563.4368 - val_loss: 1502.7576\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1551.0486 - val_loss: 1491.2346\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 7ms/step - loss: 1538.8967 - val_loss: 1479.5659\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1526.5758 - val_loss: 1467.6343\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1514.0011 - val_loss: 1455.1603\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1500.8365 - val_loss: 1442.5638\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1487.1915 - val_loss: 1429.1593\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1472.8738 - val_loss: 1414.7129\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 7ms/step - loss: 1457.3557 - val_loss: 1399.3085\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1440.8646 - val_loss: 1382.6252\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 5ms/step - loss: 1422.6211 - val_loss: 1364.4514\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 7ms/step - loss: 1402.7797 - val_loss: 1344.8983\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1381.0504 - val_loss: 1323.3740\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1357.4711 - val_loss: 1300.6149\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 5ms/step - loss: 1332.6533 - val_loss: 1275.3845\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1305.5695 - val_loss: 1249.5952\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1277.4323 - val_loss: 1222.2999\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 5ms/step - loss: 1247.8091 - val_loss: 1193.0825\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1216.8231 - val_loss: 1162.9355\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1184.4244 - val_loss: 1132.9395\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1151.5731 - val_loss: 1101.4369\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1117.7841 - val_loss: 1070.2108\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 1083.5164 - val_loss: 1037.9331\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 1048.6987 - val_loss: 1005.5659\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 1013.2422 - val_loss: 973.1087\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 978.2152 - val_loss: 940.0505\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 942.2111 - val_loss: 907.3119\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 906.0505 - val_loss: 874.3799\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 869.6634 - val_loss: 840.8164\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 832.6801 - val_loss: 807.3850\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 5ms/step - loss: 795.5143 - val_loss: 774.3284\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 758.7531 - val_loss: 741.2388\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 722.0845 - val_loss: 708.5211\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 686.4734 - val_loss: 675.2510\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 650.8386 - val_loss: 643.5742\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 5ms/step - loss: 616.6597 - val_loss: 612.9128\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 583.8673 - val_loss: 582.7484\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 551.5320 - val_loss: 554.3346\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 521.1113 - val_loss: 526.7250\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 5ms/step - loss: 491.6963 - val_loss: 500.6228\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 464.1057 - val_loss: 475.6504\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 438.4032 - val_loss: 451.3043\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 413.6213 - val_loss: 429.3678\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 391.2292 - val_loss: 408.2126\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 370.5294 - val_loss: 388.3519\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 351.1864 - val_loss: 370.6327\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 333.9411 - val_loss: 353.8981\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 318.0693 - val_loss: 338.6917\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 303.8620 - val_loss: 324.4558\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 290.7978 - val_loss: 311.8672\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 279.4307 - val_loss: 300.0241\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 269.1604 - val_loss: 289.2575\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 7ms/step - loss: 259.9047 - val_loss: 279.6912\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 251.6629 - val_loss: 271.3468\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 244.4147 - val_loss: 262.7630\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 237.7899 - val_loss: 255.3191\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 231.9355 - val_loss: 248.5384\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 226.4621 - val_loss: 242.6634\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 221.6450 - val_loss: 237.0136\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 217.2626 - val_loss: 231.7969\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 213.2141 - val_loss: 227.2159\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 209.7510 - val_loss: 222.7371\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.5384 - val_loss: 218.5210\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 203.3198 - val_loss: 215.0546\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 200.5735 - val_loss: 211.5159\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 197.9185 - val_loss: 208.3351\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.3523 - val_loss: 205.5564\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 192.9403 - val_loss: 202.5609\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 190.6446 - val_loss: 199.8239\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 188.4108 - val_loss: 197.2454\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 186.3891 - val_loss: 194.6753\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 8ms/step - loss: 184.3201 - val_loss: 192.4996\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 11ms/step - loss: 182.5190 - val_loss: 190.3826\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.8298 - val_loss: 188.3495\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 7ms/step - loss: 179.0864 - val_loss: 186.6174\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.5257 - val_loss: 184.6371\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.9766 - val_loss: 183.0700\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.6028 - val_loss: 181.3371\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 13ms/step - loss: 173.2255 - val_loss: 179.8204\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 13ms/step - loss: 171.9276 - val_loss: 178.3774\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 8ms/step - loss: 170.6352 - val_loss: 177.1806\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 11ms/step - loss: 169.4282 - val_loss: 175.6402\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.1929 - val_loss: 174.4045\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.0657 - val_loss: 173.1488\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.9279 - val_loss: 171.8797\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 164.7659 - val_loss: 170.6531\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 163.7131 - val_loss: 169.4743\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.6036 - val_loss: 168.3549\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.5953 - val_loss: 167.1956\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.5741 - val_loss: 166.3878\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 5ms/step - loss: 159.6399 - val_loss: 165.1746\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.6711 - val_loss: 164.2967\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.7022 - val_loss: 163.3021\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.7069 - val_loss: 162.2089\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.7546 - val_loss: 161.1441\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.8626 - val_loss: 160.1216\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.8412 - val_loss: 159.1425\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1597.8945 - val_loss: 1591.5663\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 1580.0305 - val_loss: 1575.1921\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1562.8804 - val_loss: 1559.3160\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1546.1956 - val_loss: 1543.7932\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1529.7335 - val_loss: 1528.4220\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1513.4067 - val_loss: 1512.9484\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1496.8027 - val_loss: 1497.2291\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1480.0663 - val_loss: 1480.9648\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1462.8181 - val_loss: 1464.5693\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1445.3010 - val_loss: 1447.4811\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 1427.1184 - val_loss: 1429.8234\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 1408.5116 - val_loss: 1411.5210\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1389.2849 - val_loss: 1392.7948\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1369.6261 - val_loss: 1373.2119\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1349.1318 - val_loss: 1352.8921\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1328.0059 - val_loss: 1331.9867\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 1306.4746 - val_loss: 1310.2042\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 1284.2163 - val_loss: 1287.7253\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1261.1033 - val_loss: 1264.8461\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1237.5082 - val_loss: 1241.1084\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1213.3961 - val_loss: 1216.4573\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1188.5869 - val_loss: 1191.1505\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1162.7892 - val_loss: 1165.3276\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 1136.8467 - val_loss: 1138.5002\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1110.2296 - val_loss: 1111.0908\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 1082.8322 - val_loss: 1083.6365\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 1055.2418 - val_loss: 1055.4368\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 1027.0875 - val_loss: 1026.3856\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 998.4127 - val_loss: 997.4937\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 5ms/step - loss: 969.5140 - val_loss: 967.5862\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 940.3651 - val_loss: 937.6090\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 7ms/step - loss: 911.1871 - val_loss: 907.7745\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 882.3226 - val_loss: 878.2132\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 853.2894 - val_loss: 849.4623\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 825.0693 - val_loss: 819.7467\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 796.6842 - val_loss: 790.8112\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 768.7985 - val_loss: 762.6633\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 741.4283 - val_loss: 734.1025\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 714.5091 - val_loss: 706.4789\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 688.5995 - val_loss: 679.1599\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 662.6332 - val_loss: 653.5695\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 637.9087 - val_loss: 628.6558\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 613.9830 - val_loss: 604.2862\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 590.8045 - val_loss: 580.6293\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 568.2960 - val_loss: 557.9281\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 546.9188 - val_loss: 535.6211\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 526.1239 - val_loss: 514.4741\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 506.3046 - val_loss: 494.4863\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 487.3744 - val_loss: 474.7185\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 469.0912 - val_loss: 456.0397\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 451.7889 - val_loss: 438.1954\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 435.1128 - val_loss: 421.7265\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 419.6758 - val_loss: 405.4734\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 404.4364 - val_loss: 390.5330\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 7ms/step - loss: 390.3942 - val_loss: 376.1650\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 7ms/step - loss: 376.8304 - val_loss: 362.9195\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 364.3056 - val_loss: 349.7575\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 351.9419 - val_loss: 337.7558\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 340.5572 - val_loss: 326.5940\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 329.7902 - val_loss: 316.0671\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 319.5454 - val_loss: 306.1436\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 310.1973 - val_loss: 296.8484\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 301.1848 - val_loss: 288.0269\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 13ms/step - loss: 292.6383 - val_loss: 280.1876\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 8ms/step - loss: 284.8595 - val_loss: 272.9720\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 13ms/step - loss: 277.7033 - val_loss: 265.8345\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 12ms/step - loss: 270.6575 - val_loss: 259.5878\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 10ms/step - loss: 264.1931 - val_loss: 253.9824\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 258.1895 - val_loss: 248.7701\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 252.5560 - val_loss: 243.6639\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 247.3372 - val_loss: 238.7990\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 242.3206 - val_loss: 234.5745\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 237.7655 - val_loss: 230.6013\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 233.4113 - val_loss: 227.2659\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 229.3895 - val_loss: 223.9865\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.6730 - val_loss: 221.1508\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.1329 - val_loss: 218.2442\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 218.8829 - val_loss: 215.4447\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.7046 - val_loss: 213.0846\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 212.6809 - val_loss: 210.7017\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 209.8560 - val_loss: 208.4710\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 5ms/step - loss: 207.1777 - val_loss: 206.4550\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 204.5717 - val_loss: 204.5534\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.0846 - val_loss: 202.7458\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.7713 - val_loss: 201.0968\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 197.5316 - val_loss: 199.2785\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.3112 - val_loss: 197.7006\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 193.3220 - val_loss: 196.1101\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 191.3124 - val_loss: 194.6139\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.3312 - val_loss: 193.1957\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 187.5913 - val_loss: 191.7050\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 185.7025 - val_loss: 190.3666\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.9888 - val_loss: 188.8987\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 182.2599 - val_loss: 187.5286\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.6448 - val_loss: 186.1477\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.0177 - val_loss: 184.8868\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 177.4366 - val_loss: 183.5305\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.8251 - val_loss: 182.2230\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.3054 - val_loss: 180.8992\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 172.7911 - val_loss: 179.6497\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1573.0061 - val_loss: 1510.0593\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1557.1614 - val_loss: 1494.9666\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1541.2798 - val_loss: 1479.8813\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1525.3557 - val_loss: 1464.4000\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1508.9550 - val_loss: 1448.9429\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1492.3689 - val_loss: 1432.6812\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1474.9476 - val_loss: 1415.8164\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1456.5997 - val_loss: 1398.1891\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1437.3887 - val_loss: 1379.6487\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1417.2708 - val_loss: 1359.9401\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 1396.0648 - val_loss: 1339.4337\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 1373.8755 - val_loss: 1317.8535\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 1350.5450 - val_loss: 1295.4154\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1326.0875 - val_loss: 1272.0964\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1300.6490 - val_loss: 1247.6359\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 1274.0472 - val_loss: 1222.7010\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1246.7124 - val_loss: 1196.6283\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1218.2526 - val_loss: 1170.2426\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1189.0477 - val_loss: 1143.0643\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 1159.2961 - val_loss: 1115.0011\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1128.7845 - val_loss: 1085.9314\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1096.9580 - val_loss: 1057.5298\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1065.4481 - val_loss: 1027.8580\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1033.1810 - val_loss: 998.1510\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1000.8264 - val_loss: 967.9988\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 967.8413 - val_loss: 938.4968\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 935.1776 - val_loss: 908.1307\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 901.8755 - val_loss: 877.8890\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 868.7657 - val_loss: 847.6295\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 835.8781 - val_loss: 817.0740\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 803.1990 - val_loss: 787.3108\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 771.3105 - val_loss: 757.6533\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 739.7459 - val_loss: 729.1827\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 708.8565 - val_loss: 700.8962\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 13ms/step - loss: 678.5366 - val_loss: 673.0146\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 648.7578 - val_loss: 646.3745\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 620.3085 - val_loss: 619.3100\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 592.0758 - val_loss: 594.3445\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 12ms/step - loss: 565.5443 - val_loss: 569.8608\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 540.0056 - val_loss: 545.5746\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 515.0839 - val_loss: 522.9872\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 13ms/step - loss: 491.3479 - val_loss: 501.7944\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 15ms/step - loss: 469.5091 - val_loss: 480.5019\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 11ms/step - loss: 447.8470 - val_loss: 461.0298\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 11ms/step - loss: 427.4715 - val_loss: 442.8479\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 408.4758 - val_loss: 425.0279\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 390.3729 - val_loss: 408.3557\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 373.4898 - val_loss: 392.9058\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 357.6716 - val_loss: 378.2230\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 342.9125 - val_loss: 364.0881\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 328.9572 - val_loss: 351.0634\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 315.6946 - val_loss: 339.2772\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 303.8556 - val_loss: 327.8080\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 292.4774 - val_loss: 317.7714\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 282.4388 - val_loss: 307.6605\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 272.5190 - val_loss: 298.9726\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 263.8151 - val_loss: 290.6407\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 255.7156 - val_loss: 282.8879\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 248.1420 - val_loss: 275.7993\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 241.2909 - val_loss: 269.0591\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 235.0148 - val_loss: 262.8122\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 228.9781 - val_loss: 257.1281\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.5041 - val_loss: 251.9770\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 218.5456 - val_loss: 247.0962\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 214.0487 - val_loss: 242.6883\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 209.8134 - val_loss: 238.5214\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.0489 - val_loss: 234.6884\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.4793 - val_loss: 231.4740\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.4488 - val_loss: 228.1812\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 196.5004 - val_loss: 225.2774\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.8429 - val_loss: 222.6696\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.4023 - val_loss: 220.2441\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 7ms/step - loss: 189.1362 - val_loss: 217.9182\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 5ms/step - loss: 186.9745 - val_loss: 215.8545\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.0105 - val_loss: 213.8771\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.1073 - val_loss: 211.9228\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.3465 - val_loss: 210.1030\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.7124 - val_loss: 208.4170\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.1266 - val_loss: 206.8615\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 176.7359 - val_loss: 205.0487\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 175.1451 - val_loss: 203.6197\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.7848 - val_loss: 202.1373\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.3690 - val_loss: 200.6471\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 171.0152 - val_loss: 199.2792\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 5ms/step - loss: 169.7355 - val_loss: 197.8645\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.5210 - val_loss: 196.4686\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.2343 - val_loss: 195.2406\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.9828 - val_loss: 193.9503\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 164.6913 - val_loss: 192.6417\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.4953 - val_loss: 191.2691\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.2740 - val_loss: 189.9938\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.0933 - val_loss: 188.7108\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.9159 - val_loss: 187.4688\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.7245 - val_loss: 186.2365\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.6878 - val_loss: 184.9899\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 7ms/step - loss: 156.4047 - val_loss: 183.8382\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.3130 - val_loss: 182.7052\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 154.2044 - val_loss: 181.4233\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.1412 - val_loss: 180.3674\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 7ms/step - loss: 151.9949 - val_loss: 179.2437\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1563.5935 - val_loss: 1463.6731\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1549.4681 - val_loss: 1449.8334\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1535.4679 - val_loss: 1435.8292\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1521.3619 - val_loss: 1421.4984\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1506.9116 - val_loss: 1406.6482\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1491.6348 - val_loss: 1391.2826\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 5ms/step - loss: 1475.6011 - val_loss: 1374.8276\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1458.5591 - val_loss: 1356.9768\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1439.7368 - val_loss: 1338.0504\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1419.4795 - val_loss: 1317.7778\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 1397.8849 - val_loss: 1296.1968\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 8ms/step - loss: 1374.5438 - val_loss: 1273.5533\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 12ms/step - loss: 1349.8350 - val_loss: 1249.9354\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 8ms/step - loss: 1323.6617 - val_loss: 1224.7385\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 12ms/step - loss: 1295.9634 - val_loss: 1198.8152\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1267.4030 - val_loss: 1171.7094\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1237.3727 - val_loss: 1143.7775\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1205.8674 - val_loss: 1115.3423\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 15ms/step - loss: 1173.9672 - val_loss: 1085.7241\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 13ms/step - loss: 1141.2614 - val_loss: 1055.1614\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 12ms/step - loss: 1107.4984 - val_loss: 1024.3175\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1073.1476 - val_loss: 992.7643\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 1038.1400 - val_loss: 960.5933\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 5ms/step - loss: 1002.6176 - val_loss: 928.2286\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 966.5769 - val_loss: 895.4590\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 930.0995 - val_loss: 862.6932\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 893.5505 - val_loss: 829.6644\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 857.0764 - val_loss: 796.5822\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 820.4317 - val_loss: 764.3582\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 785.1907 - val_loss: 731.2491\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 5ms/step - loss: 749.2018 - val_loss: 699.6270\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 714.3997 - val_loss: 668.7183\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 5ms/step - loss: 680.9933 - val_loss: 638.1331\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 648.1423 - val_loss: 608.7184\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 616.2703 - val_loss: 580.3520\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 585.7392 - val_loss: 552.8428\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 556.4831 - val_loss: 526.7618\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 529.0884 - val_loss: 501.3489\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 5ms/step - loss: 502.1881 - val_loss: 478.0653\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 477.4334 - val_loss: 455.3452\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 453.9853 - val_loss: 434.0803\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 431.8773 - val_loss: 414.1308\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 411.2597 - val_loss: 395.2896\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 392.1858 - val_loss: 377.5444\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 374.1324 - val_loss: 361.3948\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 357.8364 - val_loss: 346.1745\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 342.9428 - val_loss: 331.4608\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 328.5900 - val_loss: 318.4465\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 315.9464 - val_loss: 306.6254\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 304.3292 - val_loss: 295.1839\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 293.4061 - val_loss: 285.0466\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 283.7801 - val_loss: 274.9065\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 274.7566 - val_loss: 266.2067\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 5ms/step - loss: 266.5343 - val_loss: 258.3802\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 259.3791 - val_loss: 250.6835\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 252.3844 - val_loss: 243.8264\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 5ms/step - loss: 246.2013 - val_loss: 237.1813\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 240.4268 - val_loss: 231.3111\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 235.3509 - val_loss: 225.7745\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 230.5846 - val_loss: 220.8639\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 226.1948 - val_loss: 216.4476\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 5ms/step - loss: 222.2418 - val_loss: 211.8691\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 218.4007 - val_loss: 208.0126\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 214.9748 - val_loss: 204.2181\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 211.5992 - val_loss: 200.7142\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 208.4572 - val_loss: 197.2626\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 205.3754 - val_loss: 194.0782\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 7ms/step - loss: 202.6478 - val_loss: 191.0347\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 5ms/step - loss: 200.0227 - val_loss: 188.1643\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.3960 - val_loss: 185.6315\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.0186 - val_loss: 183.1436\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 192.7862 - val_loss: 180.7578\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.5091 - val_loss: 178.7662\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.4531 - val_loss: 176.5115\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 186.4066 - val_loss: 174.7541\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.4084 - val_loss: 172.6397\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 5ms/step - loss: 182.5434 - val_loss: 170.8891\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 7ms/step - loss: 180.5951 - val_loss: 168.9309\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.7609 - val_loss: 167.1653\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.9517 - val_loss: 165.6795\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 175.2597 - val_loss: 164.0874\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.5837 - val_loss: 162.5231\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.8952 - val_loss: 161.0659\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 170.3124 - val_loss: 159.7247\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.7474 - val_loss: 158.3904\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.2437 - val_loss: 156.8971\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.7365 - val_loss: 155.5585\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.2651 - val_loss: 154.4493\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.8445 - val_loss: 153.2064\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 161.5397 - val_loss: 151.9565\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.1876 - val_loss: 150.8416\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.8784 - val_loss: 149.6945\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.6146 - val_loss: 148.8063\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 156.3930 - val_loss: 147.6271\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.1135 - val_loss: 146.9156\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.9206 - val_loss: 145.9594\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 152.7182 - val_loss: 145.0465\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.5419 - val_loss: 143.9091\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 150.2626 - val_loss: 143.2940\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 12ms/step - loss: 149.1210 - val_loss: 142.3450\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 57ms/step - loss: 1553.0087 - val_loss: 1789.6689\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 19ms/step - loss: 1538.1921 - val_loss: 1774.7617\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 11ms/step - loss: 1524.5317 - val_loss: 1761.0409\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1511.8326 - val_loss: 1748.1511\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1499.8547 - val_loss: 1735.8153\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1488.3237 - val_loss: 1723.6542\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1476.9972 - val_loss: 1711.5677\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1465.7616 - val_loss: 1699.4160\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1454.3656 - val_loss: 1686.9503\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1442.6182 - val_loss: 1674.1760\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1430.5354 - val_loss: 1660.7179\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1417.8784 - val_loss: 1646.2963\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1404.3461 - val_loss: 1630.8020\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1389.8391 - val_loss: 1614.0928\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1374.3627 - val_loss: 1595.9760\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1357.5104 - val_loss: 1576.7639\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1339.7728 - val_loss: 1556.1350\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 1320.7839 - val_loss: 1534.2847\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1300.5505 - val_loss: 1511.4384\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 1279.6537 - val_loss: 1486.9956\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1257.4757 - val_loss: 1461.8014\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1234.3221 - val_loss: 1436.0082\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1210.8256 - val_loss: 1408.5935\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1186.3314 - val_loss: 1380.9944\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 7ms/step - loss: 1161.3726 - val_loss: 1352.2197\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 1135.4221 - val_loss: 1323.2975\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 7ms/step - loss: 1109.4745 - val_loss: 1293.6927\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 1083.2076 - val_loss: 1262.8848\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 1056.1324 - val_loss: 1233.0140\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 1029.4050 - val_loss: 1203.1653\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 1002.5668 - val_loss: 1172.1508\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 975.4257 - val_loss: 1141.4147\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 948.2311 - val_loss: 1111.2847\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 921.6345 - val_loss: 1080.0206\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 894.6433 - val_loss: 1049.9698\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 7ms/step - loss: 868.2402 - val_loss: 1019.6513\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 841.7762 - val_loss: 990.1569\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 816.1030 - val_loss: 960.3142\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 790.4396 - val_loss: 930.8074\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 765.0198 - val_loss: 902.6273\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 740.5176 - val_loss: 874.3354\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 716.0134 - val_loss: 847.1302\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 692.5884 - val_loss: 819.6411\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 5ms/step - loss: 669.4463 - val_loss: 793.1916\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 646.5280 - val_loss: 767.4709\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 624.6215 - val_loss: 742.2560\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 603.0650 - val_loss: 718.3065\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 582.3210 - val_loss: 694.7673\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 562.4810 - val_loss: 671.1039\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 542.5644 - val_loss: 649.5793\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 7ms/step - loss: 524.1451 - val_loss: 627.5429\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 5ms/step - loss: 505.8492 - val_loss: 606.8860\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 488.1494 - val_loss: 587.3875\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 471.2791 - val_loss: 568.2638\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 454.9535 - val_loss: 549.5186\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 439.2222 - val_loss: 531.4496\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 423.9464 - val_loss: 514.2349\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 409.1618 - val_loss: 498.2503\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 5ms/step - loss: 395.2800 - val_loss: 481.7113\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 381.3722 - val_loss: 467.0835\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 368.5059 - val_loss: 452.2644\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 7ms/step - loss: 355.9412 - val_loss: 438.5932\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 344.1053 - val_loss: 425.2021\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 332.6021 - val_loss: 412.3036\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 321.7072 - val_loss: 400.3416\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 311.4761 - val_loss: 388.6140\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 301.6361 - val_loss: 377.9056\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 292.5103 - val_loss: 367.5464\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 283.5930 - val_loss: 357.6556\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 275.3833 - val_loss: 348.4417\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 267.6288 - val_loss: 339.7734\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 7ms/step - loss: 260.2822 - val_loss: 331.5447\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 253.3918 - val_loss: 323.8845\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 247.0252 - val_loss: 316.2118\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 5ms/step - loss: 240.8004 - val_loss: 309.7571\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 235.1845 - val_loss: 303.1554\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 5ms/step - loss: 229.8409 - val_loss: 297.0815\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 8ms/step - loss: 224.8228 - val_loss: 291.3468\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 12ms/step - loss: 220.1577 - val_loss: 285.9097\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.6857 - val_loss: 280.7879\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 211.6355 - val_loss: 275.8917\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 207.7593 - val_loss: 271.5060\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.1690 - val_loss: 267.3039\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 200.7984 - val_loss: 262.7265\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 8ms/step - loss: 197.6064 - val_loss: 258.9409\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 12ms/step - loss: 194.4606 - val_loss: 255.2751\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 13ms/step - loss: 191.6216 - val_loss: 251.7473\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 12ms/step - loss: 188.9474 - val_loss: 247.8674\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.2672 - val_loss: 244.8507\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 11ms/step - loss: 183.7736 - val_loss: 241.4371\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 181.4213 - val_loss: 238.4849\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 5ms/step - loss: 179.1556 - val_loss: 235.5317\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.9938 - val_loss: 232.9121\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.0094 - val_loss: 229.9722\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 173.0002 - val_loss: 227.5575\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.1670 - val_loss: 224.9415\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 169.3031 - val_loss: 222.5897\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 167.5306 - val_loss: 219.8082\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.8160 - val_loss: 217.3017\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.0783 - val_loss: 215.0175\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 1553.5891 - val_loss: 1473.6464\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1536.0317 - val_loss: 1455.0042\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1518.0288 - val_loss: 1436.2362\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1499.5729 - val_loss: 1416.6814\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1480.4274 - val_loss: 1395.7948\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 7ms/step - loss: 1460.1901 - val_loss: 1374.5416\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1439.0746 - val_loss: 1352.4482\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 7ms/step - loss: 1417.0599 - val_loss: 1328.7074\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1393.7635 - val_loss: 1304.4111\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1369.7985 - val_loss: 1278.4292\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1344.2994 - val_loss: 1251.9510\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 1317.8722 - val_loss: 1224.2064\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 1290.2756 - val_loss: 1194.8478\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1261.4386 - val_loss: 1164.4016\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1231.6782 - val_loss: 1133.1873\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 1201.2015 - val_loss: 1101.1918\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1169.7043 - val_loss: 1068.5829\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 1137.4374 - val_loss: 1035.1863\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 7ms/step - loss: 1104.6091 - val_loss: 1001.3295\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 1071.0371 - val_loss: 967.2042\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 1037.3722 - val_loss: 931.8455\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1002.9693 - val_loss: 897.1246\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 968.6315 - val_loss: 862.6504\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 934.6832 - val_loss: 827.8222\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 900.3240 - val_loss: 793.5081\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 866.2643 - val_loss: 760.0075\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 832.7527 - val_loss: 726.6775\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 799.6937 - val_loss: 694.1392\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 767.2946 - val_loss: 662.3585\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 735.2573 - val_loss: 631.1503\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 703.7913 - val_loss: 600.5798\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 5ms/step - loss: 673.3177 - val_loss: 570.8851\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 643.8764 - val_loss: 542.5223\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 615.1843 - val_loss: 515.8192\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 588.0144 - val_loss: 490.1995\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 561.4721 - val_loss: 466.5112\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 536.8405 - val_loss: 443.0183\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 512.8049 - val_loss: 421.1787\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 490.2286 - val_loss: 400.6762\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 468.6475 - val_loss: 381.8438\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 448.6677 - val_loss: 363.7596\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 429.5358 - val_loss: 347.0384\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 411.3199 - val_loss: 331.7208\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 394.3918 - val_loss: 318.0671\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 379.0974 - val_loss: 304.6119\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 7ms/step - loss: 364.3556 - val_loss: 292.4984\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 350.3782 - val_loss: 282.0029\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 7ms/step - loss: 338.1463 - val_loss: 272.1235\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 326.5569 - val_loss: 263.0130\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 315.8369 - val_loss: 254.9341\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 305.7660 - val_loss: 247.7295\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 5ms/step - loss: 296.6693 - val_loss: 241.0588\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 288.3291 - val_loss: 235.0061\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 280.6211 - val_loss: 229.4491\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 273.5121 - val_loss: 224.6133\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 266.9043 - val_loss: 220.4197\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 260.8076 - val_loss: 216.3755\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 7ms/step - loss: 255.3075 - val_loss: 212.6781\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 250.0194 - val_loss: 209.3357\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 245.0921 - val_loss: 206.3712\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 240.7814 - val_loss: 203.7321\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 236.5727 - val_loss: 200.9476\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 232.6933 - val_loss: 198.5029\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 13ms/step - loss: 229.2326 - val_loss: 196.2730\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.7418 - val_loss: 194.2012\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.4785 - val_loss: 192.2085\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.4968 - val_loss: 190.0812\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 216.6183 - val_loss: 188.2066\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 13ms/step - loss: 213.7807 - val_loss: 186.6279\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 12ms/step - loss: 211.2798 - val_loss: 185.0580\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.6818 - val_loss: 183.2458\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 206.3031 - val_loss: 181.5162\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 203.9807 - val_loss: 180.1655\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.6785 - val_loss: 178.3294\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 199.5240 - val_loss: 177.0913\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 197.2371 - val_loss: 175.2899\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.2060 - val_loss: 173.9092\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.1535 - val_loss: 172.1090\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 191.0279 - val_loss: 170.2608\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 188.9872 - val_loss: 168.7460\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.0659 - val_loss: 167.4965\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.1591 - val_loss: 166.1754\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.3182 - val_loss: 164.4361\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 181.5033 - val_loss: 163.1386\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.6867 - val_loss: 161.6505\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.9232 - val_loss: 160.1190\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.1931 - val_loss: 159.1739\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 174.4798 - val_loss: 157.5836\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 172.7665 - val_loss: 156.4142\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 171.1915 - val_loss: 154.7734\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 5ms/step - loss: 169.6360 - val_loss: 153.1290\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 5ms/step - loss: 168.0789 - val_loss: 152.0156\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.5715 - val_loss: 150.8758\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.1867 - val_loss: 149.6821\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 163.7892 - val_loss: 148.4928\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.4937 - val_loss: 147.3113\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.2075 - val_loss: 146.0552\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.8167 - val_loss: 145.0172\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 158.6743 - val_loss: 143.6272\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 5ms/step - loss: 157.3206 - val_loss: 142.5692\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1564.8085 - val_loss: 1591.5704\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1550.2888 - val_loss: 1577.2495\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 1536.1855 - val_loss: 1563.1449\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1522.0830 - val_loss: 1548.5719\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 7ms/step - loss: 1507.7526 - val_loss: 1533.8965\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1493.2397 - val_loss: 1518.6074\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1478.1704 - val_loss: 1502.7018\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1462.4799 - val_loss: 1486.0507\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1445.7795 - val_loss: 1468.6130\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1428.0264 - val_loss: 1449.9436\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1409.0800 - val_loss: 1429.7670\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1388.7410 - val_loss: 1407.7076\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 1366.6890 - val_loss: 1384.5376\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 5ms/step - loss: 1342.9495 - val_loss: 1359.8427\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1318.0636 - val_loss: 1333.5116\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 1291.3855 - val_loss: 1305.6013\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1263.4214 - val_loss: 1276.4193\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1234.2946 - val_loss: 1245.7458\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1203.8066 - val_loss: 1214.0859\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1172.1573 - val_loss: 1181.3457\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1139.7125 - val_loss: 1147.6654\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 1106.5046 - val_loss: 1112.8347\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1071.9850 - val_loss: 1077.5841\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 1036.9495 - val_loss: 1042.5912\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1002.0750 - val_loss: 1005.7994\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 966.1672 - val_loss: 969.4426\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 930.2451 - val_loss: 933.0600\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 894.1221 - val_loss: 897.2221\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 5ms/step - loss: 858.8032 - val_loss: 860.2101\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 823.1832 - val_loss: 824.3517\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 787.9996 - val_loss: 788.8556\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 753.7559 - val_loss: 753.6097\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 719.7270 - val_loss: 719.8367\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 686.8440 - val_loss: 687.0223\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 655.2668 - val_loss: 654.6919\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 624.2268 - val_loss: 624.0286\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 594.4713 - val_loss: 594.1423\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 5ms/step - loss: 566.1036 - val_loss: 565.0545\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 538.8181 - val_loss: 536.8518\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 512.1100 - val_loss: 511.3434\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 487.3731 - val_loss: 486.5556\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 463.8885 - val_loss: 462.4666\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 441.4499 - val_loss: 440.0405\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 420.3933 - val_loss: 418.9135\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 13ms/step - loss: 400.3949 - val_loss: 399.4235\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 382.3191 - val_loss: 380.7617\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 364.8901 - val_loss: 363.8730\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 349.1684 - val_loss: 347.8029\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 334.4420 - val_loss: 333.1257\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 13ms/step - loss: 320.8121 - val_loss: 319.7520\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 12ms/step - loss: 308.3264 - val_loss: 307.3463\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 296.8432 - val_loss: 295.5673\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 7ms/step - loss: 286.0659 - val_loss: 285.1721\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 13ms/step - loss: 276.5002 - val_loss: 275.4623\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 267.4449 - val_loss: 266.7629\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 259.3252 - val_loss: 258.6602\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 251.8598 - val_loss: 251.3110\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 244.9030 - val_loss: 244.4420\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 238.6904 - val_loss: 238.1342\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 232.9819 - val_loss: 232.4419\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 227.6888 - val_loss: 227.1928\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.8817 - val_loss: 222.5352\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 218.5069 - val_loss: 218.1499\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 214.3460 - val_loss: 214.1083\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 210.5738 - val_loss: 210.3862\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 207.0659 - val_loss: 207.0157\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 203.8213 - val_loss: 203.5613\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 7ms/step - loss: 200.6897 - val_loss: 200.6681\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.9386 - val_loss: 197.9062\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.2768 - val_loss: 195.3394\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 192.7964 - val_loss: 193.0403\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 190.4801 - val_loss: 190.7095\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.2398 - val_loss: 188.5806\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.2408 - val_loss: 186.5699\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.1980 - val_loss: 184.9816\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 182.4814 - val_loss: 183.2193\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.6111 - val_loss: 181.5251\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 7ms/step - loss: 178.8699 - val_loss: 179.9727\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.2965 - val_loss: 178.5124\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 175.7126 - val_loss: 176.9474\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 174.1438 - val_loss: 175.6824\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.7271 - val_loss: 174.2343\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.2916 - val_loss: 173.0238\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 170.0273 - val_loss: 171.7584\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 5ms/step - loss: 168.5784 - val_loss: 170.6301\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.4284 - val_loss: 169.3404\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.1694 - val_loss: 168.3228\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 164.9774 - val_loss: 167.4079\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.8821 - val_loss: 166.5181\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.8143 - val_loss: 165.6108\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 161.8017 - val_loss: 164.5808\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.6795 - val_loss: 163.7568\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.6737 - val_loss: 163.0170\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 158.7056 - val_loss: 162.1990\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.7046 - val_loss: 161.5161\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.7821 - val_loss: 160.8828\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.9505 - val_loss: 160.2159\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.9247 - val_loss: 159.6250\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.0300 - val_loss: 159.1472\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.1957 - val_loss: 158.4041\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1483.0094 - val_loss: 1447.3929\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1465.5123 - val_loss: 1427.9019\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 1446.9269 - val_loss: 1407.6169\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 1427.2900 - val_loss: 1386.2225\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 5ms/step - loss: 1406.3414 - val_loss: 1363.6075\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1384.5005 - val_loss: 1340.0634\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1361.1581 - val_loss: 1314.9576\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1336.5276 - val_loss: 1289.2261\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 5ms/step - loss: 1311.0105 - val_loss: 1261.5409\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1283.5096 - val_loss: 1233.3732\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1255.4017 - val_loss: 1203.5583\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1225.6362 - val_loss: 1172.8425\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1195.3013 - val_loss: 1141.2010\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 5ms/step - loss: 1163.4183 - val_loss: 1109.9656\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1131.5247 - val_loss: 1076.3199\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1097.9633 - val_loss: 1042.4629\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1064.1957 - val_loss: 1007.7933\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1029.1509 - val_loss: 973.3378\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 994.5513 - val_loss: 937.8421\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 958.6984 - val_loss: 902.3479\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 5ms/step - loss: 923.0920 - val_loss: 866.6667\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 886.7952 - val_loss: 832.2775\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 8ms/step - loss: 851.3687 - val_loss: 796.4191\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 815.6196 - val_loss: 761.0316\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 12ms/step - loss: 780.1100 - val_loss: 726.6969\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 745.1679 - val_loss: 693.0248\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 7ms/step - loss: 710.5140 - val_loss: 660.4171\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 13ms/step - loss: 676.7883 - val_loss: 627.9540\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 643.7495 - val_loss: 596.2491\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 611.1245 - val_loss: 566.0654\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 579.9486 - val_loss: 536.3737\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 549.6604 - val_loss: 508.0388\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 13ms/step - loss: 520.7156 - val_loss: 480.7419\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 8ms/step - loss: 492.6741 - val_loss: 454.7315\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 11ms/step - loss: 465.7167 - val_loss: 430.5587\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 440.6016 - val_loss: 406.8373\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 416.2822 - val_loss: 384.6655\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 393.5880 - val_loss: 364.4046\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 372.5070 - val_loss: 345.0474\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 352.4156 - val_loss: 327.2972\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 334.2055 - val_loss: 310.3557\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 316.9381 - val_loss: 295.1018\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 300.9469 - val_loss: 281.2974\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 286.4739 - val_loss: 268.4120\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 273.3629 - val_loss: 256.5780\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 261.1845 - val_loss: 246.0054\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 250.3008 - val_loss: 236.3173\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 240.5793 - val_loss: 227.6291\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 231.5734 - val_loss: 219.9480\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 7ms/step - loss: 223.6006 - val_loss: 213.0661\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 216.2981 - val_loss: 206.8123\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.0217 - val_loss: 201.2955\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 7ms/step - loss: 204.2836 - val_loss: 196.2799\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 199.2784 - val_loss: 191.5787\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.6731 - val_loss: 187.6159\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.7034 - val_loss: 184.0147\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 187.1032 - val_loss: 180.8860\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 184.0600 - val_loss: 177.9563\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.0122 - val_loss: 175.4680\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.5550 - val_loss: 173.0869\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.2859 - val_loss: 171.0550\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 174.1886 - val_loss: 169.1306\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.3689 - val_loss: 167.3072\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 170.7100 - val_loss: 165.6189\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.0615 - val_loss: 164.0581\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.6206 - val_loss: 162.6881\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.3353 - val_loss: 161.3967\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.1382 - val_loss: 160.0277\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 5ms/step - loss: 163.9460 - val_loss: 158.9434\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 162.9457 - val_loss: 157.7553\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.8079 - val_loss: 156.8045\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.8556 - val_loss: 155.7917\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.9268 - val_loss: 154.7807\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.9767 - val_loss: 153.7482\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.1468 - val_loss: 152.7107\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.2571 - val_loss: 152.0166\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.4564 - val_loss: 151.2063\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.6076 - val_loss: 150.5636\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.8367 - val_loss: 149.9223\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.0968 - val_loss: 149.2276\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.3190 - val_loss: 148.3669\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 7ms/step - loss: 152.6351 - val_loss: 147.6694\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 5ms/step - loss: 152.0379 - val_loss: 146.9866\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 151.3484 - val_loss: 146.2914\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 5ms/step - loss: 150.7170 - val_loss: 145.5513\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.0586 - val_loss: 145.0514\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.4037 - val_loss: 144.4602\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.8733 - val_loss: 143.7054\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.2436 - val_loss: 143.5064\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.6010 - val_loss: 142.8055\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 147.0274 - val_loss: 142.1626\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 5ms/step - loss: 146.5226 - val_loss: 141.9070\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.9095 - val_loss: 141.2745\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.3791 - val_loss: 140.5746\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.8590 - val_loss: 140.1042\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.2332 - val_loss: 139.8284\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 143.7589 - val_loss: 139.4109\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.2762 - val_loss: 139.3154\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 142.7124 - val_loss: 138.7581\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 142.2769 - val_loss: 138.2387\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1493.4972 - val_loss: 1486.5265\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1475.0173 - val_loss: 1467.8137\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1455.8118 - val_loss: 1448.4753\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 10ms/step - loss: 1436.0686 - val_loss: 1428.2057\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 11ms/step - loss: 1415.1503 - val_loss: 1407.1647\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 12ms/step - loss: 1393.2021 - val_loss: 1385.0795\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1370.3898 - val_loss: 1361.7032\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1346.1571 - val_loss: 1337.7474\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1321.2148 - val_loss: 1311.8590\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 8ms/step - loss: 1294.5315 - val_loss: 1285.2286\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 11ms/step - loss: 1266.9066 - val_loss: 1257.3328\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1238.0002 - val_loss: 1228.2089\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1208.1654 - val_loss: 1198.2219\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1177.3289 - val_loss: 1167.7941\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 15ms/step - loss: 1145.7657 - val_loss: 1136.0491\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 10ms/step - loss: 1113.1230 - val_loss: 1103.6963\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1080.1027 - val_loss: 1070.4825\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1046.0148 - val_loss: 1037.5133\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1011.9911 - val_loss: 1003.3171\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 977.1529 - val_loss: 969.2917\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 942.4309 - val_loss: 935.0370\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 907.4942 - val_loss: 900.4280\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 872.5664 - val_loss: 866.4409\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 838.2556 - val_loss: 831.7681\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 803.6776 - val_loss: 797.9416\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 769.8117 - val_loss: 764.3463\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 736.6909 - val_loss: 731.3726\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 703.8809 - val_loss: 699.8943\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 672.5861 - val_loss: 668.1652\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 641.7177 - val_loss: 638.2476\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 612.2037 - val_loss: 609.1710\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 583.8038 - val_loss: 580.5452\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 556.4031 - val_loss: 553.0049\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 529.9486 - val_loss: 527.1431\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 505.0107 - val_loss: 502.3017\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 481.3840 - val_loss: 478.7094\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 458.8961 - val_loss: 456.1810\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 438.1087 - val_loss: 434.7717\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 418.6620 - val_loss: 414.7508\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 400.4334 - val_loss: 396.7589\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 383.5781 - val_loss: 379.9937\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 368.3113 - val_loss: 363.6048\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 353.8683 - val_loss: 348.6996\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 340.5870 - val_loss: 334.8974\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 328.6234 - val_loss: 321.9843\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 317.3515 - val_loss: 310.5670\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 307.2525 - val_loss: 299.6746\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 297.9918 - val_loss: 289.3292\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 289.4668 - val_loss: 279.8909\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 281.4343 - val_loss: 272.1188\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 274.6125 - val_loss: 263.9342\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 267.9581 - val_loss: 257.0147\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 262.1144 - val_loss: 250.3899\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 256.5654 - val_loss: 244.4459\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 251.6689 - val_loss: 238.8842\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 247.0400 - val_loss: 233.8209\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 242.7048 - val_loss: 229.0735\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 238.6315 - val_loss: 224.8896\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 234.9872 - val_loss: 220.6196\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 231.4824 - val_loss: 217.2004\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 228.1076 - val_loss: 213.3583\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 224.9831 - val_loss: 210.0337\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 221.8597 - val_loss: 206.9709\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 218.9516 - val_loss: 203.9015\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 216.2292 - val_loss: 200.9106\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 213.7005 - val_loss: 198.0472\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 7ms/step - loss: 210.9748 - val_loss: 195.5940\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.6603 - val_loss: 192.9910\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 206.2636 - val_loss: 190.9574\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 7ms/step - loss: 203.9694 - val_loss: 188.4234\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.5922 - val_loss: 186.3389\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.4333 - val_loss: 184.1642\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.3156 - val_loss: 182.0703\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.2770 - val_loss: 180.1246\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 5ms/step - loss: 193.3050 - val_loss: 178.3105\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.2457 - val_loss: 176.3748\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.3305 - val_loss: 174.6027\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 7ms/step - loss: 187.5519 - val_loss: 172.5487\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 185.5949 - val_loss: 170.9422\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.8364 - val_loss: 169.5532\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 182.1222 - val_loss: 167.8540\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 180.3882 - val_loss: 166.3119\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.7701 - val_loss: 164.7141\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 177.1290 - val_loss: 163.4157\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 5ms/step - loss: 175.4879 - val_loss: 161.9830\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.9977 - val_loss: 160.7168\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 172.5685 - val_loss: 159.3194\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.0961 - val_loss: 158.1673\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.5908 - val_loss: 156.9479\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.2181 - val_loss: 155.6636\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.8626 - val_loss: 154.6667\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.4870 - val_loss: 153.5208\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 8ms/step - loss: 164.1937 - val_loss: 152.2483\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 12ms/step - loss: 162.7634 - val_loss: 151.1327\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.3968 - val_loss: 150.0278\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.0827 - val_loss: 148.6965\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 158.8491 - val_loss: 147.6824\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 12ms/step - loss: 157.5334 - val_loss: 146.2938\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.2720 - val_loss: 145.1879\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.9986 - val_loss: 144.0878\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 56ms/step - loss: 1547.8395 - val_loss: 1410.6942\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1528.8081 - val_loss: 1393.5529\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1510.1174 - val_loss: 1376.3748\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1491.4373 - val_loss: 1359.0753\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1472.2838 - val_loss: 1341.8097\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1453.0491 - val_loss: 1324.2159\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 5ms/step - loss: 1433.5242 - val_loss: 1305.8081\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1413.3582 - val_loss: 1287.0494\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1392.6042 - val_loss: 1267.8822\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1371.3285 - val_loss: 1248.1167\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 1349.2654 - val_loss: 1227.8905\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 7ms/step - loss: 1326.5991 - val_loss: 1206.7817\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1303.2947 - val_loss: 1184.9658\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1279.1381 - val_loss: 1162.9008\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 1254.3268 - val_loss: 1140.3965\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1229.0972 - val_loss: 1116.6335\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 1202.4539 - val_loss: 1092.5101\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1175.2588 - val_loss: 1067.0762\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1146.8066 - val_loss: 1040.7979\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1117.4803 - val_loss: 1013.9236\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1087.1342 - val_loss: 986.4327\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1056.3312 - val_loss: 957.5152\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1024.1290 - val_loss: 928.2892\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 991.4767 - val_loss: 898.2805\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 957.9682 - val_loss: 867.8941\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 924.2661 - val_loss: 837.2180\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 890.1801 - val_loss: 806.0488\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 856.0120 - val_loss: 775.0112\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 821.6890 - val_loss: 744.4639\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 5ms/step - loss: 788.2756 - val_loss: 713.8344\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 755.0732 - val_loss: 683.9584\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 722.4586 - val_loss: 654.3652\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 690.5848 - val_loss: 625.6942\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 659.6147 - val_loss: 597.9680\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 629.8519 - val_loss: 571.1711\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 601.1734 - val_loss: 545.5089\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 7ms/step - loss: 573.7651 - val_loss: 520.9313\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 547.3608 - val_loss: 497.5430\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 5ms/step - loss: 522.0980 - val_loss: 475.2401\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 498.0655 - val_loss: 453.9905\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 475.4521 - val_loss: 432.9758\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 453.2184 - val_loss: 414.1656\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 432.9300 - val_loss: 395.4904\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 413.1568 - val_loss: 378.0284\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 394.8557 - val_loss: 361.0695\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 377.5542 - val_loss: 344.9148\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 360.6395 - val_loss: 330.4922\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 345.3959 - val_loss: 316.2294\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 330.5323 - val_loss: 302.9158\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 316.9268 - val_loss: 290.2001\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 303.9401 - val_loss: 278.4799\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 292.2179 - val_loss: 267.5304\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 280.7525 - val_loss: 257.9607\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 7ms/step - loss: 270.9749 - val_loss: 247.9561\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 261.2057 - val_loss: 239.4130\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 252.4032 - val_loss: 231.7744\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 244.4406 - val_loss: 224.1359\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 236.9680 - val_loss: 217.3166\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 230.2366 - val_loss: 210.9661\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 224.1138 - val_loss: 205.2364\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 218.3271 - val_loss: 200.3556\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 213.2879 - val_loss: 195.6285\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.6608 - val_loss: 191.1970\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 204.2190 - val_loss: 187.5127\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 200.4762 - val_loss: 183.9698\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 196.8885 - val_loss: 180.8846\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.6763 - val_loss: 178.0191\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.6841 - val_loss: 175.1935\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 187.9834 - val_loss: 172.8549\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 185.5047 - val_loss: 170.6961\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.3454 - val_loss: 168.8732\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 181.3271 - val_loss: 166.9486\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 7ms/step - loss: 179.4668 - val_loss: 165.2868\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 5ms/step - loss: 177.6705 - val_loss: 163.6335\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.9814 - val_loss: 162.2271\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 8ms/step - loss: 174.4119 - val_loss: 160.9834\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 12ms/step - loss: 172.9771 - val_loss: 159.7720\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.5277 - val_loss: 158.7014\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 7ms/step - loss: 170.2148 - val_loss: 157.6571\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 12ms/step - loss: 169.0192 - val_loss: 156.4276\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.6680 - val_loss: 155.5500\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 13ms/step - loss: 166.4964 - val_loss: 154.6402\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.3206 - val_loss: 153.6564\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 164.2695 - val_loss: 152.6615\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.2275 - val_loss: 151.7980\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.1790 - val_loss: 150.9963\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 9ms/step - loss: 161.0963 - val_loss: 150.1732\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.0653 - val_loss: 149.2446\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.0447 - val_loss: 148.5523\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 157.9305 - val_loss: 147.6729\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 156.9526 - val_loss: 146.8573\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.9700 - val_loss: 146.1527\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 154.9212 - val_loss: 145.3656\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.0031 - val_loss: 144.6364\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.0412 - val_loss: 143.8207\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.0295 - val_loss: 143.0532\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.1358 - val_loss: 142.2950\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.1885 - val_loss: 141.5965\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 149.2318 - val_loss: 140.8827\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.3812 - val_loss: 140.0926\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 1517.9543 - val_loss: 1493.9998\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1502.8560 - val_loss: 1479.4348\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1487.2091 - val_loss: 1463.9188\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1470.4830 - val_loss: 1447.5775\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1452.7446 - val_loss: 1429.9019\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1433.2283 - val_loss: 1411.2546\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1412.8479 - val_loss: 1390.7524\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 7ms/step - loss: 1390.5514 - val_loss: 1369.1821\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1367.2437 - val_loss: 1346.1354\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 7ms/step - loss: 1342.2035 - val_loss: 1321.9972\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1316.0483 - val_loss: 1296.4976\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1288.5259 - val_loss: 1269.8633\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1259.8799 - val_loss: 1241.6876\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1229.8483 - val_loss: 1212.3145\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1198.5991 - val_loss: 1182.2697\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1166.3802 - val_loss: 1151.7883\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1133.8423 - val_loss: 1119.9484\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 1100.3479 - val_loss: 1087.4254\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1066.2168 - val_loss: 1054.8311\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 1031.9811 - val_loss: 1021.4493\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 996.8193 - val_loss: 988.7791\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 962.3796 - val_loss: 954.9016\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 927.1916 - val_loss: 921.2301\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 5ms/step - loss: 892.1264 - val_loss: 888.0043\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 858.0052 - val_loss: 854.5341\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 823.4921 - val_loss: 821.8790\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 789.8634 - val_loss: 789.9545\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 756.9187 - val_loss: 758.7519\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 725.0431 - val_loss: 727.7662\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 693.4664 - val_loss: 697.8953\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 663.1627 - val_loss: 668.6809\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 633.1884 - val_loss: 640.8601\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 604.3453 - val_loss: 613.4883\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 576.2686 - val_loss: 586.9246\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 549.6291 - val_loss: 561.1497\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 523.8206 - val_loss: 536.5680\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 499.1431 - val_loss: 513.0469\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 475.6486 - val_loss: 490.7523\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 453.1970 - val_loss: 469.9196\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 432.2939 - val_loss: 449.9347\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 412.0630 - val_loss: 431.1336\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 393.2387 - val_loss: 413.3823\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 375.7133 - val_loss: 396.2301\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 358.8982 - val_loss: 380.8762\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 343.3564 - val_loss: 366.3466\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 328.8092 - val_loss: 352.8130\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 315.5539 - val_loss: 339.9090\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 5ms/step - loss: 303.0027 - val_loss: 328.1462\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 291.4995 - val_loss: 317.1711\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 280.8847 - val_loss: 306.9097\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 7ms/step - loss: 271.0341 - val_loss: 297.7459\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 262.1704 - val_loss: 289.4293\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 253.8458 - val_loss: 281.7739\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 246.7012 - val_loss: 273.9460\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 239.5282 - val_loss: 267.5312\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 233.2378 - val_loss: 261.2124\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 227.5049 - val_loss: 255.4636\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.3342 - val_loss: 249.9449\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 217.4358 - val_loss: 245.0268\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 213.1989 - val_loss: 240.4294\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 209.1339 - val_loss: 236.3060\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.5635 - val_loss: 232.3534\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.3076 - val_loss: 228.4592\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 12ms/step - loss: 199.3271 - val_loss: 225.3308\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 196.4961 - val_loss: 222.0034\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.7968 - val_loss: 219.0393\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.3246 - val_loss: 216.1547\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.1291 - val_loss: 213.4852\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.9470 - val_loss: 210.6688\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 13ms/step - loss: 185.0265 - val_loss: 208.3915\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.0935 - val_loss: 206.1671\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 181.3267 - val_loss: 203.9618\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 7ms/step - loss: 179.6941 - val_loss: 201.8696\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 13ms/step - loss: 178.1170 - val_loss: 199.9418\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 11ms/step - loss: 176.6741 - val_loss: 197.8133\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.1786 - val_loss: 195.9207\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.8921 - val_loss: 194.1867\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 172.5140 - val_loss: 192.5211\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.2697 - val_loss: 190.8604\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.1051 - val_loss: 189.1115\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 7ms/step - loss: 168.8755 - val_loss: 187.9410\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 167.7655 - val_loss: 186.2859\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.7709 - val_loss: 184.9803\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.6663 - val_loss: 183.5381\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.6313 - val_loss: 182.0342\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.6209 - val_loss: 180.5989\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 162.5915 - val_loss: 179.2525\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.6532 - val_loss: 177.8772\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 7ms/step - loss: 160.7108 - val_loss: 176.5042\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 159.8162 - val_loss: 175.3802\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.8669 - val_loss: 174.0816\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.9546 - val_loss: 172.7463\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.0747 - val_loss: 171.5711\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.1619 - val_loss: 170.5056\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.3815 - val_loss: 169.4443\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.6128 - val_loss: 168.1725\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.6209 - val_loss: 167.0768\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 152.6840 - val_loss: 165.8325\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.7722 - val_loss: 164.8273\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.9649 - val_loss: 163.7491\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1567.2002 - val_loss: 1621.7262\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1548.7933 - val_loss: 1603.4763\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1531.3029 - val_loss: 1585.8058\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1514.1276 - val_loss: 1568.5269\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1497.2794 - val_loss: 1551.0581\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1480.3425 - val_loss: 1533.6477\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1463.3046 - val_loss: 1516.0566\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1446.1718 - val_loss: 1498.3134\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1428.7311 - val_loss: 1480.1831\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1411.0228 - val_loss: 1461.3571\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 1392.4873 - val_loss: 1442.6715\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1373.9402 - val_loss: 1423.0173\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1354.4100 - val_loss: 1403.4725\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1334.6750 - val_loss: 1383.6000\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 7ms/step - loss: 1314.4973 - val_loss: 1362.9667\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 1293.8737 - val_loss: 1341.9707\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1272.8650 - val_loss: 1320.5719\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 1251.7057 - val_loss: 1298.4591\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1229.8458 - val_loss: 1276.7852\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1208.3458 - val_loss: 1254.1517\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1186.2291 - val_loss: 1231.7473\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1164.0743 - val_loss: 1209.0878\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1141.4974 - val_loss: 1186.4745\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1118.9490 - val_loss: 1163.4736\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 7ms/step - loss: 1096.3918 - val_loss: 1140.0768\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 1073.1490 - val_loss: 1117.4851\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 1050.7719 - val_loss: 1093.5380\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 5ms/step - loss: 1027.6962 - val_loss: 1069.9615\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 1004.2870 - val_loss: 1046.9437\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 981.4158 - val_loss: 1022.4011\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 957.8788 - val_loss: 998.2642\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 934.3492 - val_loss: 973.9125\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 910.4808 - val_loss: 949.6522\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 886.6355 - val_loss: 925.3828\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 862.9470 - val_loss: 901.3037\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 839.5914 - val_loss: 876.0176\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 815.1336 - val_loss: 852.5927\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 792.1279 - val_loss: 828.1078\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 768.5699 - val_loss: 804.0576\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 745.1161 - val_loss: 781.0992\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 722.7108 - val_loss: 757.7624\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 699.8219 - val_loss: 735.1722\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 677.8864 - val_loss: 712.9781\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 8ms/step - loss: 655.9346 - val_loss: 690.7177\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 11ms/step - loss: 634.2630 - val_loss: 668.9357\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 613.1119 - val_loss: 647.2836\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 592.3348 - val_loss: 626.4137\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 10ms/step - loss: 572.1265 - val_loss: 606.0027\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 552.2849 - val_loss: 585.8940\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 15ms/step - loss: 533.0781 - val_loss: 566.3391\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 13ms/step - loss: 514.0698 - val_loss: 547.8605\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 11ms/step - loss: 496.1273 - val_loss: 529.4839\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 13ms/step - loss: 478.8219 - val_loss: 510.7773\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 13ms/step - loss: 461.0822 - val_loss: 494.1232\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 11ms/step - loss: 444.6721 - val_loss: 477.3884\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 428.6369 - val_loss: 460.8817\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 412.9425 - val_loss: 445.1639\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 7ms/step - loss: 397.8754 - val_loss: 430.2050\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 383.6440 - val_loss: 415.7061\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 369.8214 - val_loss: 401.9413\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 356.6157 - val_loss: 388.9819\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 344.2124 - val_loss: 376.4937\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 5ms/step - loss: 332.4295 - val_loss: 364.5405\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 321.0121 - val_loss: 353.8014\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 310.6406 - val_loss: 342.9943\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 300.5550 - val_loss: 332.8057\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 290.9561 - val_loss: 323.5805\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 282.0315 - val_loss: 314.6092\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 273.6800 - val_loss: 306.2117\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 265.7847 - val_loss: 298.3608\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 258.4338 - val_loss: 291.0475\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 251.5623 - val_loss: 284.5105\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 245.2491 - val_loss: 278.1718\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 239.4049 - val_loss: 272.0072\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 5ms/step - loss: 233.7146 - val_loss: 266.4521\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 7ms/step - loss: 228.5567 - val_loss: 261.4705\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 223.8757 - val_loss: 256.7157\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 219.4035 - val_loss: 252.1585\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.0925 - val_loss: 248.0256\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 211.2286 - val_loss: 244.1826\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 7ms/step - loss: 207.6495 - val_loss: 240.3775\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.2279 - val_loss: 237.1732\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.1646 - val_loss: 234.0026\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.3018 - val_loss: 230.8354\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.5604 - val_loss: 228.2170\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.1898 - val_loss: 225.4074\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.8130 - val_loss: 223.1544\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.7394 - val_loss: 220.8395\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.7065 - val_loss: 218.5104\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 184.8228 - val_loss: 216.4608\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 183.0361 - val_loss: 214.5904\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.4060 - val_loss: 212.7387\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.7291 - val_loss: 210.9860\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 178.2253 - val_loss: 209.2097\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.8142 - val_loss: 207.5170\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.2983 - val_loss: 205.8244\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 173.8950 - val_loss: 204.3655\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 172.6269 - val_loss: 202.8152\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.3406 - val_loss: 201.3043\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.1120 - val_loss: 199.8881\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1572.3041 - val_loss: 1629.9694\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 9ms/step - loss: 1554.7847 - val_loss: 1612.4565\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 1537.6676 - val_loss: 1594.6826\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 5ms/step - loss: 1520.2534 - val_loss: 1577.0945\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 7ms/step - loss: 1502.5541 - val_loss: 1559.2443\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1484.3163 - val_loss: 1540.5946\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1465.4834 - val_loss: 1521.5955\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1445.8816 - val_loss: 1502.2566\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1425.6708 - val_loss: 1482.1725\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1404.7821 - val_loss: 1460.7587\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 1382.3649 - val_loss: 1439.0372\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1359.4521 - val_loss: 1416.1248\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1335.5183 - val_loss: 1392.2024\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1310.4702 - val_loss: 1367.4313\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1284.3411 - val_loss: 1341.6586\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 1257.2639 - val_loss: 1314.6718\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1228.9777 - val_loss: 1287.0040\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 5ms/step - loss: 1200.5109 - val_loss: 1257.8900\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 1170.3586 - val_loss: 1229.6136\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1140.3669 - val_loss: 1200.0222\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1109.8145 - val_loss: 1169.2451\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1078.3734 - val_loss: 1138.7916\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 1046.7528 - val_loss: 1107.8711\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 9ms/step - loss: 1015.0128 - val_loss: 1076.1661\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 983.0847 - val_loss: 1044.1931\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 950.8346 - val_loss: 1013.2012\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 918.9311 - val_loss: 981.8041\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 887.0419 - val_loss: 950.3372\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 13ms/step - loss: 855.2833 - val_loss: 919.4081\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 12ms/step - loss: 823.8987 - val_loss: 888.7569\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 8ms/step - loss: 792.9839 - val_loss: 858.0240\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 762.4482 - val_loss: 828.2603\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 732.7158 - val_loss: 798.1003\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 14ms/step - loss: 703.4493 - val_loss: 769.2447\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 11ms/step - loss: 675.1171 - val_loss: 741.0244\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 647.4747 - val_loss: 713.2898\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 620.5591 - val_loss: 686.5695\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 594.7632 - val_loss: 660.4531\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 569.4691 - val_loss: 635.4639\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 545.7479 - val_loss: 610.5613\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 522.4963 - val_loss: 587.1743\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 500.5554 - val_loss: 564.7596\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 479.7292 - val_loss: 542.3416\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 459.3689 - val_loss: 521.5880\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 440.4275 - val_loss: 501.9726\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 422.6166 - val_loss: 483.7679\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 406.0317 - val_loss: 465.6649\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 390.0376 - val_loss: 448.6657\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 375.0245 - val_loss: 432.5406\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 360.9565 - val_loss: 417.2974\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 348.0268 - val_loss: 403.0115\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 335.6419 - val_loss: 389.6266\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 324.3152 - val_loss: 377.2074\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 5ms/step - loss: 313.8572 - val_loss: 364.9851\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 5ms/step - loss: 303.8556 - val_loss: 354.1733\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 294.7871 - val_loss: 343.5704\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 286.3309 - val_loss: 333.3780\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 278.3958 - val_loss: 324.2900\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 271.0931 - val_loss: 315.6961\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 264.3401 - val_loss: 307.7748\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 258.1730 - val_loss: 300.3321\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 252.4416 - val_loss: 292.9390\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 246.9659 - val_loss: 286.3650\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 242.0348 - val_loss: 280.3937\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 237.4468 - val_loss: 274.3278\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 233.1631 - val_loss: 268.7191\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 229.0376 - val_loss: 263.7423\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.3726 - val_loss: 258.8435\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 221.8499 - val_loss: 254.1694\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 218.6135 - val_loss: 249.9721\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.5653 - val_loss: 246.1329\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 212.6502 - val_loss: 242.4957\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.1376 - val_loss: 238.6789\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 207.3896 - val_loss: 235.5192\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 205.0284 - val_loss: 232.1610\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.6382 - val_loss: 229.0619\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 200.4718 - val_loss: 225.9153\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 198.3198 - val_loss: 223.0874\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 5ms/step - loss: 196.3296 - val_loss: 220.4243\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.3737 - val_loss: 217.8827\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 192.5485 - val_loss: 215.2682\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.7577 - val_loss: 212.7425\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.1521 - val_loss: 210.4846\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.2831 - val_loss: 208.1591\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.6991 - val_loss: 205.9362\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 5ms/step - loss: 184.0715 - val_loss: 203.6741\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 182.6065 - val_loss: 201.6951\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.0195 - val_loss: 199.6478\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.5570 - val_loss: 197.5613\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 178.0440 - val_loss: 195.8366\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.6655 - val_loss: 193.8663\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 175.2291 - val_loss: 191.9927\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.8719 - val_loss: 190.1524\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 172.4910 - val_loss: 188.3370\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 171.1396 - val_loss: 186.5437\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.8320 - val_loss: 184.8605\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.4850 - val_loss: 183.2309\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 167.1902 - val_loss: 181.6073\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.8462 - val_loss: 179.9688\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 164.5521 - val_loss: 178.2893\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1596.4286 - val_loss: 1484.0157\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1578.4799 - val_loss: 1467.7036\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1560.5917 - val_loss: 1451.5391\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1542.5214 - val_loss: 1435.2856\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 5ms/step - loss: 1524.3986 - val_loss: 1418.2798\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1505.9556 - val_loss: 1401.0339\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1486.8145 - val_loss: 1383.4532\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1467.2928 - val_loss: 1364.9105\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 8ms/step - loss: 1447.1641 - val_loss: 1345.8658\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1426.1930 - val_loss: 1326.2213\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 1404.7771 - val_loss: 1305.5393\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1382.4269 - val_loss: 1284.4568\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1359.5232 - val_loss: 1262.5198\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1335.8516 - val_loss: 1240.1171\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 7ms/step - loss: 1311.6692 - val_loss: 1216.8158\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 13ms/step - loss: 1286.8730 - val_loss: 1192.7509\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 13ms/step - loss: 1261.0674 - val_loss: 1168.4797\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 13ms/step - loss: 1234.9514 - val_loss: 1143.3790\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 11ms/step - loss: 1207.9607 - val_loss: 1117.5397\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1180.6249 - val_loss: 1090.9386\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 1152.7131 - val_loss: 1064.1064\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1124.3837 - val_loss: 1037.3553\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 1096.1901 - val_loss: 1010.0721\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1067.5214 - val_loss: 982.4185\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1038.4579 - val_loss: 954.8085\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 1009.8568 - val_loss: 926.9335\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 980.5367 - val_loss: 899.6381\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 951.8102 - val_loss: 871.6072\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 5ms/step - loss: 922.8954 - val_loss: 843.9341\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 894.4549 - val_loss: 816.2479\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 866.0076 - val_loss: 789.4871\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 838.0366 - val_loss: 762.5884\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 810.2795 - val_loss: 735.8373\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 782.5143 - val_loss: 710.1033\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 755.7701 - val_loss: 683.7350\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 728.6107 - val_loss: 658.2271\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 701.9838 - val_loss: 633.0593\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 5ms/step - loss: 676.0384 - val_loss: 607.5156\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 650.0328 - val_loss: 582.8311\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 624.4415 - val_loss: 558.6619\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 599.5100 - val_loss: 535.1545\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 575.3562 - val_loss: 511.9986\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 551.3659 - val_loss: 489.6214\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 528.2789 - val_loss: 467.9100\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 505.7527 - val_loss: 446.8862\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 484.5662 - val_loss: 426.6263\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 463.2521 - val_loss: 408.4339\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 443.9810 - val_loss: 390.0717\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 424.9837 - val_loss: 373.1504\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 406.9292 - val_loss: 357.5955\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 390.1671 - val_loss: 342.4069\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 374.3460 - val_loss: 328.1225\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 358.9459 - val_loss: 315.4877\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 5ms/step - loss: 345.2084 - val_loss: 303.5089\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 332.0434 - val_loss: 292.8224\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 319.9703 - val_loss: 282.7018\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 308.8801 - val_loss: 273.6415\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 7ms/step - loss: 298.3477 - val_loss: 265.6107\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 289.0729 - val_loss: 257.6221\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 279.8997 - val_loss: 251.1347\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 272.0032 - val_loss: 244.9828\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 264.5189 - val_loss: 239.6235\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 257.7470 - val_loss: 234.5368\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 251.4695 - val_loss: 229.9031\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 245.6217 - val_loss: 225.7934\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 240.3692 - val_loss: 222.0085\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 235.3839 - val_loss: 218.6722\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 230.9143 - val_loss: 215.6326\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 226.8812 - val_loss: 212.7495\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 222.9910 - val_loss: 210.2132\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.5633 - val_loss: 207.8255\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 216.3803 - val_loss: 205.7151\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 213.3407 - val_loss: 203.6596\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.6732 - val_loss: 201.8916\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 7ms/step - loss: 208.2116 - val_loss: 200.1623\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.9855 - val_loss: 198.5840\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 203.6579 - val_loss: 196.9800\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.7069 - val_loss: 195.5382\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 199.8109 - val_loss: 194.0620\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.9626 - val_loss: 192.7204\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 196.2608 - val_loss: 191.3235\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.6142 - val_loss: 190.0448\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 5ms/step - loss: 193.0494 - val_loss: 189.0333\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 191.5791 - val_loss: 187.8576\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.1309 - val_loss: 186.5926\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 188.8327 - val_loss: 185.4606\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 187.4823 - val_loss: 184.6125\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 186.1444 - val_loss: 183.7675\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 184.9939 - val_loss: 182.7418\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.7155 - val_loss: 181.4665\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 182.6319 - val_loss: 180.6030\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 7ms/step - loss: 181.4301 - val_loss: 179.6803\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 180.3412 - val_loss: 178.8483\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.3208 - val_loss: 177.9281\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.2944 - val_loss: 177.0305\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.3406 - val_loss: 176.0782\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.3822 - val_loss: 175.2957\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.4423 - val_loss: 174.0601\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.4688 - val_loss: 173.3066\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 8ms/step - loss: 173.5247 - val_loss: 172.3417\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 60ms/step - loss: 1562.8955 - val_loss: 1418.2692\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 16ms/step - loss: 1546.6259 - val_loss: 1401.6803\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1529.9628 - val_loss: 1384.7845\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 8ms/step - loss: 1512.6820 - val_loss: 1367.1965\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 11ms/step - loss: 1494.7195 - val_loss: 1348.6500\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 1475.5846 - val_loss: 1329.4802\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1455.2297 - val_loss: 1309.3075\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1433.9559 - val_loss: 1287.3656\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1410.9290 - val_loss: 1264.5798\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1386.4369 - val_loss: 1240.4581\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1360.7218 - val_loss: 1214.7238\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1333.0671 - val_loss: 1188.3257\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1304.3987 - val_loss: 1160.2479\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1274.1951 - val_loss: 1131.3464\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1242.8315 - val_loss: 1101.4772\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 1210.9531 - val_loss: 1070.0856\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 1177.1638 - val_loss: 1039.0969\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1143.1459 - val_loss: 1006.8292\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1108.4164 - val_loss: 974.1230\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1072.9271 - val_loss: 941.3450\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 1037.3516 - val_loss: 907.6593\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1001.1779 - val_loss: 874.4677\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 965.4789 - val_loss: 841.0956\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 929.2607 - val_loss: 808.2764\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 893.9443 - val_loss: 775.2685\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 858.3212 - val_loss: 743.0525\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 823.4691 - val_loss: 710.7847\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 789.1949 - val_loss: 679.7117\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 755.8170 - val_loss: 649.3159\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 722.8471 - val_loss: 620.3944\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 691.3169 - val_loss: 591.3873\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 660.7069 - val_loss: 563.1322\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 5ms/step - loss: 630.6758 - val_loss: 536.4119\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 602.2205 - val_loss: 510.4121\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 574.8276 - val_loss: 485.6761\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 548.5739 - val_loss: 462.5938\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 523.7543 - val_loss: 440.5496\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 500.4493 - val_loss: 419.5079\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 478.2863 - val_loss: 399.4700\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 457.4072 - val_loss: 380.7054\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 437.6845 - val_loss: 363.3263\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 419.4461 - val_loss: 346.9648\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 402.2906 - val_loss: 331.8228\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 386.5112 - val_loss: 317.3897\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 371.6649 - val_loss: 304.7584\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 7ms/step - loss: 358.3696 - val_loss: 292.6623\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 345.8437 - val_loss: 281.4232\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 334.2448 - val_loss: 271.4486\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 323.8631 - val_loss: 262.0023\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 314.2560 - val_loss: 253.2441\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 305.1073 - val_loss: 245.5580\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 297.1417 - val_loss: 238.2813\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 289.6144 - val_loss: 232.0438\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 282.7765 - val_loss: 226.0483\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 5ms/step - loss: 276.4511 - val_loss: 220.5890\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 270.7241 - val_loss: 215.2698\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 265.2208 - val_loss: 210.7257\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 260.2594 - val_loss: 206.3986\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 255.5789 - val_loss: 202.6641\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 251.3666 - val_loss: 199.2796\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 247.5168 - val_loss: 195.8565\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 243.7086 - val_loss: 192.9170\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 240.2716 - val_loss: 189.9109\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 5ms/step - loss: 236.8456 - val_loss: 187.2686\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 233.6011 - val_loss: 184.7017\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 230.6472 - val_loss: 182.2433\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 227.7928 - val_loss: 180.0110\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 7ms/step - loss: 225.0683 - val_loss: 177.9555\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.4792 - val_loss: 176.0554\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.9283 - val_loss: 174.0060\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 217.6774 - val_loss: 171.9506\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.1271 - val_loss: 170.3630\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 212.8612 - val_loss: 168.7611\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 210.6587 - val_loss: 167.3601\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 208.4992 - val_loss: 165.7171\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 206.3474 - val_loss: 164.1622\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.2639 - val_loss: 162.6917\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.1378 - val_loss: 161.2059\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 200.1079 - val_loss: 159.8151\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 198.3255 - val_loss: 158.6331\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 196.1507 - val_loss: 157.2800\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.3473 - val_loss: 155.6956\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 192.4026 - val_loss: 154.5860\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 190.5279 - val_loss: 153.3344\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 9ms/step - loss: 188.7404 - val_loss: 152.0787\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 11ms/step - loss: 186.9733 - val_loss: 150.7019\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.2229 - val_loss: 149.5386\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.4737 - val_loss: 148.3711\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.6972 - val_loss: 147.2156\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 180.0333 - val_loss: 146.0334\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 178.3068 - val_loss: 144.8834\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 7ms/step - loss: 176.6958 - val_loss: 143.7310\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.0820 - val_loss: 142.7184\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 13ms/step - loss: 173.5445 - val_loss: 141.7635\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 15ms/step - loss: 171.9684 - val_loss: 140.7108\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 11ms/step - loss: 170.4745 - val_loss: 139.5805\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.9851 - val_loss: 138.6829\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 167.5440 - val_loss: 137.7801\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.0410 - val_loss: 136.9086\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 164.7722 - val_loss: 136.0215\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1530.2748 - val_loss: 1576.5699\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1516.7649 - val_loss: 1562.7555\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 1502.8569 - val_loss: 1548.3898\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1488.1936 - val_loss: 1533.2863\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1472.7609 - val_loss: 1517.3649\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1456.5513 - val_loss: 1500.2179\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1438.8625 - val_loss: 1482.2063\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1420.1556 - val_loss: 1462.9292\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 1400.1917 - val_loss: 1442.4238\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1378.9150 - val_loss: 1420.4431\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1356.1672 - val_loss: 1397.6617\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 1332.6124 - val_loss: 1372.5067\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1306.8960 - val_loss: 1346.5344\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1280.4701 - val_loss: 1318.7982\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1252.0298 - val_loss: 1290.5865\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1223.2181 - val_loss: 1260.4259\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1192.6183 - val_loss: 1229.6727\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 1161.1921 - val_loss: 1197.8870\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 1128.8135 - val_loss: 1165.5725\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1096.0598 - val_loss: 1131.3092\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 1061.5135 - val_loss: 1097.4979\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1027.7144 - val_loss: 1062.2292\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 992.6584 - val_loss: 1026.9546\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 957.5212 - val_loss: 991.5565\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 922.3784 - val_loss: 955.4738\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 887.0828 - val_loss: 919.5285\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 851.2560 - val_loss: 884.4263\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 816.3319 - val_loss: 848.4172\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 781.0184 - val_loss: 813.1544\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 746.6946 - val_loss: 778.1608\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 713.2775 - val_loss: 743.7042\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 680.2477 - val_loss: 711.2692\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 649.0416 - val_loss: 678.9672\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 618.4468 - val_loss: 648.2465\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 589.3265 - val_loss: 618.7012\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 561.4557 - val_loss: 590.1318\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 534.8940 - val_loss: 562.9077\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 509.7955 - val_loss: 537.2487\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 486.4887 - val_loss: 512.2505\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 463.9245 - val_loss: 489.0136\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 442.8318 - val_loss: 467.3676\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 5ms/step - loss: 423.4253 - val_loss: 446.4105\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 5ms/step - loss: 404.8748 - val_loss: 427.0235\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 387.5621 - val_loss: 408.9318\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 371.7379 - val_loss: 391.2351\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 356.6855 - val_loss: 375.0092\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 342.6671 - val_loss: 360.1186\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 329.8073 - val_loss: 345.5748\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 317.6304 - val_loss: 332.0931\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 7ms/step - loss: 306.4828 - val_loss: 319.3838\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 295.9491 - val_loss: 307.7987\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 286.3215 - val_loss: 296.8459\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 277.2586 - val_loss: 286.4681\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 268.6383 - val_loss: 276.9169\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 260.7615 - val_loss: 267.8281\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 253.5682 - val_loss: 259.1307\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 246.8005 - val_loss: 250.8762\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 240.2043 - val_loss: 243.7984\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 234.3524 - val_loss: 236.8506\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 228.9283 - val_loss: 230.2056\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 223.9395 - val_loss: 224.2387\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.2666 - val_loss: 218.6346\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 215.0741 - val_loss: 213.1604\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 211.0241 - val_loss: 208.3209\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 207.2365 - val_loss: 203.9827\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 203.9534 - val_loss: 199.5943\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 200.6946 - val_loss: 195.8307\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 197.8287 - val_loss: 192.2388\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 195.0873 - val_loss: 188.7568\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 192.5527 - val_loss: 185.7748\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.3003 - val_loss: 182.7085\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.0895 - val_loss: 180.1033\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.1276 - val_loss: 177.5031\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.2144 - val_loss: 175.2243\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 13ms/step - loss: 182.4525 - val_loss: 173.1925\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 13ms/step - loss: 180.8374 - val_loss: 170.8923\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.2545 - val_loss: 169.1327\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 7ms/step - loss: 177.8639 - val_loss: 167.1640\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 7ms/step - loss: 176.4308 - val_loss: 165.7910\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.2064 - val_loss: 164.0300\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 7ms/step - loss: 173.8900 - val_loss: 162.5506\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 13ms/step - loss: 172.7204 - val_loss: 161.0495\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 171.5295 - val_loss: 159.6559\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 10ms/step - loss: 170.4944 - val_loss: 158.4295\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.4285 - val_loss: 157.2360\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.4282 - val_loss: 155.9987\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.5179 - val_loss: 154.9627\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 166.6222 - val_loss: 153.7553\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.6415 - val_loss: 152.8648\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 164.7536 - val_loss: 151.8607\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.9147 - val_loss: 150.7977\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.9226 - val_loss: 149.9643\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.1152 - val_loss: 148.9894\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 5ms/step - loss: 161.2555 - val_loss: 147.9985\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.4415 - val_loss: 147.1653\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.6293 - val_loss: 146.2661\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.8368 - val_loss: 145.4255\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 158.0258 - val_loss: 144.6311\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.3078 - val_loss: 143.9280\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.5393 - val_loss: 143.0918\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 1511.7822 - val_loss: 1513.0360\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1494.6300 - val_loss: 1496.5743\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1476.4849 - val_loss: 1479.1475\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1457.2434 - val_loss: 1460.4690\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1436.9542 - val_loss: 1440.4076\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1415.3201 - val_loss: 1418.9794\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1392.1184 - val_loss: 1396.7280\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 7ms/step - loss: 1367.7406 - val_loss: 1373.0887\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1342.0692 - val_loss: 1347.7878\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1314.9301 - val_loss: 1321.2294\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1286.5419 - val_loss: 1293.6266\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 1257.0229 - val_loss: 1264.7598\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 1226.2531 - val_loss: 1234.8590\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 1194.4830 - val_loss: 1203.9176\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1161.9413 - val_loss: 1171.8031\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1128.2897 - val_loss: 1138.8810\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 1094.3118 - val_loss: 1104.7096\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 1058.8901 - val_loss: 1071.0894\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1023.5345 - val_loss: 1035.9213\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 987.7090 - val_loss: 1000.4824\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 951.2599 - val_loss: 965.8905\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 915.6976 - val_loss: 929.6998\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 879.3705 - val_loss: 894.4684\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 843.8274 - val_loss: 859.1000\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 808.1456 - val_loss: 824.2733\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 773.7377 - val_loss: 789.2247\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 739.4506 - val_loss: 755.3557\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 706.1944 - val_loss: 722.3640\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 5ms/step - loss: 673.5648 - val_loss: 690.0744\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 642.5755 - val_loss: 658.1337\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 611.7592 - val_loss: 627.4196\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 5ms/step - loss: 582.5679 - val_loss: 598.3161\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 554.5621 - val_loss: 569.7793\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 527.8595 - val_loss: 542.7531\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 502.5938 - val_loss: 516.6232\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 7ms/step - loss: 478.5305 - val_loss: 491.8609\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 455.8715 - val_loss: 468.4623\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 434.8549 - val_loss: 445.8783\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 414.6652 - val_loss: 425.2292\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 396.0650 - val_loss: 406.1551\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 378.9371 - val_loss: 387.6205\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 362.5945 - val_loss: 370.4634\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 347.7534 - val_loss: 354.1001\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 333.6735 - val_loss: 339.3424\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 321.1152 - val_loss: 325.3562\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 309.2640 - val_loss: 312.7909\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 298.6626 - val_loss: 300.5850\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 7ms/step - loss: 289.0139 - val_loss: 289.0908\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 279.7997 - val_loss: 279.4217\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 271.6796 - val_loss: 269.8363\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 264.0946 - val_loss: 261.4815\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 257.3525 - val_loss: 253.0207\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 12ms/step - loss: 250.8856 - val_loss: 245.2209\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 245.1659 - val_loss: 238.1591\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 239.6605 - val_loss: 232.2207\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 12ms/step - loss: 235.1577 - val_loss: 226.0587\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 13ms/step - loss: 230.5006 - val_loss: 220.7120\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 8ms/step - loss: 226.5690 - val_loss: 215.5641\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 11ms/step - loss: 222.7181 - val_loss: 211.4101\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.3407 - val_loss: 206.6645\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 9ms/step - loss: 216.0171 - val_loss: 202.6895\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 10ms/step - loss: 212.9686 - val_loss: 198.5833\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 11ms/step - loss: 210.0005 - val_loss: 194.9815\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 207.3095 - val_loss: 191.4657\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 204.7254 - val_loss: 188.0631\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.2611 - val_loss: 185.0468\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.9296 - val_loss: 181.9535\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 197.6567 - val_loss: 179.0886\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.5204 - val_loss: 176.4614\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.4568 - val_loss: 174.0851\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.5554 - val_loss: 171.5381\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 7ms/step - loss: 189.6036 - val_loss: 169.2827\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.8542 - val_loss: 166.8504\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.0021 - val_loss: 164.8732\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.3252 - val_loss: 162.8253\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.8022 - val_loss: 160.6649\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.1853 - val_loss: 158.9208\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.8065 - val_loss: 157.1590\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.4184 - val_loss: 155.6223\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.1827 - val_loss: 154.3232\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 175.8811 - val_loss: 152.8169\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 7ms/step - loss: 174.7090 - val_loss: 151.3656\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.4668 - val_loss: 150.1276\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.2995 - val_loss: 148.7704\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.1599 - val_loss: 147.4333\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.0612 - val_loss: 146.2785\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.9558 - val_loss: 145.0295\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 167.8474 - val_loss: 143.9932\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.7882 - val_loss: 142.7156\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.7061 - val_loss: 141.6547\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 164.6384 - val_loss: 140.7655\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.5928 - val_loss: 139.6467\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.6247 - val_loss: 138.5764\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.5495 - val_loss: 137.5755\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.5471 - val_loss: 136.6211\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.5247 - val_loss: 135.5231\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 158.6007 - val_loss: 134.4341\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.5754 - val_loss: 133.5684\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 156.6192 - val_loss: 132.5692\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.6298 - val_loss: 131.6381\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1491.1951 - val_loss: 1569.3184\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1472.5977 - val_loss: 1550.1111\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1453.4347 - val_loss: 1530.1261\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1433.7439 - val_loss: 1509.5331\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1413.3065 - val_loss: 1488.3473\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1392.3706 - val_loss: 1466.1514\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1370.7169 - val_loss: 1443.2815\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1348.1709 - val_loss: 1419.8630\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1325.0426 - val_loss: 1395.7473\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1301.0740 - val_loss: 1370.5192\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 1276.5095 - val_loss: 1344.1750\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1250.8591 - val_loss: 1317.8016\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1224.5366 - val_loss: 1289.6318\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1197.1666 - val_loss: 1260.6884\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1169.1985 - val_loss: 1231.0315\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 1140.5505 - val_loss: 1201.1000\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1111.4165 - val_loss: 1170.1826\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1081.5073 - val_loss: 1138.4878\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 5ms/step - loss: 1051.1902 - val_loss: 1106.8859\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1020.6555 - val_loss: 1075.0121\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 989.9458 - val_loss: 1042.5398\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 959.2438 - val_loss: 1009.7505\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 928.2009 - val_loss: 977.4729\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 897.2379 - val_loss: 945.9944\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 5ms/step - loss: 866.7867 - val_loss: 913.4638\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 836.3744 - val_loss: 881.8153\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 806.1135 - val_loss: 850.6451\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 5ms/step - loss: 776.3794 - val_loss: 819.5585\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 747.1277 - val_loss: 789.2521\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 718.6620 - val_loss: 759.0627\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 690.6069 - val_loss: 729.9251\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 13ms/step - loss: 663.3143 - val_loss: 701.8549\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 8ms/step - loss: 636.7826 - val_loss: 674.9637\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 611.1910 - val_loss: 648.1441\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 586.1871 - val_loss: 622.0757\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 561.8756 - val_loss: 597.6347\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 7ms/step - loss: 538.8644 - val_loss: 573.1894\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 516.1758 - val_loss: 549.8459\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 494.7224 - val_loss: 527.3845\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 7ms/step - loss: 473.5534 - val_loss: 506.3542\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 12ms/step - loss: 453.8893 - val_loss: 485.6529\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 434.5068 - val_loss: 465.8284\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 8ms/step - loss: 416.3775 - val_loss: 446.7393\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 398.9343 - val_loss: 429.5005\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 382.8355 - val_loss: 412.7940\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 11ms/step - loss: 367.6601 - val_loss: 396.9243\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 353.0764 - val_loss: 382.2216\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 339.1000 - val_loss: 368.5111\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 326.2403 - val_loss: 354.5793\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 313.7719 - val_loss: 342.1263\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 302.4381 - val_loss: 330.0859\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 291.6538 - val_loss: 318.9543\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 281.5371 - val_loss: 308.8875\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 272.2173 - val_loss: 299.1345\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 263.5195 - val_loss: 289.7380\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 255.1853 - val_loss: 280.9444\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 247.4576 - val_loss: 272.8238\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 240.4084 - val_loss: 265.2874\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 233.9514 - val_loss: 258.5865\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 228.0641 - val_loss: 252.1805\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.6147 - val_loss: 246.0582\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 217.4109 - val_loss: 240.6278\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 212.8636 - val_loss: 235.2283\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.5840 - val_loss: 230.3324\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.6355 - val_loss: 225.9564\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 201.0755 - val_loss: 221.7726\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 7ms/step - loss: 197.7151 - val_loss: 218.0418\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.6770 - val_loss: 214.2550\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 191.7597 - val_loss: 210.9907\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 189.1373 - val_loss: 207.8109\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 186.7879 - val_loss: 204.7946\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.3374 - val_loss: 202.1586\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.2074 - val_loss: 199.4269\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.1868 - val_loss: 197.1174\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 178.1640 - val_loss: 194.8463\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 176.3508 - val_loss: 192.8562\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.6634 - val_loss: 190.5697\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 172.9618 - val_loss: 188.6428\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.3523 - val_loss: 186.7574\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.7562 - val_loss: 184.7514\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 168.2007 - val_loss: 182.9194\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.7910 - val_loss: 181.0931\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 165.3191 - val_loss: 179.5330\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 164.0196 - val_loss: 177.9801\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 5ms/step - loss: 162.6917 - val_loss: 176.5664\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.3669 - val_loss: 174.9316\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.1029 - val_loss: 173.5283\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.8672 - val_loss: 172.2531\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.7089 - val_loss: 170.7507\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 156.5457 - val_loss: 169.3279\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.4021 - val_loss: 168.1131\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 154.3955 - val_loss: 166.9910\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.3557 - val_loss: 165.7144\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 5ms/step - loss: 152.3610 - val_loss: 164.6360\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.3862 - val_loss: 163.5681\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 150.4282 - val_loss: 162.5098\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.5732 - val_loss: 161.3647\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.6357 - val_loss: 160.4261\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 147.8072 - val_loss: 159.3197\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 5ms/step - loss: 146.9395 - val_loss: 158.3078\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1535.1675 - val_loss: 1599.4078\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1517.4714 - val_loss: 1583.6669\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1500.5428 - val_loss: 1568.6405\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1483.8578 - val_loss: 1553.6902\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1467.4174 - val_loss: 1538.4952\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1450.6304 - val_loss: 1523.2244\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1433.6700 - val_loss: 1507.5620\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1416.4050 - val_loss: 1491.5232\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1398.7430 - val_loss: 1475.1459\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1380.4528 - val_loss: 1458.2992\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1361.6814 - val_loss: 1440.1725\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1341.6505 - val_loss: 1421.7156\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 1321.0641 - val_loss: 1402.1666\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1299.4673 - val_loss: 1381.5520\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1276.6212 - val_loss: 1360.3317\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1252.9088 - val_loss: 1337.8293\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1228.0509 - val_loss: 1314.1338\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1202.3368 - val_loss: 1289.1881\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 7ms/step - loss: 1174.9937 - val_loss: 1264.5392\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 1147.6917 - val_loss: 1238.0051\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 12ms/step - loss: 1118.9521 - val_loss: 1210.9541\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1089.4087 - val_loss: 1182.8505\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1059.3505 - val_loss: 1154.0508\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 13ms/step - loss: 1028.3582 - val_loss: 1124.8623\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 15ms/step - loss: 997.1972 - val_loss: 1095.0710\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 965.4428 - val_loss: 1064.4283\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 7ms/step - loss: 933.2905 - val_loss: 1033.3668\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 901.2513 - val_loss: 1002.2058\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 869.2197 - val_loss: 971.4579\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 837.5084 - val_loss: 940.5059\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 806.0217 - val_loss: 909.6806\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 774.7323 - val_loss: 879.3676\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 744.2305 - val_loss: 848.6218\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 713.7513 - val_loss: 818.9583\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 684.6247 - val_loss: 789.9154\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 656.3459 - val_loss: 761.3580\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 7ms/step - loss: 628.9489 - val_loss: 733.6561\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 602.4273 - val_loss: 706.7016\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 5ms/step - loss: 577.5076 - val_loss: 680.2923\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 553.0421 - val_loss: 655.6145\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 530.0847 - val_loss: 631.9135\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 508.5118 - val_loss: 608.0800\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 487.5385 - val_loss: 585.6490\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 468.0434 - val_loss: 564.1561\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 449.5182 - val_loss: 544.2181\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 432.5422 - val_loss: 524.5505\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 416.4121 - val_loss: 506.2730\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 401.4723 - val_loss: 488.8658\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 387.5778 - val_loss: 472.5579\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 374.4707 - val_loss: 457.3356\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 362.6101 - val_loss: 442.7343\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 351.4164 - val_loss: 429.0552\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 341.1505 - val_loss: 416.2996\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 332.0892 - val_loss: 403.2185\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 322.8110 - val_loss: 392.6534\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 314.9812 - val_loss: 382.0202\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 307.4102 - val_loss: 372.2216\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 7ms/step - loss: 300.6144 - val_loss: 362.7292\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 294.0782 - val_loss: 354.0641\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 288.2171 - val_loss: 345.9228\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 282.6723 - val_loss: 338.1085\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 277.4530 - val_loss: 330.4838\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 272.3996 - val_loss: 323.7097\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 267.8544 - val_loss: 316.9289\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 263.5024 - val_loss: 310.6729\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 259.4336 - val_loss: 304.5312\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 7ms/step - loss: 255.5550 - val_loss: 298.3995\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 251.8997 - val_loss: 293.0135\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 248.4043 - val_loss: 287.7095\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 245.2020 - val_loss: 282.6319\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 241.9951 - val_loss: 277.9318\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 239.0750 - val_loss: 273.6697\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 236.1122 - val_loss: 269.4818\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 233.3538 - val_loss: 265.2065\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 7ms/step - loss: 230.6038 - val_loss: 261.1552\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 227.9679 - val_loss: 257.0665\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.3155 - val_loss: 253.0669\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 222.7162 - val_loss: 249.1410\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 5ms/step - loss: 220.2011 - val_loss: 245.4362\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 217.7605 - val_loss: 242.2553\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.3058 - val_loss: 238.5241\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 212.8898 - val_loss: 235.1616\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.5992 - val_loss: 231.7818\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.1380 - val_loss: 228.8197\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 206.0166 - val_loss: 225.5596\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 203.7750 - val_loss: 222.2978\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.6178 - val_loss: 219.4425\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.4005 - val_loss: 216.5534\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 7ms/step - loss: 197.3120 - val_loss: 213.7604\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.2478 - val_loss: 210.5381\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.1601 - val_loss: 207.8410\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.0404 - val_loss: 205.1462\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.0018 - val_loss: 202.7208\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.9692 - val_loss: 199.9669\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.8936 - val_loss: 197.3883\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.9790 - val_loss: 195.0022\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.9282 - val_loss: 192.7971\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.0337 - val_loss: 190.3851\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 177.0941 - val_loss: 187.8109\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.1735 - val_loss: 185.3445\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 48ms/step - loss: 1536.1185 - val_loss: 1602.7502\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 19ms/step - loss: 1520.0735 - val_loss: 1585.6643\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 7ms/step - loss: 1504.1547 - val_loss: 1569.1085\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 12ms/step - loss: 1488.4033 - val_loss: 1552.0244\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 8ms/step - loss: 1472.2356 - val_loss: 1534.8732\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 11ms/step - loss: 1455.8417 - val_loss: 1517.2810\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 8ms/step - loss: 1439.1272 - val_loss: 1499.1478\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 12ms/step - loss: 1421.6212 - val_loss: 1480.7953\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 11ms/step - loss: 1403.8160 - val_loss: 1461.0798\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1385.1122 - val_loss: 1441.0610\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 1365.7135 - val_loss: 1420.2667\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 1345.3492 - val_loss: 1398.6051\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1324.3765 - val_loss: 1375.2167\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1302.0659 - val_loss: 1351.5383\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 7ms/step - loss: 1279.2689 - val_loss: 1326.4066\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 1255.1587 - val_loss: 1300.6066\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1230.2375 - val_loss: 1273.0110\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1204.2080 - val_loss: 1244.5315\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1177.1185 - val_loss: 1215.6854\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1149.4373 - val_loss: 1185.5942\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1120.8751 - val_loss: 1154.2438\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1091.4832 - val_loss: 1121.9956\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1061.7217 - val_loss: 1089.5560\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 1031.1245 - val_loss: 1057.1377\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1000.2411 - val_loss: 1023.8875\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 969.1535 - val_loss: 989.7100\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 937.4897 - val_loss: 956.6510\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 906.2567 - val_loss: 922.8827\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 874.7653 - val_loss: 889.4622\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 843.2933 - val_loss: 856.5565\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 812.2768 - val_loss: 823.9217\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 782.0310 - val_loss: 791.1768\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 751.6782 - val_loss: 759.4896\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 722.0076 - val_loss: 728.4939\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 693.0273 - val_loss: 697.9927\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 664.5820 - val_loss: 668.6734\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 636.8256 - val_loss: 640.2574\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 609.9318 - val_loss: 612.6855\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 584.0835 - val_loss: 585.6293\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 559.1867 - val_loss: 559.4846\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 535.0583 - val_loss: 535.2301\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 512.0141 - val_loss: 511.9801\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 489.9547 - val_loss: 489.2953\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 468.7513 - val_loss: 467.6350\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 448.5951 - val_loss: 446.9477\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 429.3060 - val_loss: 427.9444\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 411.2697 - val_loss: 409.5108\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 394.1504 - val_loss: 392.4042\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 377.8984 - val_loss: 376.1829\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 362.6353 - val_loss: 361.0509\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 348.2910 - val_loss: 346.6385\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 334.7018 - val_loss: 333.6374\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 322.3591 - val_loss: 320.9324\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 310.7076 - val_loss: 309.0947\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 299.3956 - val_loss: 298.6787\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 289.5183 - val_loss: 288.4710\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 279.9671 - val_loss: 279.5369\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 271.3128 - val_loss: 271.1158\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 263.3778 - val_loss: 263.1211\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 256.0276 - val_loss: 255.6722\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 249.3280 - val_loss: 248.8107\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 243.1044 - val_loss: 242.6738\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 237.4364 - val_loss: 237.1723\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 232.5278 - val_loss: 231.9125\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 227.7783 - val_loss: 227.5123\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.6865 - val_loss: 223.1594\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.8984 - val_loss: 219.1622\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 216.3567 - val_loss: 215.6616\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 213.2834 - val_loss: 212.3093\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.3792 - val_loss: 209.2911\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 207.6955 - val_loss: 206.4676\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.1683 - val_loss: 203.8634\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.9317 - val_loss: 201.2245\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 200.7693 - val_loss: 198.8630\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.8467 - val_loss: 196.7047\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 196.9900 - val_loss: 194.6555\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.2862 - val_loss: 192.7197\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 193.7235 - val_loss: 190.7786\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 192.1454 - val_loss: 188.8612\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.6188 - val_loss: 187.2286\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.2193 - val_loss: 185.5287\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.8318 - val_loss: 183.9142\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 186.5499 - val_loss: 182.4846\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 185.3598 - val_loss: 181.0351\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 184.1091 - val_loss: 179.5930\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 8ms/step - loss: 183.0101 - val_loss: 178.1906\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.9417 - val_loss: 176.7943\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.8793 - val_loss: 175.5890\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.8120 - val_loss: 174.5690\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 13ms/step - loss: 178.8008 - val_loss: 173.4593\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.7952 - val_loss: 172.0585\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 7ms/step - loss: 176.8229 - val_loss: 170.9412\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.7993 - val_loss: 169.8686\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.8053 - val_loss: 168.6215\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.7934 - val_loss: 167.4722\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 7ms/step - loss: 172.8153 - val_loss: 166.3683\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 171.8743 - val_loss: 165.2270\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 5ms/step - loss: 170.9376 - val_loss: 164.2540\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 170.0322 - val_loss: 163.0637\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 13ms/step - loss: 169.0397 - val_loss: 162.1499\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 46ms/step - loss: 1497.4596 - val_loss: 1550.3494\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 1481.4720 - val_loss: 1534.0977\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 7ms/step - loss: 1465.0663 - val_loss: 1517.2155\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1447.8258 - val_loss: 1499.7531\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1429.7887 - val_loss: 1481.3735\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1410.7375 - val_loss: 1462.0724\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 1390.7904 - val_loss: 1441.3256\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1369.4390 - val_loss: 1419.8246\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 1347.4727 - val_loss: 1396.5446\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1323.4806 - val_loss: 1372.7404\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1299.0552 - val_loss: 1346.5577\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1272.4747 - val_loss: 1319.9326\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1245.2634 - val_loss: 1291.4534\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1216.6572 - val_loss: 1261.6233\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1186.2983 - val_loss: 1231.0192\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 1154.8123 - val_loss: 1198.3159\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1121.7666 - val_loss: 1164.6293\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1087.9139 - val_loss: 1129.1257\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1052.2893 - val_loss: 1093.1736\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1015.7770 - val_loss: 1055.5928\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 978.3906 - val_loss: 1016.7115\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 940.0103 - val_loss: 978.3444\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 902.0068 - val_loss: 938.5114\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 863.1890 - val_loss: 898.9569\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 5ms/step - loss: 824.5212 - val_loss: 860.0417\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 786.8492 - val_loss: 821.1345\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 749.6885 - val_loss: 782.9493\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 713.4186 - val_loss: 746.0861\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 677.8688 - val_loss: 709.9414\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 643.6107 - val_loss: 674.3506\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 5ms/step - loss: 610.2335 - val_loss: 640.6541\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 578.8702 - val_loss: 607.4220\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 548.0784 - val_loss: 577.0002\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 519.6769 - val_loss: 547.4192\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 492.5632 - val_loss: 519.2979\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 466.9875 - val_loss: 492.8279\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 443.0919 - val_loss: 468.2730\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 5ms/step - loss: 421.0073 - val_loss: 444.8819\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 399.9995 - val_loss: 422.8394\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 7ms/step - loss: 380.7029 - val_loss: 402.4453\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 362.8226 - val_loss: 384.0650\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 346.7168 - val_loss: 366.4318\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 331.6803 - val_loss: 350.5238\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 317.9834 - val_loss: 335.9077\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 305.4659 - val_loss: 321.9520\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 293.8685 - val_loss: 309.5787\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 283.3331 - val_loss: 298.0421\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 273.7225 - val_loss: 287.3958\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 264.9224 - val_loss: 277.8538\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 7ms/step - loss: 257.0528 - val_loss: 268.7790\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 249.7471 - val_loss: 260.8917\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 5ms/step - loss: 243.3207 - val_loss: 253.3332\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 237.1364 - val_loss: 246.7819\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 5ms/step - loss: 231.6926 - val_loss: 240.5710\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 226.7364 - val_loss: 234.9194\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.3362 - val_loss: 229.5831\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 218.0889 - val_loss: 224.9018\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 214.4066 - val_loss: 220.6548\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 210.9982 - val_loss: 216.4229\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 8ms/step - loss: 207.7443 - val_loss: 212.8145\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 11ms/step - loss: 204.9200 - val_loss: 209.3380\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 13ms/step - loss: 202.0958 - val_loss: 206.2918\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.6265 - val_loss: 203.1364\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 197.3891 - val_loss: 200.2523\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 195.0932 - val_loss: 198.0616\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.1907 - val_loss: 195.2396\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 13ms/step - loss: 191.1230 - val_loss: 193.1255\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 7ms/step - loss: 189.3105 - val_loss: 191.2123\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 15ms/step - loss: 187.6552 - val_loss: 189.2924\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 10ms/step - loss: 186.0137 - val_loss: 186.9535\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 184.4083 - val_loss: 185.1273\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 182.8822 - val_loss: 183.4683\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.4574 - val_loss: 181.7714\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 180.0923 - val_loss: 180.1692\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 178.7713 - val_loss: 178.5020\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 177.4547 - val_loss: 177.1016\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 5ms/step - loss: 176.2616 - val_loss: 175.6583\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.0333 - val_loss: 174.3449\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.9339 - val_loss: 172.9824\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 172.7490 - val_loss: 171.8039\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.6845 - val_loss: 170.6598\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 170.6208 - val_loss: 169.3444\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.4407 - val_loss: 167.9714\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 168.3566 - val_loss: 166.9433\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.3737 - val_loss: 165.8925\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 5ms/step - loss: 166.3907 - val_loss: 165.1170\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.2994 - val_loss: 163.8229\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 164.2491 - val_loss: 162.8376\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.2776 - val_loss: 161.8694\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.2821 - val_loss: 160.7536\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.3502 - val_loss: 159.7952\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 5ms/step - loss: 160.4238 - val_loss: 158.6996\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.5569 - val_loss: 157.7603\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.7132 - val_loss: 156.8889\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.8466 - val_loss: 155.7698\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.9374 - val_loss: 154.9007\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 156.0085 - val_loss: 154.0428\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.2169 - val_loss: 153.2866\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.4559 - val_loss: 152.4045\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.5993 - val_loss: 151.8541\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 44ms/step - loss: 1563.4448 - val_loss: 1639.7733\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1548.6375 - val_loss: 1624.9773\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1534.2961 - val_loss: 1610.7881\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1520.2483 - val_loss: 1596.6586\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1506.0475 - val_loss: 1582.5695\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 7ms/step - loss: 1491.8079 - val_loss: 1567.8390\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 5ms/step - loss: 1476.9154 - val_loss: 1552.5612\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1461.3652 - val_loss: 1536.7108\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1445.1154 - val_loss: 1520.0085\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1427.9911 - val_loss: 1502.1993\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1409.7219 - val_loss: 1483.3662\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1390.5547 - val_loss: 1463.2629\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1370.1614 - val_loss: 1442.2196\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1348.8032 - val_loss: 1419.8467\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1326.1931 - val_loss: 1396.1625\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 1302.5074 - val_loss: 1371.1029\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 1277.5950 - val_loss: 1345.3330\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1251.8285 - val_loss: 1318.3470\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1225.1168 - val_loss: 1289.5494\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1196.8340 - val_loss: 1260.2356\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 1167.8699 - val_loss: 1229.8680\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 1138.2296 - val_loss: 1198.2893\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 1107.4170 - val_loss: 1166.0221\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1076.4274 - val_loss: 1132.8190\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1044.5863 - val_loss: 1098.8895\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 1012.3297 - val_loss: 1064.4880\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 979.6522 - val_loss: 1030.2395\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 946.6532 - val_loss: 995.4407\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 913.7678 - val_loss: 960.0176\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 880.5223 - val_loss: 923.9571\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 847.1608 - val_loss: 889.1021\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 814.3117 - val_loss: 855.3644\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 782.8385 - val_loss: 820.1985\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 750.5110 - val_loss: 786.8051\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 719.4471 - val_loss: 753.1407\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 688.9648 - val_loss: 720.0123\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 9ms/step - loss: 659.0190 - val_loss: 688.3375\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 630.1902 - val_loss: 658.3668\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 602.6465 - val_loss: 628.5972\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 7ms/step - loss: 575.7756 - val_loss: 599.9638\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 550.0572 - val_loss: 571.9165\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 525.1233 - val_loss: 545.4694\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 14ms/step - loss: 501.2612 - val_loss: 520.9688\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 12ms/step - loss: 478.5808 - val_loss: 497.3393\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 13ms/step - loss: 457.1378 - val_loss: 474.2203\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 13ms/step - loss: 436.6910 - val_loss: 452.1702\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 416.9500 - val_loss: 431.9688\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 8ms/step - loss: 398.7578 - val_loss: 412.5918\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 11ms/step - loss: 381.5170 - val_loss: 394.3629\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 365.4426 - val_loss: 377.0215\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 350.1168 - val_loss: 361.2475\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 335.8207 - val_loss: 346.3127\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 322.6282 - val_loss: 332.3068\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 310.0670 - val_loss: 320.1401\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 298.9382 - val_loss: 307.9218\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 288.1149 - val_loss: 296.9657\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 278.4250 - val_loss: 286.4358\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 269.0424 - val_loss: 277.6182\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 260.9187 - val_loss: 268.7311\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 253.2493 - val_loss: 260.8156\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 246.2220 - val_loss: 253.6718\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 239.8594 - val_loss: 246.8891\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 233.9882 - val_loss: 240.6498\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 228.6742 - val_loss: 234.9917\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.5482 - val_loss: 230.2801\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 219.1776 - val_loss: 225.4939\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 7ms/step - loss: 214.9693 - val_loss: 221.2588\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 211.2164 - val_loss: 217.4780\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 207.9107 - val_loss: 213.8981\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.7445 - val_loss: 210.4403\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 201.7345 - val_loss: 207.1108\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 7ms/step - loss: 199.0295 - val_loss: 204.1407\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 196.4593 - val_loss: 201.5117\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.2040 - val_loss: 198.9105\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 5ms/step - loss: 191.8083 - val_loss: 196.3501\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 5ms/step - loss: 189.8083 - val_loss: 193.9200\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 187.7505 - val_loss: 191.5869\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 185.7947 - val_loss: 189.4704\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 5ms/step - loss: 183.9933 - val_loss: 187.3289\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.2848 - val_loss: 185.4050\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.6783 - val_loss: 183.4227\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.0475 - val_loss: 181.6417\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.5914 - val_loss: 179.8797\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.0869 - val_loss: 178.0909\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.6107 - val_loss: 176.2673\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.2863 - val_loss: 174.5169\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.7819 - val_loss: 172.8791\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.4947 - val_loss: 171.2967\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 7ms/step - loss: 169.1209 - val_loss: 169.6780\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 167.8226 - val_loss: 167.7917\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.4396 - val_loss: 166.3347\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.1932 - val_loss: 164.7775\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 163.9516 - val_loss: 163.2020\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 162.6426 - val_loss: 161.6204\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 161.4108 - val_loss: 160.2336\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.2002 - val_loss: 158.5553\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 158.9663 - val_loss: 157.0911\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 5ms/step - loss: 157.7213 - val_loss: 155.5907\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.5663 - val_loss: 154.3261\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.3799 - val_loss: 152.8510\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 45ms/step - loss: 1662.8322 - val_loss: 1560.5260\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1643.6598 - val_loss: 1541.8370\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1625.9036 - val_loss: 1524.2358\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1609.0319 - val_loss: 1508.1298\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1593.6002 - val_loss: 1492.3872\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1578.5214 - val_loss: 1477.8638\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1564.3660 - val_loss: 1463.6925\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1550.4785 - val_loss: 1449.8690\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1536.6138 - val_loss: 1436.2981\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1522.9128 - val_loss: 1422.5836\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1508.9146 - val_loss: 1408.8765\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 7ms/step - loss: 1494.8969 - val_loss: 1394.7750\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 1480.2415 - val_loss: 1380.4248\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 1465.1047 - val_loss: 1365.5211\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 7ms/step - loss: 1449.0934 - val_loss: 1349.6465\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1432.0990 - val_loss: 1333.0798\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1414.2163 - val_loss: 1315.5162\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 14ms/step - loss: 1395.2845 - val_loss: 1296.7814\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 11ms/step - loss: 1375.0729 - val_loss: 1277.3700\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 13ms/step - loss: 1353.9851 - val_loss: 1256.9763\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 13ms/step - loss: 1332.1194 - val_loss: 1235.9375\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 13ms/step - loss: 1309.5458 - val_loss: 1213.9065\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 14ms/step - loss: 1285.9900 - val_loss: 1191.2505\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 13ms/step - loss: 1261.4786 - val_loss: 1167.9038\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 11ms/step - loss: 1236.5055 - val_loss: 1143.6869\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 1210.3379 - val_loss: 1119.5321\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 1183.8739 - val_loss: 1093.8956\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 1156.8127 - val_loss: 1067.8788\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 1128.9733 - val_loss: 1041.6931\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 1100.7177 - val_loss: 1014.8896\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 1071.8708 - val_loss: 987.0340\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 7ms/step - loss: 1042.3934 - val_loss: 958.8561\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 1012.2876 - val_loss: 930.3319\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 981.8473 - val_loss: 900.5015\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 950.4059 - val_loss: 870.9479\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 919.3405 - val_loss: 841.1327\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 888.3058 - val_loss: 810.5782\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 856.7347 - val_loss: 780.8887\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 826.1134 - val_loss: 751.5458\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 795.4794 - val_loss: 722.8082\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 765.7871 - val_loss: 694.2004\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 736.1697 - val_loss: 666.3309\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 707.3996 - val_loss: 638.8304\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 679.1136 - val_loss: 612.6124\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 651.6652 - val_loss: 587.2288\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 625.0159 - val_loss: 562.6276\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 599.0026 - val_loss: 539.2291\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 5ms/step - loss: 574.9086 - val_loss: 514.9241\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 550.0258 - val_loss: 493.9023\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 527.5802 - val_loss: 472.8842\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 7ms/step - loss: 505.7985 - val_loss: 452.6830\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 5ms/step - loss: 484.7542 - val_loss: 434.1042\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 465.0030 - val_loss: 416.1294\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 446.1080 - val_loss: 399.5954\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 5ms/step - loss: 428.3371 - val_loss: 383.4911\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 411.6119 - val_loss: 368.0440\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 395.7105 - val_loss: 353.8170\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 380.6798 - val_loss: 340.8970\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 7ms/step - loss: 366.6589 - val_loss: 328.4640\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 353.3467 - val_loss: 317.2375\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 341.3495 - val_loss: 305.9833\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 329.5806 - val_loss: 296.1613\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 5ms/step - loss: 318.9878 - val_loss: 286.8209\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 309.1536 - val_loss: 277.9906\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 299.9337 - val_loss: 270.2526\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 291.5823 - val_loss: 262.8379\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 283.6877 - val_loss: 255.7162\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 276.1102 - val_loss: 249.5881\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 269.3990 - val_loss: 243.7621\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 7ms/step - loss: 263.2411 - val_loss: 238.2358\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 257.4451 - val_loss: 233.0662\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 252.0490 - val_loss: 228.7425\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 247.1302 - val_loss: 224.6721\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 242.6618 - val_loss: 220.3758\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 7ms/step - loss: 238.2531 - val_loss: 216.7686\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 5ms/step - loss: 234.2917 - val_loss: 213.2242\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 230.5003 - val_loss: 210.0681\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 227.1578 - val_loss: 207.0755\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 223.8325 - val_loss: 204.3214\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 220.9818 - val_loss: 201.6003\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 218.1214 - val_loss: 199.1320\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 7ms/step - loss: 215.4403 - val_loss: 196.9739\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 213.0671 - val_loss: 194.6714\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.7158 - val_loss: 192.5281\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 208.4485 - val_loss: 190.4839\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.5087 - val_loss: 188.7292\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 204.3429 - val_loss: 186.9327\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.4649 - val_loss: 185.2444\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 200.6150 - val_loss: 183.7583\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.8495 - val_loss: 182.1478\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.2359 - val_loss: 180.6002\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 195.5359 - val_loss: 179.2076\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.9417 - val_loss: 177.8650\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 5ms/step - loss: 192.4122 - val_loss: 176.3999\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 190.9666 - val_loss: 175.0161\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 7ms/step - loss: 189.5451 - val_loss: 173.7984\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 188.1931 - val_loss: 172.3998\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 186.7381 - val_loss: 171.3999\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.3216 - val_loss: 170.0185\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 5ms/step - loss: 184.0264 - val_loss: 168.6743\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 59ms/step - loss: 1625.4967 - val_loss: 1576.1636\n",
            "Epoch 2/100\n",
            "23/23 - 1s - 22ms/step - loss: 1611.1300 - val_loss: 1563.0424\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 12ms/step - loss: 1597.7794 - val_loss: 1550.8234\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 12ms/step - loss: 1585.2944 - val_loss: 1539.0300\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1573.2412 - val_loss: 1527.4254\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1561.6055 - val_loss: 1515.8209\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1550.0610 - val_loss: 1504.1459\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 5ms/step - loss: 1538.4182 - val_loss: 1492.1810\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1526.3953 - val_loss: 1479.9744\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1514.2454 - val_loss: 1467.0273\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1501.4341 - val_loss: 1453.7600\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1488.1794 - val_loss: 1439.7793\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1474.2268 - val_loss: 1425.3929\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1459.7001 - val_loss: 1410.3649\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1444.5286 - val_loss: 1394.9054\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1428.8826 - val_loss: 1378.3140\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1412.4089 - val_loss: 1361.2694\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1395.3447 - val_loss: 1343.8394\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1377.6007 - val_loss: 1326.2524\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1359.5609 - val_loss: 1307.8085\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 1340.7140 - val_loss: 1288.5732\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1321.4368 - val_loss: 1268.9331\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 1301.6503 - val_loss: 1248.7535\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1281.6151 - val_loss: 1228.0345\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 7ms/step - loss: 1260.7814 - val_loss: 1207.4724\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 1239.9203 - val_loss: 1186.4811\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 1218.5747 - val_loss: 1165.6086\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 1197.2418 - val_loss: 1144.1439\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 1175.6664 - val_loss: 1122.3173\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 1153.5459 - val_loss: 1100.6150\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 1131.7164 - val_loss: 1078.7856\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 1109.4598 - val_loss: 1057.3281\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 1087.6155 - val_loss: 1035.4624\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 1065.2299 - val_loss: 1014.0822\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 1043.4153 - val_loss: 992.3473\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 1021.1819 - val_loss: 970.5128\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 999.2067 - val_loss: 949.3299\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 977.2189 - val_loss: 928.8887\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 5ms/step - loss: 956.1654 - val_loss: 907.2997\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 934.1213 - val_loss: 887.0810\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 913.0470 - val_loss: 866.5005\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 892.0217 - val_loss: 846.4253\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 871.0112 - val_loss: 826.6339\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 850.8638 - val_loss: 806.6527\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 830.1135 - val_loss: 787.9521\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 810.7902 - val_loss: 768.8436\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 791.2336 - val_loss: 750.7452\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 772.4111 - val_loss: 733.1591\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 753.8919 - val_loss: 715.7652\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 735.9023 - val_loss: 698.6853\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 718.2062 - val_loss: 682.0299\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 701.0604 - val_loss: 665.5526\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 684.1127 - val_loss: 650.1778\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 667.7617 - val_loss: 634.9767\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 5ms/step - loss: 651.8621 - val_loss: 619.7234\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 636.1254 - val_loss: 605.1810\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 621.1423 - val_loss: 591.0068\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 606.5790 - val_loss: 576.9455\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 592.1373 - val_loss: 563.9072\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 578.4872 - val_loss: 550.7753\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 564.9872 - val_loss: 537.9701\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 551.6198 - val_loss: 525.7892\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 538.8353 - val_loss: 513.5337\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 526.1703 - val_loss: 501.5565\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 513.7076 - val_loss: 489.3680\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 500.8978 - val_loss: 477.6042\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 488.2472 - val_loss: 465.2816\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 475.2972 - val_loss: 453.1043\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 462.2871 - val_loss: 440.6993\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 449.0350 - val_loss: 428.3022\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 7ms/step - loss: 436.0952 - val_loss: 415.6998\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 423.1631 - val_loss: 403.8166\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 410.7717 - val_loss: 392.0432\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 398.5603 - val_loss: 380.4239\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 386.6155 - val_loss: 369.6011\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 375.3736 - val_loss: 359.1100\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 364.7006 - val_loss: 349.1582\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 354.6611 - val_loss: 339.6677\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 5ms/step - loss: 345.0311 - val_loss: 330.6097\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 336.0103 - val_loss: 322.0575\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 327.4592 - val_loss: 313.8677\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 319.1574 - val_loss: 306.3419\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 9ms/step - loss: 311.5023 - val_loss: 299.2202\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 11ms/step - loss: 304.2168 - val_loss: 292.2608\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 297.3701 - val_loss: 285.6169\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 12ms/step - loss: 290.7703 - val_loss: 279.5806\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 284.5461 - val_loss: 273.8583\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 278.8815 - val_loss: 268.2843\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 13ms/step - loss: 273.3596 - val_loss: 263.0916\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 13ms/step - loss: 268.2301 - val_loss: 258.1260\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 13ms/step - loss: 263.1909 - val_loss: 253.4158\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 258.4854 - val_loss: 248.8912\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 11ms/step - loss: 253.9288 - val_loss: 244.8844\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 249.7700 - val_loss: 240.7707\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 245.6801 - val_loss: 237.0849\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 5ms/step - loss: 241.9779 - val_loss: 233.4988\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 238.2768 - val_loss: 230.2614\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 234.9500 - val_loss: 227.1012\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 231.5929 - val_loss: 223.8307\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 228.2968 - val_loss: 221.0241\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 42ms/step - loss: 1573.7262 - val_loss: 1629.1410\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1560.2496 - val_loss: 1616.4128\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 7ms/step - loss: 1547.6002 - val_loss: 1604.2676\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 5ms/step - loss: 1535.4609 - val_loss: 1592.6674\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 5ms/step - loss: 1523.6158 - val_loss: 1580.8381\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1511.7041 - val_loss: 1568.8571\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 1499.3945 - val_loss: 1556.7780\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1486.8695 - val_loss: 1543.9297\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1473.7272 - val_loss: 1530.8745\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1460.2356 - val_loss: 1516.8328\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 1446.0156 - val_loss: 1502.3789\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 1431.4546 - val_loss: 1487.1642\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1416.1835 - val_loss: 1471.4421\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1400.4027 - val_loss: 1455.3328\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1384.1462 - val_loss: 1438.6963\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1367.3821 - val_loss: 1420.8219\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 1349.6710 - val_loss: 1402.9938\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 1331.4244 - val_loss: 1384.3635\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 1312.5232 - val_loss: 1364.7144\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1292.9569 - val_loss: 1344.2559\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1272.4114 - val_loss: 1323.5085\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1251.4387 - val_loss: 1301.7489\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1229.5028 - val_loss: 1279.0483\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 1206.9413 - val_loss: 1255.3715\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 7ms/step - loss: 1183.4178 - val_loss: 1231.2120\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 1159.4033 - val_loss: 1205.8551\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 1134.0735 - val_loss: 1180.0588\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 5ms/step - loss: 1108.8903 - val_loss: 1153.1359\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 1082.7930 - val_loss: 1126.4456\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 1056.9620 - val_loss: 1099.3116\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 1030.4009 - val_loss: 1072.3240\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 1004.1524 - val_loss: 1044.9387\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 977.8956 - val_loss: 1017.9287\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 951.6202 - val_loss: 991.3567\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 925.9135 - val_loss: 963.8762\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 7ms/step - loss: 899.4304 - val_loss: 937.1816\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 873.5438 - val_loss: 909.7331\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 847.3399 - val_loss: 882.9734\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 821.7875 - val_loss: 855.2563\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 795.7521 - val_loss: 827.7015\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 769.2982 - val_loss: 801.1194\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 743.2944 - val_loss: 773.2415\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 716.8085 - val_loss: 745.4635\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 689.6632 - val_loss: 717.8605\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 662.2598 - val_loss: 690.1304\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 634.3843 - val_loss: 661.8474\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 606.4805 - val_loss: 634.1715\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 578.8890 - val_loss: 605.1495\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 5ms/step - loss: 551.2478 - val_loss: 576.7787\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 523.9495 - val_loss: 549.3486\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 497.3970 - val_loss: 522.3463\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 471.2768 - val_loss: 495.6299\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 445.4415 - val_loss: 470.3721\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 420.9659 - val_loss: 445.6917\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 396.7724 - val_loss: 423.2299\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 7ms/step - loss: 374.9680 - val_loss: 399.6862\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 5ms/step - loss: 352.9497 - val_loss: 378.3141\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 332.8499 - val_loss: 358.0865\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 313.6341 - val_loss: 339.5771\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 295.9319 - val_loss: 321.5085\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 279.8469 - val_loss: 304.8527\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 264.3783 - val_loss: 290.3141\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 250.6561 - val_loss: 276.2494\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 13ms/step - loss: 238.0990 - val_loss: 262.9219\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 226.7773 - val_loss: 251.8507\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 217.0865 - val_loss: 241.4189\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 13ms/step - loss: 208.1098 - val_loss: 232.7008\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 200.5435 - val_loss: 224.3569\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.6881 - val_loss: 217.6597\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.1027 - val_loss: 210.9764\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.8353 - val_loss: 205.4305\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 13ms/step - loss: 178.5704 - val_loss: 200.3272\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 13ms/step - loss: 174.7618 - val_loss: 196.0961\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 12ms/step - loss: 171.5645 - val_loss: 192.2514\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.6006 - val_loss: 189.3873\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.2649 - val_loss: 186.2906\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 7ms/step - loss: 164.0796 - val_loss: 183.3427\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.2692 - val_loss: 180.7463\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.5800 - val_loss: 179.0688\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 159.1612 - val_loss: 176.7521\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.8313 - val_loss: 175.0179\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.7754 - val_loss: 173.6221\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.6481 - val_loss: 172.1914\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.7140 - val_loss: 170.6959\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.7808 - val_loss: 169.7735\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.9739 - val_loss: 168.7034\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 152.1932 - val_loss: 167.6012\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.4100 - val_loss: 166.4622\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.6582 - val_loss: 165.6140\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.8796 - val_loss: 164.7414\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 149.2050 - val_loss: 163.7645\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 148.4653 - val_loss: 162.8969\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.7675 - val_loss: 162.1455\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.1147 - val_loss: 161.3000\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 146.4328 - val_loss: 160.6731\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.8040 - val_loss: 159.5537\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.1852 - val_loss: 158.9454\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.5144 - val_loss: 158.2948\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.9384 - val_loss: 157.4242\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 143.2818 - val_loss: 156.5128\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1547.5234 - val_loss: 1469.1938\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1533.3433 - val_loss: 1454.1687\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1519.0582 - val_loss: 1438.9821\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1504.3004 - val_loss: 1423.4580\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1489.3800 - val_loss: 1407.1194\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1473.4257 - val_loss: 1390.4523\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1457.0388 - val_loss: 1372.7994\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1439.6494 - val_loss: 1354.0538\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1421.4890 - val_loss: 1334.3160\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1401.7618 - val_loss: 1314.1464\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1381.4207 - val_loss: 1291.5192\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 1359.3213 - val_loss: 1268.1805\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1336.1946 - val_loss: 1243.4254\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1311.5575 - val_loss: 1217.1963\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1285.1611 - val_loss: 1190.1072\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 7ms/step - loss: 1257.8776 - val_loss: 1161.1082\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 1228.9297 - val_loss: 1130.2228\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 5ms/step - loss: 1198.5448 - val_loss: 1098.5632\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 1166.7594 - val_loss: 1066.0895\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1133.9805 - val_loss: 1032.5767\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 1099.8230 - val_loss: 997.9739\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1064.6644 - val_loss: 962.2870\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1029.0260 - val_loss: 926.0947\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 992.5527 - val_loss: 890.0031\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 955.6403 - val_loss: 853.7808\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 918.5582 - val_loss: 817.3937\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 881.4263 - val_loss: 781.9901\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 844.4835 - val_loss: 745.9288\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 807.4038 - val_loss: 711.5800\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 772.0461 - val_loss: 676.2583\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 735.9817 - val_loss: 643.1388\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 7ms/step - loss: 701.0200 - val_loss: 610.3543\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 5ms/step - loss: 666.6188 - val_loss: 579.6772\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 634.0825 - val_loss: 549.2224\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 601.9391 - val_loss: 520.4896\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 571.3477 - val_loss: 492.6602\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 541.5236 - val_loss: 466.7126\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 513.1049 - val_loss: 441.9861\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 485.7893 - val_loss: 418.6739\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 459.7398 - val_loss: 396.7213\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 435.1757 - val_loss: 375.0646\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 5ms/step - loss: 410.8561 - val_loss: 355.3259\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 5ms/step - loss: 388.2096 - val_loss: 337.0900\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 8ms/step - loss: 367.2581 - val_loss: 319.3965\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 13ms/step - loss: 346.7577 - val_loss: 303.9267\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 15ms/step - loss: 328.2177 - val_loss: 289.2970\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 11ms/step - loss: 310.5929 - val_loss: 275.9781\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 8ms/step - loss: 294.5377 - val_loss: 263.9277\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 12ms/step - loss: 279.6272 - val_loss: 253.2711\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 13ms/step - loss: 266.2500 - val_loss: 243.7128\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 13ms/step - loss: 253.9757 - val_loss: 235.1813\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 242.9154 - val_loss: 227.8043\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 12ms/step - loss: 233.1393 - val_loss: 221.3057\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 224.4276 - val_loss: 215.6167\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 5ms/step - loss: 216.5511 - val_loss: 210.7292\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 209.8076 - val_loss: 206.3402\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 203.6399 - val_loss: 202.4483\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.3682 - val_loss: 199.2248\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.4017 - val_loss: 196.4020\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.2952 - val_loss: 193.7345\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.4719 - val_loss: 191.4421\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.2545 - val_loss: 189.2891\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.2769 - val_loss: 187.3273\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.7361 - val_loss: 185.9449\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.2283 - val_loss: 184.2426\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 172.0855 - val_loss: 182.9394\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 5ms/step - loss: 170.1922 - val_loss: 181.7048\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.3853 - val_loss: 180.2258\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.8346 - val_loss: 178.8714\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.3366 - val_loss: 177.6977\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 163.9252 - val_loss: 176.6975\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.7685 - val_loss: 175.8794\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.5549 - val_loss: 174.6676\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.4627 - val_loss: 173.8919\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.5080 - val_loss: 172.8674\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 158.4867 - val_loss: 172.1474\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.6079 - val_loss: 171.0094\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 7ms/step - loss: 156.6389 - val_loss: 170.1689\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.8373 - val_loss: 169.4725\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 154.9795 - val_loss: 168.4005\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 154.2656 - val_loss: 167.7512\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.4115 - val_loss: 166.9399\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.6535 - val_loss: 166.1134\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.8512 - val_loss: 165.1790\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.1432 - val_loss: 164.5081\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 150.4700 - val_loss: 163.5741\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 149.7179 - val_loss: 163.0410\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 149.1192 - val_loss: 162.1394\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 148.3897 - val_loss: 161.4706\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 147.8268 - val_loss: 160.6941\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 147.2517 - val_loss: 159.9820\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.5970 - val_loss: 159.4088\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 146.0009 - val_loss: 158.7922\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.4716 - val_loss: 158.2391\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 144.9819 - val_loss: 157.4812\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 5ms/step - loss: 144.4347 - val_loss: 157.0919\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.8350 - val_loss: 156.2889\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 5ms/step - loss: 143.2955 - val_loss: 155.6410\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.8768 - val_loss: 155.1977\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.3486 - val_loss: 154.6621\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 1445.0050 - val_loss: 1612.4468\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1428.1294 - val_loss: 1593.9913\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 1411.6903 - val_loss: 1575.1191\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1394.8245 - val_loss: 1556.3760\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 5ms/step - loss: 1377.8348 - val_loss: 1536.6617\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1360.2217 - val_loss: 1516.6844\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 1342.1886 - val_loss: 1495.5035\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1323.4586 - val_loss: 1473.8823\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1304.0486 - val_loss: 1451.3336\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 1283.6610 - val_loss: 1428.1342\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 1262.7274 - val_loss: 1403.7009\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 1240.6310 - val_loss: 1378.5928\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 1218.1610 - val_loss: 1351.3387\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1193.9611 - val_loss: 1323.9768\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1169.3353 - val_loss: 1295.6869\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 1143.9808 - val_loss: 1265.6978\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1117.4493 - val_loss: 1234.6608\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 1090.1774 - val_loss: 1202.8352\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1062.1580 - val_loss: 1170.7866\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 1033.3987 - val_loss: 1138.1794\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1004.1922 - val_loss: 1104.4744\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 974.4101 - val_loss: 1069.8916\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 944.1053 - val_loss: 1035.6404\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 913.6071 - val_loss: 1000.2357\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 13ms/step - loss: 882.3394 - val_loss: 965.2914\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 851.1038 - val_loss: 929.8380\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 819.1933 - val_loss: 894.2469\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 787.7143 - val_loss: 857.8671\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 13ms/step - loss: 755.6205 - val_loss: 822.6761\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 724.1931 - val_loss: 786.5759\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 13ms/step - loss: 692.4242 - val_loss: 751.5912\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 13ms/step - loss: 661.3127 - val_loss: 716.8172\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 13ms/step - loss: 630.7468 - val_loss: 683.3011\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 12ms/step - loss: 601.2980 - val_loss: 650.1575\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 571.9644 - val_loss: 618.9981\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 544.2020 - val_loss: 588.2429\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 517.1533 - val_loss: 558.7699\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 491.5532 - val_loss: 530.3218\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 466.7586 - val_loss: 504.2697\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 443.8892 - val_loss: 478.8824\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 421.6563 - val_loss: 455.7038\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 401.3185 - val_loss: 433.5220\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 381.9009 - val_loss: 412.6407\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 363.8408 - val_loss: 393.5374\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 347.4287 - val_loss: 374.9707\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 331.4508 - val_loss: 358.7411\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 317.2502 - val_loss: 343.2483\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 303.9733 - val_loss: 329.1005\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 291.7724 - val_loss: 316.4219\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 5ms/step - loss: 280.8271 - val_loss: 304.0559\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 270.2991 - val_loss: 293.1856\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 261.2123 - val_loss: 282.6913\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 252.5135 - val_loss: 273.9326\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 244.8625 - val_loss: 265.0963\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 237.8398 - val_loss: 257.2502\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 231.1960 - val_loss: 250.5844\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 225.2941 - val_loss: 244.3174\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 220.0088 - val_loss: 238.4251\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.0984 - val_loss: 232.9142\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.6367 - val_loss: 227.5674\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 206.4395 - val_loss: 223.1021\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.6559 - val_loss: 219.0254\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.2243 - val_loss: 215.1457\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 196.0317 - val_loss: 211.5288\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 193.0177 - val_loss: 208.3827\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 190.3497 - val_loss: 205.0341\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 187.7016 - val_loss: 202.3593\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 7ms/step - loss: 185.4054 - val_loss: 199.5008\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.1197 - val_loss: 197.0686\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.1022 - val_loss: 194.9068\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.1388 - val_loss: 192.6729\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.2679 - val_loss: 190.6121\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 175.5664 - val_loss: 188.6326\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 5ms/step - loss: 173.9438 - val_loss: 186.9130\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 5ms/step - loss: 172.3108 - val_loss: 185.1379\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 170.8705 - val_loss: 183.5212\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 7ms/step - loss: 169.3654 - val_loss: 181.9059\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.9787 - val_loss: 180.4782\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.6762 - val_loss: 178.9525\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.4196 - val_loss: 177.5429\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 164.2158 - val_loss: 176.1335\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 163.0160 - val_loss: 174.8773\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.8145 - val_loss: 173.3718\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.6194 - val_loss: 172.0968\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.5147 - val_loss: 170.9589\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.4009 - val_loss: 169.7696\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.3106 - val_loss: 168.5998\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 156.2811 - val_loss: 167.5799\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.2487 - val_loss: 166.2385\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 154.1831 - val_loss: 165.3003\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.1885 - val_loss: 164.1087\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 152.1645 - val_loss: 163.0243\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.1935 - val_loss: 161.9211\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.2326 - val_loss: 160.7993\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 149.2404 - val_loss: 159.8526\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 148.3600 - val_loss: 158.9431\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 147.3679 - val_loss: 157.7807\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.4478 - val_loss: 156.7051\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 145.4778 - val_loss: 155.7003\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 5ms/step - loss: 144.5381 - val_loss: 154.6767\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1592.0671 - val_loss: 1656.0044\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1574.2678 - val_loss: 1637.4543\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 1557.7977 - val_loss: 1619.1278\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1541.2194 - val_loss: 1602.0770\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1525.4031 - val_loss: 1585.0103\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1509.6365 - val_loss: 1567.9670\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1493.6171 - val_loss: 1550.9821\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1477.3788 - val_loss: 1533.8713\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 15ms/step - loss: 1460.9905 - val_loss: 1516.3744\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 11ms/step - loss: 1444.1259 - val_loss: 1498.8096\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1426.9568 - val_loss: 1480.3962\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 13ms/step - loss: 1409.0956 - val_loss: 1461.3806\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1390.7418 - val_loss: 1441.8568\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 13ms/step - loss: 1371.9446 - val_loss: 1421.9907\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 14ms/step - loss: 1352.2474 - val_loss: 1402.3062\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 12ms/step - loss: 1332.5128 - val_loss: 1381.0830\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 11ms/step - loss: 1311.7949 - val_loss: 1359.6465\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1290.4143 - val_loss: 1337.9396\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1268.9436 - val_loss: 1314.8538\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 1246.4537 - val_loss: 1292.1383\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 1223.6876 - val_loss: 1268.7589\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1200.8730 - val_loss: 1244.9242\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 1177.4329 - val_loss: 1220.6592\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 1153.5964 - val_loss: 1196.2092\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 7ms/step - loss: 1129.4576 - val_loss: 1171.6963\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 1105.2361 - val_loss: 1146.4988\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 1080.3438 - val_loss: 1121.4196\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 5ms/step - loss: 1055.7692 - val_loss: 1095.8701\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 1030.7471 - val_loss: 1070.5842\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 1005.8259 - val_loss: 1044.8485\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 980.9785 - val_loss: 1018.8388\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 955.7004 - val_loss: 993.4698\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 931.1411 - val_loss: 968.1529\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 906.4338 - val_loss: 943.0462\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 882.0513 - val_loss: 918.5196\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 858.2209 - val_loss: 893.3388\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 834.3600 - val_loss: 868.6889\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 810.9851 - val_loss: 844.6025\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 787.6052 - val_loss: 821.4792\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 765.3502 - val_loss: 798.1112\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 743.1491 - val_loss: 775.5901\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 721.5289 - val_loss: 753.1583\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 700.2647 - val_loss: 730.8731\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 679.3135 - val_loss: 709.9467\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 659.2756 - val_loss: 688.9407\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 639.3248 - val_loss: 668.7349\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 620.2713 - val_loss: 648.8843\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 601.5519 - val_loss: 629.7670\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 583.4351 - val_loss: 610.9082\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 565.9451 - val_loss: 592.6526\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 549.1417 - val_loss: 574.9883\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 532.8638 - val_loss: 558.1307\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 517.1212 - val_loss: 542.2466\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 502.1439 - val_loss: 526.4532\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 487.6664 - val_loss: 510.8935\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 473.6187 - val_loss: 496.4489\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 460.4063 - val_loss: 482.1026\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 447.3919 - val_loss: 468.6309\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 435.0350 - val_loss: 455.7225\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 423.1582 - val_loss: 443.4233\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 411.9215 - val_loss: 431.0360\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 400.9559 - val_loss: 419.2137\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 390.4679 - val_loss: 408.1232\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 380.5295 - val_loss: 397.4527\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 370.9742 - val_loss: 386.6618\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 361.6475 - val_loss: 376.7341\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 352.8859 - val_loss: 367.0794\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 344.6091 - val_loss: 357.8129\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 336.5084 - val_loss: 349.1031\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 328.9965 - val_loss: 340.5011\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 321.5829 - val_loss: 332.4107\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 314.4820 - val_loss: 324.4194\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 307.8019 - val_loss: 316.5957\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 301.0955 - val_loss: 309.7115\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 295.2171 - val_loss: 302.4213\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 289.1782 - val_loss: 296.4299\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 283.8409 - val_loss: 289.8677\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 7ms/step - loss: 278.4354 - val_loss: 283.8112\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 273.3141 - val_loss: 278.1642\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 268.5286 - val_loss: 272.6285\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 264.0221 - val_loss: 267.2051\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 7ms/step - loss: 259.4826 - val_loss: 262.1030\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 5ms/step - loss: 255.2617 - val_loss: 257.4132\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 251.2021 - val_loss: 252.6180\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 247.0066 - val_loss: 248.6341\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 243.3590 - val_loss: 244.0775\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 239.4258 - val_loss: 240.3139\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 235.9875 - val_loss: 236.2079\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 7ms/step - loss: 232.5692 - val_loss: 232.5068\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 229.4273 - val_loss: 229.1236\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 226.3543 - val_loss: 225.6398\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.1847 - val_loss: 222.7012\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 220.1481 - val_loss: 219.3503\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 217.1415 - val_loss: 216.3257\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 214.1263 - val_loss: 213.4922\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 7ms/step - loss: 211.4069 - val_loss: 210.5319\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 13ms/step - loss: 208.6927 - val_loss: 207.8727\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 13ms/step - loss: 206.0660 - val_loss: 205.2645\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 13ms/step - loss: 203.5175 - val_loss: 202.6333\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 200.9031 - val_loss: 200.0894\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 57ms/step - loss: 1575.5417 - val_loss: 1651.3611\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1557.6676 - val_loss: 1631.6183\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1540.3085 - val_loss: 1612.8229\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1523.5631 - val_loss: 1594.5233\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1507.1383 - val_loss: 1576.4113\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 1490.9745 - val_loss: 1558.3420\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1474.5853 - val_loss: 1539.9465\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1458.0024 - val_loss: 1521.4667\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1441.1483 - val_loss: 1502.7397\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1424.0199 - val_loss: 1483.0109\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1406.2343 - val_loss: 1462.7102\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 7ms/step - loss: 1387.5739 - val_loss: 1442.0349\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1368.2560 - val_loss: 1420.2257\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1347.9718 - val_loss: 1397.3091\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1326.8901 - val_loss: 1373.4742\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1304.7726 - val_loss: 1348.9213\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1281.9792 - val_loss: 1323.6938\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 1258.5175 - val_loss: 1297.7704\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 1234.3087 - val_loss: 1271.8669\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 1209.9777 - val_loss: 1244.5676\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 5ms/step - loss: 1184.7837 - val_loss: 1217.4647\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 1159.2035 - val_loss: 1189.4065\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 1132.9620 - val_loss: 1160.8446\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1106.0542 - val_loss: 1132.8966\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 1079.4625 - val_loss: 1103.5127\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 1051.9523 - val_loss: 1074.7585\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 1024.7092 - val_loss: 1046.0646\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 997.3115 - val_loss: 1017.2975\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 969.8764 - val_loss: 988.3744\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 941.9503 - val_loss: 959.8382\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 914.3083 - val_loss: 931.6097\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 886.9948 - val_loss: 902.7524\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 859.0555 - val_loss: 874.5784\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 831.6166 - val_loss: 846.6526\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 804.0988 - val_loss: 819.0966\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 776.9543 - val_loss: 791.9159\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 749.9833 - val_loss: 765.2336\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 723.5435 - val_loss: 738.8434\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 697.5049 - val_loss: 712.5496\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 671.0249 - val_loss: 687.7269\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 645.8112 - val_loss: 662.8005\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 620.5592 - val_loss: 638.6252\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 7ms/step - loss: 595.9940 - val_loss: 614.9554\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 571.9019 - val_loss: 592.9312\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 548.9744 - val_loss: 570.5958\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 526.6541 - val_loss: 548.9187\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 504.9062 - val_loss: 528.6976\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 484.1970 - val_loss: 509.1339\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 464.2574 - val_loss: 490.5890\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 445.1431 - val_loss: 472.8429\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 426.9393 - val_loss: 455.6209\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 409.3910 - val_loss: 439.5016\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 392.8067 - val_loss: 424.5486\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 7ms/step - loss: 377.2852 - val_loss: 409.7144\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 5ms/step - loss: 362.1980 - val_loss: 396.3710\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 348.4652 - val_loss: 383.3151\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 335.2787 - val_loss: 371.4996\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 322.7867 - val_loss: 360.9062\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 311.4106 - val_loss: 350.7361\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 300.7930 - val_loss: 341.1060\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 290.6129 - val_loss: 332.3443\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 5ms/step - loss: 281.2356 - val_loss: 324.1556\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 272.5788 - val_loss: 316.5762\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 264.4230 - val_loss: 309.6596\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 256.8536 - val_loss: 303.0695\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 249.9164 - val_loss: 297.3588\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 243.4599 - val_loss: 291.9696\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 237.5091 - val_loss: 286.8888\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 231.9601 - val_loss: 282.4072\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 226.9068 - val_loss: 278.1118\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 222.1380 - val_loss: 273.9660\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 217.6586 - val_loss: 270.2995\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 213.6071 - val_loss: 267.2933\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 209.8072 - val_loss: 264.0302\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 5ms/step - loss: 206.3324 - val_loss: 261.1060\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.9278 - val_loss: 258.5565\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 199.9922 - val_loss: 256.1269\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.1299 - val_loss: 253.6503\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.5923 - val_loss: 251.6140\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 8ms/step - loss: 191.9510 - val_loss: 249.5177\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.6829 - val_loss: 247.6684\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.3766 - val_loss: 245.7348\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.2891 - val_loss: 243.9677\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.3518 - val_loss: 242.3293\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.4521 - val_loss: 240.6867\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.7911 - val_loss: 239.1604\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.9851 - val_loss: 237.7218\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.4105 - val_loss: 236.2614\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.8501 - val_loss: 234.8166\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 8ms/step - loss: 173.4018 - val_loss: 233.3272\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.9406 - val_loss: 232.0381\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 7ms/step - loss: 170.5916 - val_loss: 231.0680\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.2986 - val_loss: 229.7200\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.0524 - val_loss: 228.6784\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.8050 - val_loss: 227.5175\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 8ms/step - loss: 165.6515 - val_loss: 226.2196\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 12ms/step - loss: 164.5168 - val_loss: 224.9731\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 11ms/step - loss: 163.4142 - val_loss: 223.9094\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 162.3154 - val_loss: 222.7836\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.2572 - val_loss: 221.7604\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1615.9314 - val_loss: 1537.5482\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1600.6226 - val_loss: 1523.6039\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1585.8679 - val_loss: 1509.9563\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1571.3306 - val_loss: 1496.4088\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1556.7802 - val_loss: 1482.4788\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1541.8662 - val_loss: 1468.2346\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1526.4108 - val_loss: 1453.5950\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1510.5322 - val_loss: 1438.1117\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1493.8970 - val_loss: 1422.0522\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1476.7831 - val_loss: 1405.1270\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 1458.9060 - val_loss: 1387.7516\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 1440.3499 - val_loss: 1369.5015\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1421.0703 - val_loss: 1350.2969\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 1400.8400 - val_loss: 1330.5640\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1380.0492 - val_loss: 1310.2024\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 7ms/step - loss: 1358.4944 - val_loss: 1289.0229\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1336.2532 - val_loss: 1266.9873\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1313.2252 - val_loss: 1244.6123\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 1289.7859 - val_loss: 1222.2750\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 5ms/step - loss: 1266.0161 - val_loss: 1198.7479\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 5ms/step - loss: 1241.5732 - val_loss: 1174.2990\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1216.1718 - val_loss: 1150.0403\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1190.6935 - val_loss: 1125.7120\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1164.5208 - val_loss: 1100.9067\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 7ms/step - loss: 1138.4651 - val_loss: 1075.0055\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 1111.7672 - val_loss: 1048.9890\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 1084.8728 - val_loss: 1023.2350\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 1057.7657 - val_loss: 997.4421\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 5ms/step - loss: 1030.8427 - val_loss: 970.6787\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 1003.1691 - val_loss: 944.6967\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 975.8755 - val_loss: 917.6038\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 947.9643 - val_loss: 890.9064\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 920.2609 - val_loss: 863.5486\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 892.1275 - val_loss: 836.7444\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 864.4243 - val_loss: 809.7302\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 7ms/step - loss: 836.6043 - val_loss: 782.5249\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 808.8565 - val_loss: 755.4878\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 781.2755 - val_loss: 729.0924\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 754.3462 - val_loss: 702.5721\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 727.5696 - val_loss: 676.4374\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 700.8604 - val_loss: 651.1066\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 674.7700 - val_loss: 626.1720\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 649.6688 - val_loss: 601.1893\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 624.7495 - val_loss: 577.6088\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 600.4679 - val_loss: 554.8082\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 577.2709 - val_loss: 532.5436\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 554.5113 - val_loss: 510.6464\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 5ms/step - loss: 532.5119 - val_loss: 489.8184\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 511.5627 - val_loss: 469.5359\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 491.1046 - val_loss: 450.2697\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 471.6240 - val_loss: 431.5196\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 5ms/step - loss: 452.7445 - val_loss: 413.8440\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 434.9334 - val_loss: 396.3427\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 417.3583 - val_loss: 380.4188\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 401.0950 - val_loss: 364.7618\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 385.2625 - val_loss: 350.2318\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 370.3334 - val_loss: 336.1222\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 356.2029 - val_loss: 322.6790\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 342.6826 - val_loss: 310.4582\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 330.0526 - val_loss: 298.4944\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 317.9978 - val_loss: 287.2253\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 306.5809 - val_loss: 276.9943\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 296.1997 - val_loss: 267.0924\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 286.0244 - val_loss: 258.2253\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 276.7279 - val_loss: 249.7124\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 268.0107 - val_loss: 241.7326\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 259.8089 - val_loss: 234.4386\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 252.1947 - val_loss: 227.9546\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 245.4481 - val_loss: 221.3959\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 238.7241 - val_loss: 215.8565\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 232.8136 - val_loss: 210.5322\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 8ms/step - loss: 227.2935 - val_loss: 205.6273\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.0961 - val_loss: 201.1857\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 14ms/step - loss: 217.4123 - val_loss: 197.0351\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 7ms/step - loss: 212.9827 - val_loss: 193.3508\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.9562 - val_loss: 189.8954\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.3175 - val_loss: 186.6207\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.7229 - val_loss: 183.8422\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.6291 - val_loss: 181.3316\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.6624 - val_loss: 179.0489\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 13ms/step - loss: 192.9347 - val_loss: 176.8822\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 13ms/step - loss: 190.4588 - val_loss: 174.8869\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 13ms/step - loss: 188.0932 - val_loss: 173.2387\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.0070 - val_loss: 171.4999\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 7ms/step - loss: 183.9220 - val_loss: 170.1249\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 182.1431 - val_loss: 168.7889\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 180.4653 - val_loss: 167.5351\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.8705 - val_loss: 166.4437\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.3567 - val_loss: 165.3997\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.0634 - val_loss: 164.6244\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 174.7542 - val_loss: 163.6295\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.5079 - val_loss: 162.8855\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.3485 - val_loss: 162.1044\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.2589 - val_loss: 161.4297\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 170.2006 - val_loss: 160.7265\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.2693 - val_loss: 160.1220\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.2976 - val_loss: 159.5226\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 7ms/step - loss: 167.4155 - val_loss: 158.9471\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.5884 - val_loss: 158.3192\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.7901 - val_loss: 157.9181\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1596.0560 - val_loss: 1551.0640\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 1579.5016 - val_loss: 1534.1116\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1563.1238 - val_loss: 1517.5624\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 1546.8043 - val_loss: 1500.6765\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1530.3291 - val_loss: 1483.6937\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1513.9131 - val_loss: 1465.9678\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1496.7415 - val_loss: 1448.0817\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 7ms/step - loss: 1479.2615 - val_loss: 1429.4996\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 5ms/step - loss: 1461.1254 - val_loss: 1410.0067\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 1442.1891 - val_loss: 1390.1345\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 1422.8353 - val_loss: 1368.9749\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 1402.1655 - val_loss: 1347.5294\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1381.2965 - val_loss: 1324.8175\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 1359.3759 - val_loss: 1301.3875\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1336.5770 - val_loss: 1277.4250\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 1313.1868 - val_loss: 1252.2683\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1288.8093 - val_loss: 1226.7008\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1263.9690 - val_loss: 1200.0109\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1238.0319 - val_loss: 1172.8624\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 1211.5825 - val_loss: 1144.8066\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 1184.5135 - val_loss: 1116.2799\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1157.0234 - val_loss: 1087.3145\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1129.1140 - val_loss: 1058.3081\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1100.6270 - val_loss: 1029.1395\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1072.1530 - val_loss: 999.2669\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 1043.0754 - val_loss: 969.3576\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 1014.1964 - val_loss: 939.2570\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 984.8708 - val_loss: 909.2007\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 955.6389 - val_loss: 879.4934\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 926.6819 - val_loss: 849.5796\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 897.4398 - val_loss: 820.7655\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 5ms/step - loss: 868.8738 - val_loss: 791.2233\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 840.1398 - val_loss: 762.3142\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 811.6978 - val_loss: 734.1119\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 5ms/step - loss: 783.5874 - val_loss: 706.3390\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 756.3897 - val_loss: 678.4527\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 729.1141 - val_loss: 651.5901\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 702.3314 - val_loss: 625.6443\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 676.3094 - val_loss: 600.1534\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 650.9742 - val_loss: 575.6357\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 626.1066 - val_loss: 552.1225\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 602.6046 - val_loss: 528.7027\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 578.9841 - val_loss: 507.2750\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 556.9664 - val_loss: 485.9546\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 535.2449 - val_loss: 465.9364\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 514.6497 - val_loss: 446.3912\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 494.5806 - val_loss: 428.4347\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 475.6984 - val_loss: 410.9103\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 457.5652 - val_loss: 394.0518\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 439.8336 - val_loss: 378.2441\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 423.2832 - val_loss: 363.3142\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 5ms/step - loss: 407.2635 - val_loss: 349.6393\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 392.6190 - val_loss: 336.1043\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 378.0522 - val_loss: 324.0558\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 364.7838 - val_loss: 312.3854\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 351.9529 - val_loss: 302.0791\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 340.2210 - val_loss: 292.0601\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 329.1278 - val_loss: 282.8533\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 318.3243 - val_loss: 274.4396\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 13ms/step - loss: 308.6140 - val_loss: 266.3978\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 299.2143 - val_loss: 259.1671\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 290.6477 - val_loss: 252.2193\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 282.5724 - val_loss: 246.0382\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 12ms/step - loss: 274.9098 - val_loss: 240.2993\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 267.9637 - val_loss: 235.0031\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 13ms/step - loss: 261.1705 - val_loss: 230.2942\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 255.1143 - val_loss: 225.7258\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 15ms/step - loss: 249.1656 - val_loss: 221.5600\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 11ms/step - loss: 243.6913 - val_loss: 217.7175\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 11ms/step - loss: 238.7502 - val_loss: 213.8869\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 233.8416 - val_loss: 210.5725\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 229.4284 - val_loss: 207.5041\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 225.2079 - val_loss: 204.6104\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 221.2289 - val_loss: 201.7286\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 217.5711 - val_loss: 199.1263\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 214.0303 - val_loss: 196.7171\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 5ms/step - loss: 210.7869 - val_loss: 194.4594\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 207.7432 - val_loss: 192.1335\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.7246 - val_loss: 190.0959\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 201.9329 - val_loss: 188.0281\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.2276 - val_loss: 185.9435\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 7ms/step - loss: 196.7038 - val_loss: 184.1584\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.2607 - val_loss: 182.3212\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.8947 - val_loss: 180.6784\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 5ms/step - loss: 189.5801 - val_loss: 178.9532\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 187.4287 - val_loss: 177.3233\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 185.3177 - val_loss: 175.7665\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.3149 - val_loss: 174.3629\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.3940 - val_loss: 172.8006\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.6174 - val_loss: 171.3482\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.7934 - val_loss: 170.0154\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 176.0882 - val_loss: 168.6684\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 174.3943 - val_loss: 167.4319\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 172.7999 - val_loss: 166.1877\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.2458 - val_loss: 164.9062\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.7240 - val_loss: 163.4485\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.2326 - val_loss: 162.4180\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.8252 - val_loss: 161.2403\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 165.3855 - val_loss: 160.1276\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 164.0954 - val_loss: 159.0399\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1561.1620 - val_loss: 1563.5168\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1542.3898 - val_loss: 1545.7437\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1524.4694 - val_loss: 1528.2068\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1506.8698 - val_loss: 1511.1111\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1489.7430 - val_loss: 1493.5000\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1472.0978 - val_loss: 1476.1473\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1454.5519 - val_loss: 1457.8696\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1436.2970 - val_loss: 1439.7888\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1417.8118 - val_loss: 1420.7845\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1398.7920 - val_loss: 1401.0392\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1378.9987 - val_loss: 1381.0675\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 1358.7239 - val_loss: 1360.5731\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1338.1085 - val_loss: 1339.0864\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1316.5507 - val_loss: 1317.3972\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1294.8563 - val_loss: 1294.4799\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 1271.9071 - val_loss: 1271.8857\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1249.0778 - val_loss: 1247.4348\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 1224.9120 - val_loss: 1222.9058\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1200.4830 - val_loss: 1197.4952\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1175.2048 - val_loss: 1171.1775\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1149.2838 - val_loss: 1144.0938\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1122.3630 - val_loss: 1116.5442\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1095.1353 - val_loss: 1087.7078\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 1066.7664 - val_loss: 1058.5698\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1038.1680 - val_loss: 1027.9783\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 1008.5067 - val_loss: 997.5922\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 978.7653 - val_loss: 966.4772\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 948.6747 - val_loss: 934.8813\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 917.8491 - val_loss: 903.9772\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 887.7990 - val_loss: 871.6458\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 856.9829 - val_loss: 840.3057\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 826.7889 - val_loss: 808.8169\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 796.7288 - val_loss: 777.9371\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 5ms/step - loss: 767.1254 - val_loss: 748.0333\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 738.5328 - val_loss: 718.1106\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 710.1720 - val_loss: 689.2673\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 682.8180 - val_loss: 660.9892\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 656.1495 - val_loss: 634.0636\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 5ms/step - loss: 630.5750 - val_loss: 607.7281\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 605.9543 - val_loss: 582.0243\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 582.3177 - val_loss: 557.8429\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 559.5717 - val_loss: 534.8840\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 5ms/step - loss: 537.9722 - val_loss: 512.7339\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 517.4822 - val_loss: 491.3837\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 497.9799 - val_loss: 471.7439\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 12ms/step - loss: 479.8025 - val_loss: 452.9071\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 462.4216 - val_loss: 435.2261\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 445.8796 - val_loss: 418.9127\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 430.5937 - val_loss: 403.1066\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 7ms/step - loss: 416.0554 - val_loss: 387.9305\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 9ms/step - loss: 402.1792 - val_loss: 374.1104\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 389.4765 - val_loss: 361.0492\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 377.0761 - val_loss: 349.2079\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 14ms/step - loss: 366.0402 - val_loss: 337.4464\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 355.3153 - val_loss: 326.7097\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 7ms/step - loss: 345.3653 - val_loss: 316.8034\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 335.8566 - val_loss: 307.9179\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 327.2513 - val_loss: 299.0461\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 318.9563 - val_loss: 291.1788\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 311.3831 - val_loss: 283.5720\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 304.0570 - val_loss: 276.3406\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 297.0897 - val_loss: 269.5996\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 5ms/step - loss: 290.6107 - val_loss: 263.3589\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 284.4619 - val_loss: 257.7619\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 278.7785 - val_loss: 252.2948\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 273.3775 - val_loss: 246.9363\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 268.1175 - val_loss: 242.2899\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 263.2618 - val_loss: 237.9264\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 258.5789 - val_loss: 233.6927\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 254.0813 - val_loss: 229.8213\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 249.9676 - val_loss: 225.9789\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 245.8965 - val_loss: 222.6393\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 242.1004 - val_loss: 219.2698\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 238.3252 - val_loss: 216.2253\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 234.8267 - val_loss: 213.1848\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 231.4693 - val_loss: 210.4009\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 228.1812 - val_loss: 207.7232\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.1268 - val_loss: 205.3993\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 7ms/step - loss: 222.2023 - val_loss: 202.6850\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 219.1584 - val_loss: 200.6369\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 216.3129 - val_loss: 198.2759\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 213.5686 - val_loss: 196.1659\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 211.0108 - val_loss: 194.0152\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.4997 - val_loss: 192.0435\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 7ms/step - loss: 206.0720 - val_loss: 190.1561\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 203.8234 - val_loss: 188.3159\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 201.5442 - val_loss: 186.7120\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.3843 - val_loss: 185.0738\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 197.2519 - val_loss: 183.4861\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 195.1548 - val_loss: 181.9605\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.1787 - val_loss: 180.4614\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.2919 - val_loss: 178.9669\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.3414 - val_loss: 177.6073\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 187.5559 - val_loss: 176.2691\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 185.8491 - val_loss: 174.9899\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 184.1181 - val_loss: 173.7616\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.4464 - val_loss: 172.5949\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.8629 - val_loss: 171.4460\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.1813 - val_loss: 170.0875\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 7ms/step - loss: 177.6183 - val_loss: 168.6713\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1532.7979 - val_loss: 1569.9452\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 5ms/step - loss: 1516.9464 - val_loss: 1554.7122\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1501.2084 - val_loss: 1539.5237\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1485.5558 - val_loss: 1524.3885\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 7ms/step - loss: 1470.1526 - val_loss: 1508.7333\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1454.1716 - val_loss: 1493.2096\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1438.2196 - val_loss: 1476.9880\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1421.5920 - val_loss: 1460.3888\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1404.6870 - val_loss: 1442.9476\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 7ms/step - loss: 1387.2620 - val_loss: 1424.9667\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 1369.0143 - val_loss: 1406.7115\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 1350.2833 - val_loss: 1387.6565\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1330.7954 - val_loss: 1368.0154\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 7ms/step - loss: 1310.7080 - val_loss: 1346.9727\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1289.5642 - val_loss: 1325.6115\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 1268.0782 - val_loss: 1303.3660\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1245.5591 - val_loss: 1280.8192\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1222.5125 - val_loss: 1257.1310\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1198.4805 - val_loss: 1232.9342\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 1174.0875 - val_loss: 1207.5758\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 1148.4424 - val_loss: 1181.2573\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1122.0361 - val_loss: 1154.1886\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 1095.0762 - val_loss: 1126.1376\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 1067.0651 - val_loss: 1097.2527\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1037.9692 - val_loss: 1067.5746\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 1007.8796 - val_loss: 1037.0981\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 977.0192 - val_loss: 1004.6604\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 944.4788 - val_loss: 971.9713\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 911.1795 - val_loss: 938.3943\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 8ms/step - loss: 877.0139 - val_loss: 904.2252\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 11ms/step - loss: 842.7750 - val_loss: 869.5103\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 7ms/step - loss: 807.7228 - val_loss: 834.7634\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 12ms/step - loss: 772.8117 - val_loss: 799.4169\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 737.2180 - val_loss: 765.8041\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 703.0192 - val_loss: 731.5846\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 669.1453 - val_loss: 698.6744\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 636.8097 - val_loss: 665.8975\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 8ms/step - loss: 604.8907 - val_loss: 635.3900\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 574.7899 - val_loss: 604.2758\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 13ms/step - loss: 545.3914 - val_loss: 575.5054\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 13ms/step - loss: 517.8857 - val_loss: 548.1057\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 491.8064 - val_loss: 521.8663\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 467.3779 - val_loss: 496.8704\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 444.1895 - val_loss: 472.7699\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 422.3217 - val_loss: 450.7032\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 402.0603 - val_loss: 429.8819\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 383.2500 - val_loss: 410.0518\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 365.7627 - val_loss: 391.7663\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 349.6482 - val_loss: 374.6993\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 334.7415 - val_loss: 358.7843\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 321.1435 - val_loss: 343.8816\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 308.7106 - val_loss: 330.2693\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 297.3503 - val_loss: 317.5015\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 286.8400 - val_loss: 306.1216\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 277.4396 - val_loss: 295.4797\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 268.7885 - val_loss: 285.7847\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 261.2527 - val_loss: 276.6905\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 254.0397 - val_loss: 268.3024\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 5ms/step - loss: 247.6999 - val_loss: 261.2158\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 241.8673 - val_loss: 254.6018\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 236.7192 - val_loss: 247.9389\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 231.8607 - val_loss: 242.2406\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 227.3924 - val_loss: 237.2996\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 223.5114 - val_loss: 232.2378\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 219.8533 - val_loss: 228.1741\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 216.5946 - val_loss: 223.6264\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 213.4426 - val_loss: 220.6797\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.7014 - val_loss: 217.0338\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 208.1035 - val_loss: 214.0563\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 205.8385 - val_loss: 210.9456\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 7ms/step - loss: 203.4698 - val_loss: 208.5583\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 201.3565 - val_loss: 205.9332\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.2428 - val_loss: 203.6793\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 197.4750 - val_loss: 201.0198\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.5779 - val_loss: 198.9950\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 193.8002 - val_loss: 197.3585\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 5ms/step - loss: 192.0885 - val_loss: 195.5759\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 190.6494 - val_loss: 193.7855\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.9349 - val_loss: 192.1883\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 187.5600 - val_loss: 190.2902\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 186.1594 - val_loss: 188.6239\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 184.7937 - val_loss: 187.3758\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 183.5445 - val_loss: 185.9108\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.3755 - val_loss: 184.4960\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.1269 - val_loss: 183.5678\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.9659 - val_loss: 182.3147\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 178.8514 - val_loss: 181.1612\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 177.7465 - val_loss: 180.1750\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.6268 - val_loss: 179.1464\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.5043 - val_loss: 177.8329\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.5186 - val_loss: 176.9202\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.3397 - val_loss: 175.9142\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 172.3174 - val_loss: 174.8465\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.3901 - val_loss: 173.3657\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.2991 - val_loss: 172.6173\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.3808 - val_loss: 172.0071\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.4303 - val_loss: 170.9566\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 167.4930 - val_loss: 170.3316\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.5089 - val_loss: 169.3128\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.5699 - val_loss: 168.6440\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1589.0680 - val_loss: 1629.9437\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 1571.6208 - val_loss: 1612.2899\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 1554.8076 - val_loss: 1594.9747\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 5ms/step - loss: 1538.1919 - val_loss: 1578.0781\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1521.6902 - val_loss: 1561.1450\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1505.1971 - val_loss: 1544.0785\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1488.5322 - val_loss: 1526.9109\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 5ms/step - loss: 1471.6229 - val_loss: 1509.2900\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1454.2456 - val_loss: 1491.1117\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1436.4882 - val_loss: 1472.5463\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 1418.0811 - val_loss: 1453.5520\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 1399.4066 - val_loss: 1433.8629\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1379.9116 - val_loss: 1413.9922\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 1359.9397 - val_loss: 1393.0231\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 9ms/step - loss: 1339.2767 - val_loss: 1371.4724\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 12ms/step - loss: 1317.9526 - val_loss: 1349.5665\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 1296.2124 - val_loss: 1326.8568\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1273.7156 - val_loss: 1303.5964\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1250.4690 - val_loss: 1280.1683\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1226.9237 - val_loss: 1255.4490\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 1202.5164 - val_loss: 1230.3147\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1177.4844 - val_loss: 1204.5981\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1151.9575 - val_loss: 1177.6212\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 1125.5424 - val_loss: 1150.5211\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 13ms/step - loss: 1098.8446 - val_loss: 1122.8289\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 1071.5459 - val_loss: 1094.9823\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 7ms/step - loss: 1043.9785 - val_loss: 1066.8890\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 13ms/step - loss: 1016.3538 - val_loss: 1037.4059\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 987.8733 - val_loss: 1007.7675\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 959.1221 - val_loss: 978.5022\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 5ms/step - loss: 930.3746 - val_loss: 949.0588\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 901.6172 - val_loss: 918.9907\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 872.3806 - val_loss: 889.4983\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 843.5170 - val_loss: 860.1700\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 815.1444 - val_loss: 830.8646\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 786.7549 - val_loss: 802.5352\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 758.9655 - val_loss: 774.2587\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 731.3784 - val_loss: 745.9592\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 704.2172 - val_loss: 718.5108\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 677.6741 - val_loss: 691.9315\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 651.6001 - val_loss: 665.7839\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 626.2142 - val_loss: 640.7057\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 601.7909 - val_loss: 615.9929\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 577.8709 - val_loss: 592.3812\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 555.0754 - val_loss: 569.5220\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 532.7207 - val_loss: 547.8345\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 511.6902 - val_loss: 526.6577\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 5ms/step - loss: 491.4937 - val_loss: 506.9423\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 472.2419 - val_loss: 488.0941\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 454.1169 - val_loss: 470.0787\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 436.8249 - val_loss: 452.8022\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 420.2749 - val_loss: 437.5968\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 405.1692 - val_loss: 422.1240\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 390.5454 - val_loss: 407.7928\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 376.8598 - val_loss: 394.3772\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 364.1357 - val_loss: 382.0013\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 352.1487 - val_loss: 370.7560\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 341.1050 - val_loss: 359.9911\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 330.6588 - val_loss: 349.9050\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 320.8816 - val_loss: 340.9237\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 312.1434 - val_loss: 332.1160\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 303.5708 - val_loss: 324.5813\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 295.9054 - val_loss: 316.9594\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 288.4847 - val_loss: 310.4237\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 281.8264 - val_loss: 304.1674\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 275.5984 - val_loss: 298.0579\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 269.6792 - val_loss: 292.8156\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 264.2250 - val_loss: 287.8719\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 259.1696 - val_loss: 283.1797\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 254.4093 - val_loss: 278.5743\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 249.8397 - val_loss: 274.8570\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 245.7238 - val_loss: 270.9451\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 241.9101 - val_loss: 267.4223\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 238.1716 - val_loss: 264.0806\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 234.8760 - val_loss: 260.8835\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 231.5645 - val_loss: 258.0697\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 228.5634 - val_loss: 255.1608\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.6392 - val_loss: 252.5781\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.7941 - val_loss: 249.9832\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 220.1734 - val_loss: 247.6074\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 217.6366 - val_loss: 245.2292\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.1677 - val_loss: 242.8356\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 212.7444 - val_loss: 240.6387\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 210.3492 - val_loss: 238.4446\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.0868 - val_loss: 236.3526\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.0182 - val_loss: 234.1721\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 203.6546 - val_loss: 232.1513\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 201.5631 - val_loss: 230.0583\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 199.4604 - val_loss: 228.3534\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.4014 - val_loss: 226.1953\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 195.3562 - val_loss: 223.9838\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.3146 - val_loss: 222.1822\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 191.2983 - val_loss: 220.2225\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.3556 - val_loss: 218.3375\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 187.4444 - val_loss: 216.4694\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 5ms/step - loss: 185.4839 - val_loss: 214.6191\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.5957 - val_loss: 212.7315\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 181.7810 - val_loss: 211.0396\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.9515 - val_loss: 209.2725\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 178.0788 - val_loss: 207.1822\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 42ms/step - loss: 1523.7310 - val_loss: 1502.5768\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1509.1168 - val_loss: 1487.2859\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 7ms/step - loss: 1494.0752 - val_loss: 1471.6409\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 1478.4393 - val_loss: 1455.6906\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1462.3003 - val_loss: 1438.5828\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1445.2512 - val_loss: 1420.9434\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1427.6135 - val_loss: 1401.8229\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1408.5116 - val_loss: 1381.9579\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 1388.4619 - val_loss: 1361.0743\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1367.3104 - val_loss: 1338.0699\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 13ms/step - loss: 1344.3979 - val_loss: 1314.3125\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1320.5055 - val_loss: 1288.9402\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 13ms/step - loss: 1295.0459 - val_loss: 1262.3434\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 13ms/step - loss: 1268.3575 - val_loss: 1233.8478\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1240.0267 - val_loss: 1204.4071\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 1210.4159 - val_loss: 1173.3116\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1179.0046 - val_loss: 1140.5627\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1146.2378 - val_loss: 1107.0630\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 5ms/step - loss: 1112.3617 - val_loss: 1072.5504\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 1077.0591 - val_loss: 1036.5647\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1041.1613 - val_loss: 999.1647\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1003.8556 - val_loss: 962.1884\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 966.5815 - val_loss: 924.5069\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 928.6359 - val_loss: 886.4850\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 890.6058 - val_loss: 847.8339\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 851.9886 - val_loss: 810.0531\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 813.7519 - val_loss: 772.3717\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 775.8201 - val_loss: 735.4548\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 5ms/step - loss: 738.3318 - val_loss: 698.4790\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 701.9824 - val_loss: 661.8950\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 665.7316 - val_loss: 627.7142\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 630.9645 - val_loss: 594.6968\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 597.6761 - val_loss: 562.3654\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 565.3525 - val_loss: 531.6859\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 534.7255 - val_loss: 502.1091\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 505.3592 - val_loss: 474.6826\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 477.6757 - val_loss: 449.2293\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 451.7349 - val_loss: 424.2778\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 426.6246 - val_loss: 401.7372\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 404.0715 - val_loss: 379.6117\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 382.2065 - val_loss: 359.9659\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 362.1444 - val_loss: 342.3030\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 344.3909 - val_loss: 324.4744\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 326.8154 - val_loss: 309.6753\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 311.6553 - val_loss: 295.4697\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 297.5291 - val_loss: 282.7079\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 284.5645 - val_loss: 271.3822\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 273.1313 - val_loss: 260.4904\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 262.0729 - val_loss: 251.6106\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 252.6027 - val_loss: 243.1292\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 243.7758 - val_loss: 235.4150\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 236.1369 - val_loss: 228.1703\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 228.7081 - val_loss: 222.3198\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.2733 - val_loss: 216.7948\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 5ms/step - loss: 216.4798 - val_loss: 211.5780\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 211.1314 - val_loss: 207.0043\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.2921 - val_loss: 203.0161\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 201.9330 - val_loss: 199.0326\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.7114 - val_loss: 195.7616\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.1412 - val_loss: 192.7470\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.6670 - val_loss: 189.9312\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 187.6032 - val_loss: 187.3081\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 184.6319 - val_loss: 185.0106\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.9176 - val_loss: 182.8382\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.4256 - val_loss: 180.9135\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 177.0524 - val_loss: 178.9856\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 7ms/step - loss: 174.7856 - val_loss: 177.2835\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.6760 - val_loss: 175.6780\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 170.6144 - val_loss: 174.1112\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.7658 - val_loss: 172.6765\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 167.0308 - val_loss: 171.3644\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.2031 - val_loss: 170.0424\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 163.5547 - val_loss: 168.7965\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.9847 - val_loss: 167.5900\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.4989 - val_loss: 166.5271\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.0756 - val_loss: 165.4306\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.7264 - val_loss: 164.3045\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.3311 - val_loss: 163.3792\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.1569 - val_loss: 162.5123\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 153.8949 - val_loss: 161.4942\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.6796 - val_loss: 160.6370\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.5106 - val_loss: 159.7503\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 150.3820 - val_loss: 158.9168\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 149.3397 - val_loss: 158.0696\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.2311 - val_loss: 157.2590\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.2276 - val_loss: 156.4950\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.1842 - val_loss: 155.7021\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 145.2781 - val_loss: 154.9949\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 144.2687 - val_loss: 154.2563\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 143.3600 - val_loss: 153.5196\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 142.4861 - val_loss: 152.8506\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.6039 - val_loss: 152.1718\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.7180 - val_loss: 151.5829\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 139.9110 - val_loss: 150.8861\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 139.1122 - val_loss: 150.1695\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 138.2819 - val_loss: 149.5858\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 137.5458 - val_loss: 148.8849\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.6740 - val_loss: 148.1878\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 135.9899 - val_loss: 147.5292\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.2271 - val_loss: 147.0399\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 61ms/step - loss: 1502.0994 - val_loss: 1457.7032\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1483.8527 - val_loss: 1438.9484\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1465.0005 - val_loss: 1419.3496\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 1445.1858 - val_loss: 1398.8983\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 11ms/step - loss: 1424.2607 - val_loss: 1377.9373\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1402.9436 - val_loss: 1355.2080\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1380.1855 - val_loss: 1331.4902\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1356.3456 - val_loss: 1306.6296\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1331.3140 - val_loss: 1281.1931\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1305.8192 - val_loss: 1253.8433\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 1278.2682 - val_loss: 1226.5082\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 1250.0842 - val_loss: 1196.9824\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1220.5483 - val_loss: 1166.9351\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 1190.4259 - val_loss: 1136.3887\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1159.4174 - val_loss: 1104.1616\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 1127.3423 - val_loss: 1072.0527\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1094.9814 - val_loss: 1039.0515\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 1061.9419 - val_loss: 1006.0599\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 1028.2384 - val_loss: 973.0642\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 994.7803 - val_loss: 939.1464\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 961.4507 - val_loss: 905.0110\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 927.1310 - val_loss: 872.0504\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 893.8179 - val_loss: 838.8904\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 860.6616 - val_loss: 805.8362\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 5ms/step - loss: 827.3496 - val_loss: 773.7306\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 795.0588 - val_loss: 741.4845\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 762.7424 - val_loss: 710.4860\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 5ms/step - loss: 731.6000 - val_loss: 679.6399\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 700.2185 - val_loss: 649.9159\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 669.8870 - val_loss: 620.7669\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 5ms/step - loss: 640.3184 - val_loss: 592.7410\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 611.8435 - val_loss: 565.5521\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 584.0316 - val_loss: 539.1667\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 5ms/step - loss: 557.1320 - val_loss: 514.2155\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 531.1092 - val_loss: 490.2805\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 506.2117 - val_loss: 467.3781\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 482.4378 - val_loss: 445.8324\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 459.8470 - val_loss: 425.8129\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 438.7498 - val_loss: 405.8374\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 417.9913 - val_loss: 387.5647\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 398.8089 - val_loss: 370.3354\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 380.2382 - val_loss: 354.4709\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 363.2181 - val_loss: 339.0518\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 346.9547 - val_loss: 325.1824\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 332.0783 - val_loss: 312.2485\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 318.1650 - val_loss: 300.4082\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 305.4359 - val_loss: 289.2297\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 293.2914 - val_loss: 279.3307\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 282.3194 - val_loss: 269.9228\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 7ms/step - loss: 272.2456 - val_loss: 261.0679\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 262.8091 - val_loss: 253.1991\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 5ms/step - loss: 254.0016 - val_loss: 246.2465\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 246.1028 - val_loss: 239.4677\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 238.6946 - val_loss: 233.5113\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 232.0950 - val_loss: 227.7683\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 225.7881 - val_loss: 222.7815\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 220.1209 - val_loss: 218.2146\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 215.0131 - val_loss: 214.0184\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 7ms/step - loss: 210.2200 - val_loss: 210.2205\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.8377 - val_loss: 206.6525\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 201.6711 - val_loss: 203.4396\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.0000 - val_loss: 200.5167\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 194.4903 - val_loss: 197.7789\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.2191 - val_loss: 195.3307\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 188.2858 - val_loss: 192.8022\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.2554 - val_loss: 190.7829\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 7ms/step - loss: 182.8125 - val_loss: 188.7216\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 180.2436 - val_loss: 186.8351\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 178.0312 - val_loss: 185.2834\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.8245 - val_loss: 183.5810\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.8778 - val_loss: 182.1046\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.9052 - val_loss: 180.7092\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 7ms/step - loss: 170.0789 - val_loss: 179.5324\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.3667 - val_loss: 178.2648\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.7561 - val_loss: 177.0632\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.2034 - val_loss: 175.8041\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 163.7020 - val_loss: 174.7561\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 162.2779 - val_loss: 173.7743\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.9128 - val_loss: 172.9386\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.7131 - val_loss: 171.9527\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 158.5247 - val_loss: 171.1094\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.4371 - val_loss: 170.2025\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.3543 - val_loss: 169.4099\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.3176 - val_loss: 168.5841\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.3813 - val_loss: 167.7624\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 13ms/step - loss: 153.4065 - val_loss: 166.7895\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 13ms/step - loss: 152.5538 - val_loss: 166.1305\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.6723 - val_loss: 165.2307\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.7751 - val_loss: 164.5990\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.9630 - val_loss: 163.7805\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.1612 - val_loss: 163.1866\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 8ms/step - loss: 148.3006 - val_loss: 162.4967\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.5251 - val_loss: 161.7451\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 146.7579 - val_loss: 161.2247\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 14ms/step - loss: 145.8696 - val_loss: 160.4104\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 11ms/step - loss: 145.1277 - val_loss: 159.7666\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 144.3193 - val_loss: 158.9535\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 143.5638 - val_loss: 158.3242\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.8225 - val_loss: 157.8043\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 142.0016 - val_loss: 157.0351\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1489.7859 - val_loss: 1529.3790\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1471.5693 - val_loss: 1510.4454\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1452.4087 - val_loss: 1490.3138\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1432.0983 - val_loss: 1469.0912\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 7ms/step - loss: 1410.9642 - val_loss: 1446.3878\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 1388.3932 - val_loss: 1423.2089\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1364.9951 - val_loss: 1398.5204\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1340.5435 - val_loss: 1372.6289\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1314.7719 - val_loss: 1345.8046\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1288.2684 - val_loss: 1317.5468\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1260.2983 - val_loss: 1288.4419\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 1231.4108 - val_loss: 1258.2256\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1201.1161 - val_loss: 1226.7225\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1169.8528 - val_loss: 1193.9171\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 1137.6541 - val_loss: 1160.8051\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 1105.1078 - val_loss: 1126.1204\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1071.1260 - val_loss: 1091.5242\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 1037.2002 - val_loss: 1055.7874\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 1002.5748 - val_loss: 1019.9104\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 967.3776 - val_loss: 984.3256\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 932.2511 - val_loss: 947.7592\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 896.5778 - val_loss: 911.8246\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 861.9158 - val_loss: 875.1459\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 826.5200 - val_loss: 839.5836\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 792.2731 - val_loss: 803.7000\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 758.2299 - val_loss: 769.2097\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 725.0709 - val_loss: 735.4841\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 692.6476 - val_loss: 702.6570\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 660.6528 - val_loss: 671.5994\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 630.5844 - val_loss: 639.4875\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 8ms/step - loss: 600.7480 - val_loss: 609.5631\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 572.6721 - val_loss: 580.8488\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 545.2266 - val_loss: 553.6374\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 519.6590 - val_loss: 527.8005\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 495.3916 - val_loss: 503.1695\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 472.0826 - val_loss: 479.4386\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 450.0837 - val_loss: 457.3580\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 429.2953 - val_loss: 436.9362\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 410.3295 - val_loss: 417.0910\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 392.1088 - val_loss: 399.0231\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 375.4643 - val_loss: 382.4753\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 359.9318 - val_loss: 366.6274\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 345.3336 - val_loss: 352.2353\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 331.9707 - val_loss: 338.2059\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 319.1124 - val_loss: 325.9578\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 307.9034 - val_loss: 314.0788\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 297.1599 - val_loss: 303.4561\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 287.4386 - val_loss: 294.1160\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 278.6840 - val_loss: 285.4772\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 270.5735 - val_loss: 277.2144\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 263.0962 - val_loss: 269.6775\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 256.3434 - val_loss: 262.7144\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 250.2094 - val_loss: 256.3935\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 244.5276 - val_loss: 250.8103\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 239.4160 - val_loss: 245.6209\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 234.7228 - val_loss: 240.7884\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 230.2854 - val_loss: 236.4658\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 226.4135 - val_loss: 232.4446\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 5ms/step - loss: 222.9975 - val_loss: 228.4220\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 219.3845 - val_loss: 225.1647\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 216.5060 - val_loss: 221.8362\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 213.5203 - val_loss: 219.0042\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.9154 - val_loss: 216.1474\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 5ms/step - loss: 208.5066 - val_loss: 213.3444\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 206.0558 - val_loss: 210.8820\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 203.8028 - val_loss: 208.5236\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.7296 - val_loss: 206.0743\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 199.7120 - val_loss: 203.9732\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 197.7978 - val_loss: 201.9724\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 195.9682 - val_loss: 200.0108\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.2542 - val_loss: 198.0953\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 8ms/step - loss: 192.5383 - val_loss: 196.3372\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 10ms/step - loss: 190.9082 - val_loss: 194.5068\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 189.2449 - val_loss: 192.7577\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 13ms/step - loss: 187.7176 - val_loss: 191.0562\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.1901 - val_loss: 189.3663\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 13ms/step - loss: 184.6487 - val_loss: 187.6476\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.1978 - val_loss: 186.0287\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 13ms/step - loss: 181.7648 - val_loss: 184.5042\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 13ms/step - loss: 180.4316 - val_loss: 182.8447\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 12ms/step - loss: 179.1022 - val_loss: 181.3191\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.7999 - val_loss: 179.8992\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.5876 - val_loss: 178.4343\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 175.3865 - val_loss: 177.1255\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 174.1863 - val_loss: 175.6821\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 5ms/step - loss: 172.9783 - val_loss: 174.3439\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 171.8910 - val_loss: 173.0327\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 170.7556 - val_loss: 171.8120\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 169.5850 - val_loss: 170.4673\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.5104 - val_loss: 169.0857\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 167.4235 - val_loss: 167.7155\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.3071 - val_loss: 166.4794\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 7ms/step - loss: 165.2344 - val_loss: 165.1382\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.1333 - val_loss: 163.9407\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.1145 - val_loss: 162.7220\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 162.0846 - val_loss: 161.6585\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.1122 - val_loss: 160.5804\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 5ms/step - loss: 160.1222 - val_loss: 159.4495\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.1864 - val_loss: 158.4177\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 158.3421 - val_loss: 157.3418\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 43ms/step - loss: 1536.0731 - val_loss: 1481.4331\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 6ms/step - loss: 1519.3256 - val_loss: 1465.1183\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1501.9810 - val_loss: 1448.3169\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 5ms/step - loss: 1484.0132 - val_loss: 1430.7953\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1465.0144 - val_loss: 1412.5635\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1445.2747 - val_loss: 1393.2214\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1424.3979 - val_loss: 1372.9172\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1402.4927 - val_loss: 1351.5986\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 1379.5690 - val_loss: 1329.0538\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 1355.4590 - val_loss: 1305.8019\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 1330.2249 - val_loss: 1281.3846\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 1303.8069 - val_loss: 1255.8291\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1276.3413 - val_loss: 1229.3800\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 1248.2373 - val_loss: 1201.5983\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1218.8419 - val_loss: 1173.7786\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 1189.0748 - val_loss: 1144.7517\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 1158.0519 - val_loss: 1115.4608\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 1126.5972 - val_loss: 1085.5695\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 1094.7092 - val_loss: 1055.0518\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1062.3011 - val_loss: 1023.8738\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 1029.5573 - val_loss: 993.1564\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 997.0157 - val_loss: 961.2060\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 963.9098 - val_loss: 929.7318\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 931.0352 - val_loss: 897.9195\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 897.9848 - val_loss: 866.8704\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 865.5137 - val_loss: 835.4884\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 832.9074 - val_loss: 804.5338\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 800.4962 - val_loss: 774.2172\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 5ms/step - loss: 769.6532 - val_loss: 743.0240\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 5ms/step - loss: 737.9670 - val_loss: 713.8797\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 707.8170 - val_loss: 684.9385\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 678.3296 - val_loss: 656.6396\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 649.2308 - val_loss: 629.7684\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 621.5859 - val_loss: 602.6702\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 5ms/step - loss: 594.7188 - val_loss: 576.6576\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 568.6473 - val_loss: 551.4675\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 543.3445 - val_loss: 528.0895\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 519.8843 - val_loss: 504.6698\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 496.5016 - val_loss: 483.1568\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 475.1111 - val_loss: 461.9545\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 453.9732 - val_loss: 442.6860\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 434.5952 - val_loss: 423.7459\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 7ms/step - loss: 416.0629 - val_loss: 405.8455\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 5ms/step - loss: 398.4798 - val_loss: 389.7177\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 382.3439 - val_loss: 373.6817\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 366.7067 - val_loss: 359.1624\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 352.0913 - val_loss: 345.8539\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 338.7610 - val_loss: 332.5895\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 326.0437 - val_loss: 320.8332\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 314.2631 - val_loss: 310.0884\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 303.6489 - val_loss: 299.7043\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 8ms/step - loss: 293.5826 - val_loss: 290.4093\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 13ms/step - loss: 284.3681 - val_loss: 281.8194\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 275.9779 - val_loss: 273.7271\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 268.0176 - val_loss: 266.4263\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 260.6652 - val_loss: 259.7462\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 254.1255 - val_loss: 253.3750\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 247.8287 - val_loss: 247.7365\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 242.1770 - val_loss: 242.1878\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 236.7981 - val_loss: 237.3666\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 13ms/step - loss: 231.9231 - val_loss: 232.8038\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 227.3630 - val_loss: 228.4734\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 13ms/step - loss: 223.1862 - val_loss: 224.4601\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 14ms/step - loss: 219.2108 - val_loss: 220.6996\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.5240 - val_loss: 217.2594\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 212.1789 - val_loss: 214.0563\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 5ms/step - loss: 208.8802 - val_loss: 210.9641\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.9044 - val_loss: 208.0076\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 203.0214 - val_loss: 205.1631\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 200.2081 - val_loss: 202.5331\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.6320 - val_loss: 200.0124\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 195.1135 - val_loss: 197.6418\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 192.7748 - val_loss: 195.3400\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 190.5381 - val_loss: 193.1575\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.3358 - val_loss: 191.0509\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.3390 - val_loss: 188.7927\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.2134 - val_loss: 186.7879\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.2986 - val_loss: 184.8279\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 180.4144 - val_loss: 182.8936\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 178.6126 - val_loss: 180.9233\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.8158 - val_loss: 179.0400\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.0301 - val_loss: 177.3098\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 173.3038 - val_loss: 175.5697\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 171.7279 - val_loss: 173.9011\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 170.0840 - val_loss: 172.2022\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 5ms/step - loss: 168.5010 - val_loss: 170.6765\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.9358 - val_loss: 169.0411\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 165.4796 - val_loss: 167.4124\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 163.9422 - val_loss: 165.8595\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 162.5319 - val_loss: 164.3865\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 5ms/step - loss: 161.0913 - val_loss: 163.0816\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.6576 - val_loss: 161.5250\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.2316 - val_loss: 160.1121\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.8810 - val_loss: 158.6434\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.5118 - val_loss: 157.1803\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 154.2054 - val_loss: 155.8207\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.8418 - val_loss: 154.3994\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.5778 - val_loss: 153.1243\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 150.2895 - val_loss: 151.7011\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 148.9941 - val_loss: 150.5778\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1569.6952 - val_loss: 1604.8888\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 1556.9075 - val_loss: 1592.5659\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1544.7170 - val_loss: 1580.4283\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 1532.6556 - val_loss: 1568.2700\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1520.5137 - val_loss: 1555.8698\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1508.1744 - val_loss: 1543.0398\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 1495.2084 - val_loss: 1529.8203\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1481.7798 - val_loss: 1515.6298\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1467.3164 - val_loss: 1500.9685\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1452.3173 - val_loss: 1485.3593\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1436.2035 - val_loss: 1469.0541\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1419.2343 - val_loss: 1451.9454\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1401.1760 - val_loss: 1433.6993\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1382.2992 - val_loss: 1414.1636\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 1361.7963 - val_loss: 1394.1611\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1340.2889 - val_loss: 1372.8940\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1318.1946 - val_loss: 1349.9226\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 1294.1251 - val_loss: 1326.8694\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1269.8285 - val_loss: 1302.1501\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 1244.0287 - val_loss: 1276.5485\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 1216.9542 - val_loss: 1250.4443\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1189.4349 - val_loss: 1223.0409\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 1160.7246 - val_loss: 1194.1821\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1130.9126 - val_loss: 1164.7896\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1100.2771 - val_loss: 1134.3856\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 1069.1260 - val_loss: 1103.0513\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 1036.7273 - val_loss: 1071.3918\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 1004.2687 - val_loss: 1038.2773\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 970.0998 - val_loss: 1005.3383\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 936.1231 - val_loss: 971.5976\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 901.3920 - val_loss: 938.1529\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 867.1796 - val_loss: 903.4518\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 832.5792 - val_loss: 869.6719\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 798.5873 - val_loss: 835.8256\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 764.5259 - val_loss: 803.0206\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 731.3828 - val_loss: 770.0299\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 698.7004 - val_loss: 737.1903\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 5ms/step - loss: 666.6087 - val_loss: 705.3742\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 8ms/step - loss: 635.4037 - val_loss: 674.1213\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 604.8414 - val_loss: 643.9371\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 8ms/step - loss: 575.6080 - val_loss: 613.8761\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 11ms/step - loss: 547.0120 - val_loss: 585.2062\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 519.5477 - val_loss: 557.3719\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 492.9655 - val_loss: 530.5845\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 467.6230 - val_loss: 505.0322\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 13ms/step - loss: 443.6934 - val_loss: 480.4955\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 420.7769 - val_loss: 457.2935\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 13ms/step - loss: 399.3837 - val_loss: 435.2211\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 13ms/step - loss: 379.0787 - val_loss: 414.7950\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 13ms/step - loss: 360.2864 - val_loss: 395.5761\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 342.6407 - val_loss: 377.4583\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 326.3907 - val_loss: 360.8071\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 311.3526 - val_loss: 345.3583\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 297.5103 - val_loss: 330.8394\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 284.5885 - val_loss: 317.8008\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 273.0180 - val_loss: 305.5166\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 5ms/step - loss: 262.3442 - val_loss: 294.9413\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 252.8857 - val_loss: 284.9449\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 243.9376 - val_loss: 275.8730\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 236.1477 - val_loss: 267.4849\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 228.8057 - val_loss: 259.9254\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 5ms/step - loss: 222.2650 - val_loss: 253.3892\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 5ms/step - loss: 216.7736 - val_loss: 246.9297\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 5ms/step - loss: 211.3284 - val_loss: 241.8520\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.7096 - val_loss: 237.2490\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.5609 - val_loss: 232.4812\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.5040 - val_loss: 228.4237\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.9711 - val_loss: 224.9566\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.7913 - val_loss: 221.3799\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 188.7105 - val_loss: 218.3907\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.1563 - val_loss: 215.4032\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 183.6658 - val_loss: 212.8601\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.5016 - val_loss: 210.3251\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.3444 - val_loss: 208.3872\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.4260 - val_loss: 206.0703\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.5887 - val_loss: 203.6725\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.8458 - val_loss: 201.7799\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.2068 - val_loss: 199.8055\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 5ms/step - loss: 170.8124 - val_loss: 197.8483\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.2233 - val_loss: 196.7938\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 167.9202 - val_loss: 194.7707\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.5714 - val_loss: 193.2368\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 165.2965 - val_loss: 191.9383\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 164.0756 - val_loss: 190.2617\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.8656 - val_loss: 188.6266\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 7ms/step - loss: 161.7691 - val_loss: 187.3840\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 160.6351 - val_loss: 186.2480\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.5816 - val_loss: 184.5216\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.4925 - val_loss: 183.3815\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.4430 - val_loss: 182.3643\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.4609 - val_loss: 180.7774\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.4689 - val_loss: 179.7147\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.5786 - val_loss: 178.6998\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 153.6354 - val_loss: 177.7574\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 152.7197 - val_loss: 176.6640\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.8466 - val_loss: 175.8723\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.9802 - val_loss: 174.8304\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.1208 - val_loss: 173.8371\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 149.3333 - val_loss: 172.8570\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 148.5550 - val_loss: 172.2608\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1598.5198 - val_loss: 1469.2450\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 1580.7797 - val_loss: 1453.6897\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 1563.4514 - val_loss: 1437.9775\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 5ms/step - loss: 1545.9846 - val_loss: 1422.4332\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1528.4806 - val_loss: 1406.6490\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1510.3363 - val_loss: 1390.5378\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 5ms/step - loss: 1491.9081 - val_loss: 1373.8545\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1472.8444 - val_loss: 1356.4833\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 1452.7761 - val_loss: 1338.6652\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1432.3010 - val_loss: 1319.4896\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1410.2983 - val_loss: 1300.2704\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 1387.8390 - val_loss: 1279.5151\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1363.9087 - val_loss: 1257.6100\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1338.3517 - val_loss: 1235.0189\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1312.1534 - val_loss: 1210.6648\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 1284.0287 - val_loss: 1186.0079\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 1255.4579 - val_loss: 1159.7300\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 5ms/step - loss: 1225.8500 - val_loss: 1133.0142\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 5ms/step - loss: 1195.5780 - val_loss: 1105.5437\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 1164.5967 - val_loss: 1077.8462\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 5ms/step - loss: 1132.7350 - val_loss: 1049.5121\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 1100.4996 - val_loss: 1020.8371\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1067.8944 - val_loss: 991.3239\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 1034.8363 - val_loss: 962.2225\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 13ms/step - loss: 1002.1566 - val_loss: 932.6216\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 13ms/step - loss: 969.2746 - val_loss: 903.5220\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 936.7551 - val_loss: 874.3048\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 904.3679 - val_loss: 845.4869\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 13ms/step - loss: 872.7423 - val_loss: 816.6174\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 841.0338 - val_loss: 788.7218\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 810.3356 - val_loss: 760.8517\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 12ms/step - loss: 779.9855 - val_loss: 733.6491\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 14ms/step - loss: 750.5967 - val_loss: 707.1976\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 11ms/step - loss: 721.7512 - val_loss: 681.2810\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 693.9307 - val_loss: 655.8421\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 666.8632 - val_loss: 630.8884\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 640.3008 - val_loss: 607.4714\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 615.3386 - val_loss: 583.6464\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 590.2470 - val_loss: 561.8407\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 566.7419 - val_loss: 540.1605\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 543.8891 - val_loss: 518.9875\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 521.8593 - val_loss: 498.7854\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 500.8431 - val_loss: 479.7368\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 480.9421 - val_loss: 460.7828\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 461.5472 - val_loss: 442.9763\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 442.8900 - val_loss: 426.1108\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 425.2806 - val_loss: 409.7367\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 408.2719 - val_loss: 393.6245\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 391.9029 - val_loss: 378.7094\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 375.9976 - val_loss: 364.2754\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 361.3668 - val_loss: 350.0707\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 346.6919 - val_loss: 337.1530\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 333.4240 - val_loss: 324.5138\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 7ms/step - loss: 320.5218 - val_loss: 312.9048\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 308.5363 - val_loss: 302.0290\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 7ms/step - loss: 297.3253 - val_loss: 292.1251\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 5ms/step - loss: 287.1314 - val_loss: 282.2771\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 277.3039 - val_loss: 273.4283\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 268.4724 - val_loss: 265.3716\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 260.2190 - val_loss: 257.9479\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 252.7804 - val_loss: 251.1489\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 7ms/step - loss: 245.9206 - val_loss: 244.6443\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 239.5822 - val_loss: 239.0445\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 233.7290 - val_loss: 233.9942\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 228.5016 - val_loss: 228.7016\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.4687 - val_loss: 224.3439\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 218.9744 - val_loss: 220.3944\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 214.7490 - val_loss: 216.5015\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 210.8793 - val_loss: 213.0400\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 207.2007 - val_loss: 210.0119\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 203.8787 - val_loss: 206.7948\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 200.7177 - val_loss: 204.0388\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.8882 - val_loss: 201.1581\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.9103 - val_loss: 198.6774\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 192.2862 - val_loss: 196.1980\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.7038 - val_loss: 193.9998\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 187.3157 - val_loss: 191.7343\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.0295 - val_loss: 189.5619\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 182.8332 - val_loss: 187.4445\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.7000 - val_loss: 185.8758\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 178.7253 - val_loss: 183.9313\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 176.9353 - val_loss: 182.1591\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 175.0366 - val_loss: 180.4176\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.2100 - val_loss: 178.8864\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 7ms/step - loss: 171.5196 - val_loss: 177.4059\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.8795 - val_loss: 175.9115\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.2988 - val_loss: 174.5486\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 166.7492 - val_loss: 172.9239\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 165.1948 - val_loss: 171.7430\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 163.6229 - val_loss: 170.3111\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.1744 - val_loss: 168.9079\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.8160 - val_loss: 167.4865\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.4679 - val_loss: 166.3253\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 5ms/step - loss: 158.1148 - val_loss: 165.1990\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 156.7759 - val_loss: 163.9213\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.5040 - val_loss: 162.8080\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.1755 - val_loss: 161.5940\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 5ms/step - loss: 152.9384 - val_loss: 160.4276\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 151.7223 - val_loss: 159.4069\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.5447 - val_loss: 158.2318\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 1576.2983 - val_loss: 1479.2651\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 9ms/step - loss: 1559.8196 - val_loss: 1463.5315\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 1543.3894 - val_loss: 1447.3801\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1526.4081 - val_loss: 1431.0426\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1509.4022 - val_loss: 1414.1866\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 7ms/step - loss: 1491.7173 - val_loss: 1396.6188\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 13ms/step - loss: 1473.2062 - val_loss: 1378.7269\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 9ms/step - loss: 1454.1453 - val_loss: 1359.9761\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 10ms/step - loss: 1434.1615 - val_loss: 1340.3541\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 13ms/step - loss: 1413.2136 - val_loss: 1319.5675\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 14ms/step - loss: 1391.0172 - val_loss: 1297.8669\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 13ms/step - loss: 1368.1616 - val_loss: 1275.2644\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1344.0513 - val_loss: 1251.9590\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1318.8699 - val_loss: 1227.3024\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 13ms/step - loss: 1292.3309 - val_loss: 1201.5902\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 1264.8721 - val_loss: 1174.9761\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1236.4401 - val_loss: 1147.1555\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1206.9751 - val_loss: 1118.7686\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1176.6888 - val_loss: 1089.8408\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 1145.7777 - val_loss: 1060.0427\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 1114.1931 - val_loss: 1029.7194\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1082.1146 - val_loss: 999.3500\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 1049.8097 - val_loss: 968.2854\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 1017.3892 - val_loss: 936.9167\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 984.4439 - val_loss: 906.0534\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 951.7325 - val_loss: 875.0729\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 919.3826 - val_loss: 844.0540\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 887.0860 - val_loss: 813.7538\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 855.3163 - val_loss: 783.4472\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 823.6218 - val_loss: 753.8684\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 792.6982 - val_loss: 725.0912\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 762.5748 - val_loss: 696.8163\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 732.7440 - val_loss: 668.8917\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 703.6869 - val_loss: 641.8159\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 675.6426 - val_loss: 615.3396\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 8ms/step - loss: 648.1526 - val_loss: 589.9425\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 621.3404 - val_loss: 565.6489\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 595.9724 - val_loss: 541.8827\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 571.3103 - val_loss: 519.4019\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 547.7524 - val_loss: 497.7945\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 525.2012 - val_loss: 477.2982\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 503.6374 - val_loss: 457.6369\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 483.0780 - val_loss: 439.1901\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 463.6292 - val_loss: 421.1393\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 444.8376 - val_loss: 404.7272\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 7ms/step - loss: 427.2994 - val_loss: 389.0398\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 410.7760 - val_loss: 374.0341\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 394.9929 - val_loss: 360.4176\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 380.1273 - val_loss: 347.8561\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 366.6206 - val_loss: 335.8026\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 353.6363 - val_loss: 324.8118\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 341.9116 - val_loss: 314.4167\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 330.6693 - val_loss: 305.0202\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 320.5697 - val_loss: 296.1781\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 311.1963 - val_loss: 287.8325\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 302.2488 - val_loss: 280.3813\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 294.0904 - val_loss: 273.8371\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 286.6103 - val_loss: 267.4600\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 279.7179 - val_loss: 261.3783\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 273.0913 - val_loss: 256.0642\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 267.2068 - val_loss: 251.0232\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 261.6750 - val_loss: 246.5406\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 256.6170 - val_loss: 242.3600\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 251.8883 - val_loss: 238.4888\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 247.5663 - val_loss: 234.6472\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 243.4335 - val_loss: 231.2156\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 239.6860 - val_loss: 228.0691\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 236.1342 - val_loss: 225.3017\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 232.8926 - val_loss: 222.7275\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 229.8089 - val_loss: 220.1517\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 226.9489 - val_loss: 217.7383\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 224.2318 - val_loss: 215.3929\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 5ms/step - loss: 221.6471 - val_loss: 213.1981\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.1435 - val_loss: 211.1101\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 7ms/step - loss: 216.6504 - val_loss: 209.2329\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 214.3929 - val_loss: 207.2891\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 212.2734 - val_loss: 205.4101\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.1234 - val_loss: 203.7297\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.0573 - val_loss: 202.0531\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.1068 - val_loss: 200.2906\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.1938 - val_loss: 198.5745\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.2214 - val_loss: 197.0830\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 200.3644 - val_loss: 195.5961\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.6045 - val_loss: 194.0647\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 196.8052 - val_loss: 192.5889\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.1231 - val_loss: 191.1047\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 193.4874 - val_loss: 189.7478\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 191.8454 - val_loss: 188.3576\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.2481 - val_loss: 186.9868\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 188.6302 - val_loss: 185.4358\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.1247 - val_loss: 184.0970\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 7ms/step - loss: 185.4357 - val_loss: 182.6964\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 183.9681 - val_loss: 181.2264\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.3476 - val_loss: 179.8779\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.8717 - val_loss: 178.3880\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.3627 - val_loss: 177.1017\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 177.8056 - val_loss: 175.8140\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 8ms/step - loss: 176.3232 - val_loss: 174.4817\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 11ms/step - loss: 174.7609 - val_loss: 172.9108\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.2458 - val_loss: 171.5173\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 61ms/step - loss: 1547.5123 - val_loss: 1632.4575\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 15ms/step - loss: 1530.1387 - val_loss: 1615.2271\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1512.9683 - val_loss: 1598.7001\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1496.3857 - val_loss: 1582.1665\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1479.8606 - val_loss: 1565.6211\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1463.5360 - val_loss: 1548.7792\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 1446.8417 - val_loss: 1532.2026\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1430.0879 - val_loss: 1514.8041\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1412.6772 - val_loss: 1497.0953\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1394.8445 - val_loss: 1478.6620\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1376.2235 - val_loss: 1459.9061\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1356.7878 - val_loss: 1439.9890\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1336.7190 - val_loss: 1418.6058\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 1315.2032 - val_loss: 1396.8909\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 7ms/step - loss: 1293.1809 - val_loss: 1373.9543\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 1270.0514 - val_loss: 1349.6210\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 1245.8164 - val_loss: 1324.5084\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1220.4275 - val_loss: 1298.8488\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1194.7157 - val_loss: 1271.5005\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1167.2585 - val_loss: 1243.9656\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 1139.7377 - val_loss: 1215.3771\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 1111.0919 - val_loss: 1186.4176\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1082.3328 - val_loss: 1155.7015\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 5ms/step - loss: 1052.0642 - val_loss: 1125.7288\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 1022.4379 - val_loss: 1095.0734\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 992.4697 - val_loss: 1064.2058\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 962.1722 - val_loss: 1033.6796\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 932.3809 - val_loss: 1002.4846\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 901.9924 - val_loss: 971.3597\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 872.0684 - val_loss: 940.3337\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 842.2489 - val_loss: 909.9152\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 812.8745 - val_loss: 879.8313\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 783.8768 - val_loss: 849.5357\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 755.1812 - val_loss: 819.7794\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 726.8643 - val_loss: 790.8989\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 699.5389 - val_loss: 762.2407\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 672.7753 - val_loss: 734.0839\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 646.3638 - val_loss: 706.7392\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 5ms/step - loss: 620.7223 - val_loss: 679.9981\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 595.6962 - val_loss: 653.4171\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 571.4207 - val_loss: 628.0464\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 547.7634 - val_loss: 603.0563\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 525.2961 - val_loss: 578.1822\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 503.0048 - val_loss: 555.4870\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 482.1757 - val_loss: 532.7968\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 462.1365 - val_loss: 510.8851\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 442.6527 - val_loss: 490.5837\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 424.7544 - val_loss: 470.0488\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 407.0535 - val_loss: 451.1590\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 390.5367 - val_loss: 433.2172\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 375.1992 - val_loss: 415.8022\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 360.5875 - val_loss: 399.6726\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 346.9942 - val_loss: 384.9710\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 334.2161 - val_loss: 370.9330\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 322.3564 - val_loss: 357.2797\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 311.1347 - val_loss: 344.7034\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 300.7986 - val_loss: 333.3971\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 291.3613 - val_loss: 322.6299\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 5ms/step - loss: 282.5880 - val_loss: 312.6162\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 274.5396 - val_loss: 303.3644\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 266.9460 - val_loss: 294.7438\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 260.1447 - val_loss: 286.4021\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 253.4899 - val_loss: 279.4100\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 5ms/step - loss: 247.7375 - val_loss: 272.2698\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 242.2988 - val_loss: 265.9025\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 237.1738 - val_loss: 260.2232\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 232.4827 - val_loss: 254.6404\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 7ms/step - loss: 228.2137 - val_loss: 249.2194\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.9462 - val_loss: 244.8243\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 220.4091 - val_loss: 239.9191\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 216.8165 - val_loss: 236.0448\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 213.7066 - val_loss: 232.1147\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 210.7509 - val_loss: 228.5240\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.0409 - val_loss: 224.8982\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 5ms/step - loss: 205.3621 - val_loss: 221.9388\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.9736 - val_loss: 218.9640\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 5ms/step - loss: 200.7185 - val_loss: 216.1909\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 198.4982 - val_loss: 213.5878\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 196.3980 - val_loss: 211.1705\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.4543 - val_loss: 208.5255\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 192.6265 - val_loss: 206.1502\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 190.9451 - val_loss: 204.3949\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 8ms/step - loss: 189.3808 - val_loss: 202.0845\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 12ms/step - loss: 187.7875 - val_loss: 200.2547\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.3237 - val_loss: 198.4771\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 8ms/step - loss: 184.9464 - val_loss: 196.7887\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 11ms/step - loss: 183.5501 - val_loss: 194.9768\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 15ms/step - loss: 182.2353 - val_loss: 193.5329\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 12ms/step - loss: 180.9629 - val_loss: 191.8672\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 14ms/step - loss: 179.7841 - val_loss: 190.4194\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 178.7296 - val_loss: 189.2524\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 11ms/step - loss: 177.5965 - val_loss: 187.7868\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 176.5190 - val_loss: 186.6148\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 175.5331 - val_loss: 185.2845\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 174.5778 - val_loss: 184.0685\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 5ms/step - loss: 173.5542 - val_loss: 182.9688\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.6243 - val_loss: 181.8344\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.6824 - val_loss: 180.7733\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.7636 - val_loss: 179.5697\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.8581 - val_loss: 178.6084\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1573.5850 - val_loss: 1514.4791\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1557.8473 - val_loss: 1498.5952\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1542.3524 - val_loss: 1482.6848\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1526.7880 - val_loss: 1466.5729\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1510.9376 - val_loss: 1450.3026\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1495.1891 - val_loss: 1433.3441\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1478.6055 - val_loss: 1416.0637\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1461.6263 - val_loss: 1398.2277\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1443.9152 - val_loss: 1379.4432\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1425.3690 - val_loss: 1359.9672\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 1405.7627 - val_loss: 1339.6802\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1385.2921 - val_loss: 1318.1691\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1363.4502 - val_loss: 1296.1926\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 1340.9215 - val_loss: 1272.4949\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1316.3745 - val_loss: 1248.5339\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 7ms/step - loss: 1291.0684 - val_loss: 1223.0496\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 1264.3408 - val_loss: 1196.7875\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1236.5265 - val_loss: 1169.1323\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1207.5271 - val_loss: 1140.4675\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 1177.4365 - val_loss: 1111.0516\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1146.8765 - val_loss: 1080.8372\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1115.4403 - val_loss: 1050.4707\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 1083.2990 - val_loss: 1019.7297\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 1050.8928 - val_loss: 987.9124\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1017.9820 - val_loss: 956.2759\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 984.4332 - val_loss: 924.6409\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 951.1994 - val_loss: 892.2582\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 917.2336 - val_loss: 860.6470\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 883.4509 - val_loss: 828.5617\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 849.4670 - val_loss: 796.2454\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 815.2577 - val_loss: 764.1102\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 781.4125 - val_loss: 732.5714\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 748.4179 - val_loss: 701.4421\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 715.3696 - val_loss: 671.7216\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 683.3423 - val_loss: 641.6477\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 651.5584 - val_loss: 612.5841\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 620.7250 - val_loss: 584.2794\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 590.7158 - val_loss: 556.7825\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 562.3172 - val_loss: 530.5237\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 534.4119 - val_loss: 505.5576\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 508.0517 - val_loss: 481.3702\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 482.3779 - val_loss: 459.2171\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 458.7204 - val_loss: 437.4279\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 436.0676 - val_loss: 416.7722\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 414.4908 - val_loss: 398.3253\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 394.4340 - val_loss: 381.3126\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 376.1924 - val_loss: 364.3718\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 358.9522 - val_loss: 349.2931\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 342.8477 - val_loss: 335.4904\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 328.1997 - val_loss: 322.3430\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 314.6851 - val_loss: 310.7637\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 302.4022 - val_loss: 299.7984\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 290.8544 - val_loss: 290.0891\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 280.5467 - val_loss: 281.1013\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 271.1989 - val_loss: 272.8923\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 262.5748 - val_loss: 265.4148\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 254.7200 - val_loss: 258.2980\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 247.4892 - val_loss: 251.8669\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 240.7546 - val_loss: 245.9300\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 234.4954 - val_loss: 240.7578\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 228.9569 - val_loss: 235.5117\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 223.6834 - val_loss: 230.8113\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 5ms/step - loss: 218.8776 - val_loss: 226.7384\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 214.4970 - val_loss: 222.6617\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 210.2494 - val_loss: 219.0176\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 206.4616 - val_loss: 215.7506\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 203.0340 - val_loss: 212.4137\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 13ms/step - loss: 199.6374 - val_loss: 209.4208\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 196.6133 - val_loss: 206.7200\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.9124 - val_loss: 203.9046\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.0916 - val_loss: 201.1899\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.3891 - val_loss: 198.9540\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 13ms/step - loss: 186.1641 - val_loss: 196.8626\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 13ms/step - loss: 184.0296 - val_loss: 194.6593\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 15ms/step - loss: 181.8559 - val_loss: 192.6640\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 8ms/step - loss: 179.8702 - val_loss: 190.8086\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 11ms/step - loss: 178.0657 - val_loss: 189.0351\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.2131 - val_loss: 187.2398\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.5582 - val_loss: 185.5626\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.8967 - val_loss: 183.9453\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.4053 - val_loss: 182.4170\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.8765 - val_loss: 180.9885\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.4146 - val_loss: 179.5445\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.9041 - val_loss: 178.1854\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.5923 - val_loss: 176.6439\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.2655 - val_loss: 175.5028\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.0063 - val_loss: 174.1888\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.7098 - val_loss: 172.9496\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.4942 - val_loss: 171.7108\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 159.2855 - val_loss: 170.5511\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.0985 - val_loss: 169.2953\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.9798 - val_loss: 168.2785\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.7060 - val_loss: 166.9031\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.5551 - val_loss: 165.7566\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.3797 - val_loss: 164.6980\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.3564 - val_loss: 163.6151\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.2511 - val_loss: 162.5840\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.2654 - val_loss: 161.5577\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.1010 - val_loss: 160.5255\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.1111 - val_loss: 159.5891\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 43ms/step - loss: 1502.4176 - val_loss: 1452.5825\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1484.9663 - val_loss: 1434.6964\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1466.8547 - val_loss: 1415.8865\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 5ms/step - loss: 1447.1274 - val_loss: 1396.0250\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 5ms/step - loss: 1426.7845 - val_loss: 1374.4772\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1404.5828 - val_loss: 1351.9482\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1381.2905 - val_loss: 1327.8440\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1356.5193 - val_loss: 1302.3420\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1330.4392 - val_loss: 1275.5533\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1302.8900 - val_loss: 1247.2896\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 1273.8279 - val_loss: 1217.6477\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 1243.2719 - val_loss: 1186.7670\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 1211.2090 - val_loss: 1155.0533\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 1177.9291 - val_loss: 1121.9896\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1144.1010 - val_loss: 1086.9985\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1108.1311 - val_loss: 1052.7517\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1072.2277 - val_loss: 1017.5823\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 1035.6456 - val_loss: 981.7971\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 998.6080 - val_loss: 945.8228\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 960.8079 - val_loss: 910.3135\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 923.5659 - val_loss: 874.3221\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 886.1793 - val_loss: 838.2490\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 848.7455 - val_loss: 803.3076\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 811.9069 - val_loss: 769.1290\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 776.0751 - val_loss: 735.5148\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 740.7397 - val_loss: 702.6016\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 706.1414 - val_loss: 671.0031\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 672.8120 - val_loss: 640.2696\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 640.5046 - val_loss: 610.8681\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 609.7010 - val_loss: 582.2304\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 579.2521 - val_loss: 555.2927\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 550.6899 - val_loss: 529.6243\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 523.4310 - val_loss: 504.8567\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 497.5051 - val_loss: 481.3147\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 472.6706 - val_loss: 459.6656\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 449.6111 - val_loss: 439.1647\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 427.7700 - val_loss: 419.9532\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 407.4325 - val_loss: 401.4550\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 387.7796 - val_loss: 384.4551\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 370.1864 - val_loss: 368.4135\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 353.2086 - val_loss: 353.6685\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 337.4760 - val_loss: 340.3201\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 323.4519 - val_loss: 327.7228\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 310.3477 - val_loss: 316.1504\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 298.2907 - val_loss: 305.5270\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 7ms/step - loss: 287.2180 - val_loss: 295.7022\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 277.0340 - val_loss: 286.7891\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 267.6344 - val_loss: 278.5879\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 259.0896 - val_loss: 270.7941\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 251.4159 - val_loss: 263.5987\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 244.1264 - val_loss: 257.6553\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 237.5735 - val_loss: 251.9095\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 231.7750 - val_loss: 246.2687\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 226.2580 - val_loss: 241.2998\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 221.2980 - val_loss: 236.7893\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 7ms/step - loss: 216.6942 - val_loss: 232.7426\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 212.6638 - val_loss: 229.0593\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 8ms/step - loss: 208.6777 - val_loss: 225.3844\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 11ms/step - loss: 205.2802 - val_loss: 221.9729\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 201.8954 - val_loss: 219.1096\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 13ms/step - loss: 198.8686 - val_loss: 216.2865\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 11ms/step - loss: 195.9870 - val_loss: 213.4425\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 5ms/step - loss: 193.1993 - val_loss: 210.8000\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.6870 - val_loss: 208.4243\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 188.2773 - val_loss: 205.9879\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 186.0044 - val_loss: 203.7981\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 183.7646 - val_loss: 201.6645\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 181.7959 - val_loss: 199.5519\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.8220 - val_loss: 197.8276\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 177.8852 - val_loss: 195.9749\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.0901 - val_loss: 194.1859\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 174.3758 - val_loss: 192.4097\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.6686 - val_loss: 190.7637\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.1022 - val_loss: 189.2523\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.5731 - val_loss: 187.7959\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.0668 - val_loss: 186.5417\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 5ms/step - loss: 166.6757 - val_loss: 185.1540\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.2878 - val_loss: 184.0280\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 5ms/step - loss: 164.0204 - val_loss: 182.6306\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 162.7539 - val_loss: 181.4359\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.5574 - val_loss: 180.2690\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.3638 - val_loss: 178.9318\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.1836 - val_loss: 177.9787\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.2641 - val_loss: 177.2607\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.0833 - val_loss: 176.1166\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 156.1884 - val_loss: 175.2246\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 155.2781 - val_loss: 174.4265\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.4469 - val_loss: 173.6768\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.5810 - val_loss: 173.1129\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 152.7986 - val_loss: 172.2020\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.9530 - val_loss: 171.5643\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.1976 - val_loss: 170.7107\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.4269 - val_loss: 170.2689\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.8071 - val_loss: 169.4429\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 149.0162 - val_loss: 168.9004\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.3419 - val_loss: 168.3380\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 147.6984 - val_loss: 167.7426\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 7ms/step - loss: 146.9514 - val_loss: 167.1215\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.3194 - val_loss: 166.6423\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 145.6845 - val_loss: 166.1052\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1571.3750 - val_loss: 1550.0646\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1553.4436 - val_loss: 1532.2115\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1535.6366 - val_loss: 1514.1230\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1517.1663 - val_loss: 1495.8835\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 7ms/step - loss: 1498.4443 - val_loss: 1476.9142\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 1479.2103 - val_loss: 1457.2546\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 5ms/step - loss: 1458.8407 - val_loss: 1437.1975\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1437.8768 - val_loss: 1416.2631\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1415.6858 - val_loss: 1394.6814\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 1392.7855 - val_loss: 1371.6595\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 1368.7059 - val_loss: 1347.9976\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 1343.5839 - val_loss: 1323.7542\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1317.8755 - val_loss: 1298.0217\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 1290.9812 - val_loss: 1271.2732\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1262.7902 - val_loss: 1244.0598\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 1234.1016 - val_loss: 1215.9377\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1204.6788 - val_loss: 1186.9741\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 1173.8557 - val_loss: 1157.3816\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 5ms/step - loss: 1142.9821 - val_loss: 1126.7789\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 5ms/step - loss: 1110.9144 - val_loss: 1096.5958\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1079.0760 - val_loss: 1064.8345\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1045.7974 - val_loss: 1033.5336\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 1013.0675 - val_loss: 1001.5479\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 980.1555 - val_loss: 969.6225\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 5ms/step - loss: 946.6609 - val_loss: 937.8511\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 913.3670 - val_loss: 906.4206\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 880.4424 - val_loss: 874.7746\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 847.6629 - val_loss: 843.4307\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 815.2549 - val_loss: 812.5831\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 783.4793 - val_loss: 782.1849\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 751.6586 - val_loss: 753.0652\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 721.7795 - val_loss: 723.3372\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 691.5468 - val_loss: 695.7269\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 8ms/step - loss: 663.1819 - val_loss: 667.8519\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 10ms/step - loss: 634.8360 - val_loss: 642.0514\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 608.2903 - val_loss: 615.9739\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 582.1144 - val_loss: 591.7198\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 557.4479 - val_loss: 567.9471\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 13ms/step - loss: 533.7043 - val_loss: 545.3883\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 12ms/step - loss: 510.9084 - val_loss: 523.9117\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 489.4090 - val_loss: 503.1643\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 468.7719 - val_loss: 484.3940\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 14ms/step - loss: 449.8270 - val_loss: 465.5766\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 11ms/step - loss: 431.5560 - val_loss: 447.8939\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 11ms/step - loss: 414.4732 - val_loss: 431.4803\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 398.6106 - val_loss: 416.1365\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 383.6917 - val_loss: 401.5210\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 369.6557 - val_loss: 387.6078\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 356.4142 - val_loss: 374.7286\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 344.1577 - val_loss: 362.6740\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 332.7240 - val_loss: 351.3226\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 322.3228 - val_loss: 340.2894\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 7ms/step - loss: 312.3070 - val_loss: 330.2020\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 302.9765 - val_loss: 320.7702\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 7ms/step - loss: 294.3217 - val_loss: 312.0885\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 286.5456 - val_loss: 303.3129\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 278.9152 - val_loss: 295.6461\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 272.0318 - val_loss: 288.3561\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 265.4506 - val_loss: 281.4844\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 259.5994 - val_loss: 274.9311\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 253.8224 - val_loss: 268.9399\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 248.6122 - val_loss: 263.0001\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 243.4344 - val_loss: 257.8095\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 238.7328 - val_loss: 252.4379\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 234.2037 - val_loss: 247.3805\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 230.0610 - val_loss: 243.1250\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 225.8600 - val_loss: 238.5008\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.0370 - val_loss: 234.3259\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 218.3792 - val_loss: 230.6342\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 214.9887 - val_loss: 226.4212\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 211.5181 - val_loss: 222.8808\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 208.4133 - val_loss: 219.4688\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 7ms/step - loss: 205.3287 - val_loss: 216.2999\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.4239 - val_loss: 213.0891\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 199.7476 - val_loss: 210.0962\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.0378 - val_loss: 207.2920\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.4253 - val_loss: 204.8536\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 192.0778 - val_loss: 202.3007\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.7448 - val_loss: 199.8052\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 187.4175 - val_loss: 197.3080\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 185.2593 - val_loss: 194.7287\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.0815 - val_loss: 192.8184\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 180.9839 - val_loss: 190.4962\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 179.0476 - val_loss: 188.3927\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.0668 - val_loss: 186.4038\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 175.1417 - val_loss: 184.6429\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.2068 - val_loss: 182.6334\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.3558 - val_loss: 180.9637\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.5666 - val_loss: 179.1375\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.7477 - val_loss: 177.0961\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.0061 - val_loss: 175.3064\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.2506 - val_loss: 173.6005\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.5822 - val_loss: 172.2083\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.9049 - val_loss: 170.2463\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.2277 - val_loss: 168.8183\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.5944 - val_loss: 166.9943\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 155.9093 - val_loss: 165.5714\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 154.3617 - val_loss: 163.9512\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.8148 - val_loss: 162.3352\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 5ms/step - loss: 151.3555 - val_loss: 161.1044\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 1570.5304 - val_loss: 1623.0020\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 1553.7784 - val_loss: 1605.1111\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1536.9858 - val_loss: 1587.7528\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1520.6267 - val_loss: 1570.6788\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1504.6072 - val_loss: 1553.3304\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1488.3920 - val_loss: 1535.8339\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1471.9312 - val_loss: 1518.0557\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1455.0892 - val_loss: 1499.6674\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 5ms/step - loss: 1437.9172 - val_loss: 1480.4360\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1419.9927 - val_loss: 1460.6847\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1401.1484 - val_loss: 1440.4060\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1381.8914 - val_loss: 1418.6311\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 1361.5531 - val_loss: 1395.7952\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1340.2128 - val_loss: 1372.3975\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1318.3345 - val_loss: 1348.4277\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 7ms/step - loss: 1295.6674 - val_loss: 1323.7734\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 13ms/step - loss: 1272.5424 - val_loss: 1297.9641\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 8ms/step - loss: 1248.7999 - val_loss: 1271.3735\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 11ms/step - loss: 1224.0498 - val_loss: 1244.8485\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 13ms/step - loss: 1199.3467 - val_loss: 1217.0392\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1173.7177 - val_loss: 1189.6245\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 13ms/step - loss: 1148.0420 - val_loss: 1161.5187\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1122.0653 - val_loss: 1132.5111\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 1095.5125 - val_loss: 1103.8806\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1069.1820 - val_loss: 1074.6543\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 1042.2983 - val_loss: 1045.5856\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 8ms/step - loss: 1015.6473 - val_loss: 1016.1464\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 11ms/step - loss: 988.7502 - val_loss: 987.2953\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 962.3160 - val_loss: 957.8088\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 935.5001 - val_loss: 928.9066\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 908.8286 - val_loss: 900.3439\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 882.4753 - val_loss: 871.6333\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 856.3807 - val_loss: 843.0213\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 830.0274 - val_loss: 816.1486\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 804.9189 - val_loss: 788.3888\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 779.5591 - val_loss: 761.2723\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 754.6074 - val_loss: 735.2917\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 730.4044 - val_loss: 709.2045\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 706.5144 - val_loss: 683.6791\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 683.0851 - val_loss: 658.9149\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 660.1748 - val_loss: 634.1245\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 637.4808 - val_loss: 610.6023\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 615.5200 - val_loss: 587.6829\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 594.1573 - val_loss: 565.5187\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 573.2682 - val_loss: 543.5281\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 552.6765 - val_loss: 522.4451\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 532.9769 - val_loss: 501.7423\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 7ms/step - loss: 513.3646 - val_loss: 481.9866\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 494.3898 - val_loss: 462.8418\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 476.1637 - val_loss: 444.2589\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 458.1371 - val_loss: 427.0086\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 5ms/step - loss: 440.8032 - val_loss: 410.2770\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 424.4046 - val_loss: 393.6833\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 408.1518 - val_loss: 378.5410\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 392.8025 - val_loss: 364.0712\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 377.9333 - val_loss: 350.7090\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 364.4447 - val_loss: 337.4966\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 350.8169 - val_loss: 326.0700\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 7ms/step - loss: 338.6163 - val_loss: 314.4563\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 326.5544 - val_loss: 304.2738\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 315.7579 - val_loss: 294.6721\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 305.2767 - val_loss: 285.9868\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 295.3046 - val_loss: 278.2961\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 286.7367 - val_loss: 270.4921\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 278.0478 - val_loss: 263.8651\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 270.2234 - val_loss: 257.8003\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 263.1078 - val_loss: 252.1687\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 256.0448 - val_loss: 247.4101\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 5ms/step - loss: 249.8881 - val_loss: 242.9121\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 244.1787 - val_loss: 238.7381\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 238.7911 - val_loss: 235.0676\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 233.9287 - val_loss: 231.4029\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 228.9983 - val_loss: 228.3076\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 224.7103 - val_loss: 225.6115\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 220.7749 - val_loss: 222.9766\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 5ms/step - loss: 217.0818 - val_loss: 220.6422\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 213.6200 - val_loss: 218.4683\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 7ms/step - loss: 210.3690 - val_loss: 216.4107\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 207.3900 - val_loss: 214.4878\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.4711 - val_loss: 212.8547\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 201.8926 - val_loss: 211.1913\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.2933 - val_loss: 209.6841\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 196.9574 - val_loss: 208.1203\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 194.7773 - val_loss: 206.8637\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 5ms/step - loss: 192.7100 - val_loss: 205.5523\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.7313 - val_loss: 204.3989\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.9006 - val_loss: 203.1889\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 187.1855 - val_loss: 202.0558\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 185.4876 - val_loss: 200.9977\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 183.8543 - val_loss: 199.8220\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.3201 - val_loss: 198.6657\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 5ms/step - loss: 180.7614 - val_loss: 197.4933\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.3191 - val_loss: 196.4549\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 177.9468 - val_loss: 195.5162\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 176.6844 - val_loss: 194.3050\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 175.3480 - val_loss: 193.1876\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 174.0463 - val_loss: 192.1330\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.7945 - val_loss: 190.9391\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 171.6119 - val_loss: 189.8762\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 5ms/step - loss: 170.3791 - val_loss: 188.8543\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 45ms/step - loss: 1556.7764 - val_loss: 1599.7195\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 19ms/step - loss: 1539.3776 - val_loss: 1581.3392\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 7ms/step - loss: 1522.5001 - val_loss: 1563.0110\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 13ms/step - loss: 1505.5544 - val_loss: 1545.0062\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1488.8392 - val_loss: 1526.6218\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 13ms/step - loss: 1471.7781 - val_loss: 1508.1547\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 13ms/step - loss: 1454.1870 - val_loss: 1489.3588\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 7ms/step - loss: 1436.2247 - val_loss: 1469.6194\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 11ms/step - loss: 1417.4553 - val_loss: 1449.6725\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 1398.2427 - val_loss: 1428.6973\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 1378.0853 - val_loss: 1407.0238\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 1357.2417 - val_loss: 1384.7185\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 1335.5940 - val_loss: 1361.3688\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 5ms/step - loss: 1313.0845 - val_loss: 1337.3285\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 1289.8417 - val_loss: 1312.1405\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1265.5609 - val_loss: 1286.3816\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 1240.2858 - val_loss: 1259.3661\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1214.3356 - val_loss: 1231.3483\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1187.2958 - val_loss: 1203.0131\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1159.6715 - val_loss: 1173.8667\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1131.2157 - val_loss: 1143.8141\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1101.9882 - val_loss: 1112.3959\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1071.6570 - val_loss: 1080.6891\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1041.2008 - val_loss: 1048.0054\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 7ms/step - loss: 1009.8296 - val_loss: 1014.8707\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 978.0243 - val_loss: 980.8652\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 945.7180 - val_loss: 946.8286\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 5ms/step - loss: 913.4388 - val_loss: 912.3851\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 5ms/step - loss: 881.4001 - val_loss: 877.5380\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 848.7603 - val_loss: 844.3297\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 817.1965 - val_loss: 810.7458\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 785.7778 - val_loss: 777.8339\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 5ms/step - loss: 754.9022 - val_loss: 745.0894\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 724.4950 - val_loss: 713.3598\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 694.8235 - val_loss: 682.3382\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 666.1485 - val_loss: 651.7006\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 637.6634 - val_loss: 623.1736\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 610.7230 - val_loss: 595.5983\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 585.0055 - val_loss: 568.2552\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 559.7490 - val_loss: 542.9387\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 535.9471 - val_loss: 517.9203\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 513.0486 - val_loss: 494.2865\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 491.1602 - val_loss: 472.0685\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 5ms/step - loss: 470.5497 - val_loss: 451.3216\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 451.2216 - val_loss: 431.4647\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 432.6170 - val_loss: 412.8466\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 415.2182 - val_loss: 395.6476\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 399.2134 - val_loss: 378.9366\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 5ms/step - loss: 383.9159 - val_loss: 363.6225\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 369.5628 - val_loss: 349.9774\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 356.3860 - val_loss: 336.8206\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 344.1619 - val_loss: 324.2438\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 332.6552 - val_loss: 313.0691\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 322.0466 - val_loss: 302.6818\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 312.2449 - val_loss: 292.9963\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 303.0901 - val_loss: 284.3062\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 294.6736 - val_loss: 276.3703\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 286.9854 - val_loss: 268.9701\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 5ms/step - loss: 279.6389 - val_loss: 262.2025\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 273.0296 - val_loss: 255.8360\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 266.8263 - val_loss: 250.2166\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 261.2744 - val_loss: 244.8122\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 255.9910 - val_loss: 239.9261\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 5ms/step - loss: 251.1033 - val_loss: 235.5730\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 246.7532 - val_loss: 231.4591\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 242.5833 - val_loss: 227.7025\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 5ms/step - loss: 238.6955 - val_loss: 224.1795\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 235.0971 - val_loss: 220.8509\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 231.5747 - val_loss: 217.7666\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 228.4057 - val_loss: 214.8447\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 225.2364 - val_loss: 212.4185\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.3985 - val_loss: 209.5852\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.6550 - val_loss: 207.1542\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 217.1274 - val_loss: 204.8659\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 5ms/step - loss: 214.5012 - val_loss: 202.7212\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 5ms/step - loss: 212.1522 - val_loss: 200.5698\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 209.9221 - val_loss: 198.4596\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 207.5668 - val_loss: 196.4534\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.4202 - val_loss: 194.5195\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 203.2306 - val_loss: 192.5257\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 201.1433 - val_loss: 190.5857\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 199.0357 - val_loss: 188.8518\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 5ms/step - loss: 197.0731 - val_loss: 186.9473\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 195.1766 - val_loss: 185.1551\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.2083 - val_loss: 183.5137\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 191.2833 - val_loss: 181.6992\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 189.4038 - val_loss: 179.9368\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.5931 - val_loss: 178.2978\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.7799 - val_loss: 176.7220\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 14ms/step - loss: 184.0278 - val_loss: 175.1910\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 5ms/step - loss: 182.3365 - val_loss: 173.4389\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.6075 - val_loss: 171.8147\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.8780 - val_loss: 170.1941\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.1653 - val_loss: 168.8288\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 175.5970 - val_loss: 167.2816\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.8682 - val_loss: 165.7706\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 172.3713 - val_loss: 164.2836\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.8411 - val_loss: 162.9713\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.2657 - val_loss: 161.5573\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 7ms/step - loss: 167.8304 - val_loss: 160.1225\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 58ms/step - loss: 1553.2290 - val_loss: 1530.0328\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 1535.6031 - val_loss: 1513.0237\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1518.0952 - val_loss: 1495.2233\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 5ms/step - loss: 1500.1547 - val_loss: 1477.2649\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1481.5671 - val_loss: 1459.1051\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1462.2753 - val_loss: 1440.0546\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1442.0992 - val_loss: 1419.8500\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1420.8414 - val_loss: 1398.8835\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1398.9707 - val_loss: 1376.5557\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 1375.6865 - val_loss: 1353.2914\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 1351.2812 - val_loss: 1328.9484\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 1325.6560 - val_loss: 1303.5380\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 1299.1429 - val_loss: 1277.1182\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 1271.9954 - val_loss: 1249.2780\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1242.9362 - val_loss: 1221.1635\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1213.6499 - val_loss: 1191.3815\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 1182.6460 - val_loss: 1161.5889\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 1151.6178 - val_loss: 1129.2827\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1118.5516 - val_loss: 1096.8087\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 1084.8044 - val_loss: 1062.7922\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1049.8469 - val_loss: 1027.5649\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1013.6293 - val_loss: 992.1711\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 977.1527 - val_loss: 955.2728\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 939.4364 - val_loss: 918.2883\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 7ms/step - loss: 902.0636 - val_loss: 879.8687\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 863.7820 - val_loss: 842.8539\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 825.9348 - val_loss: 805.8453\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 788.6929 - val_loss: 768.6780\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 751.5184 - val_loss: 732.5475\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 715.3804 - val_loss: 696.9648\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 680.0067 - val_loss: 662.6448\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 645.8392 - val_loss: 629.1506\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 5ms/step - loss: 612.9851 - val_loss: 597.2336\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 581.4852 - val_loss: 566.2390\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 550.8193 - val_loss: 537.0772\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 522.0081 - val_loss: 508.8137\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 494.6442 - val_loss: 482.1913\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 468.8758 - val_loss: 456.9116\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 444.1299 - val_loss: 433.7873\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 421.1996 - val_loss: 412.0235\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 399.7747 - val_loss: 391.1486\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 379.8062 - val_loss: 371.8727\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 361.2096 - val_loss: 354.0126\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 344.0298 - val_loss: 337.6578\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 328.1950 - val_loss: 322.7676\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 313.8103 - val_loss: 308.8454\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 300.6857 - val_loss: 296.0822\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 288.5027 - val_loss: 284.5580\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 277.6445 - val_loss: 273.8316\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 267.2146 - val_loss: 264.7285\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 258.2611 - val_loss: 255.7206\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 249.8574 - val_loss: 247.8348\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 242.3748 - val_loss: 240.5574\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 235.5129 - val_loss: 233.9210\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 229.3055 - val_loss: 228.0802\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.6867 - val_loss: 222.9148\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 218.7113 - val_loss: 218.0450\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 213.9919 - val_loss: 213.9472\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 209.9674 - val_loss: 209.8536\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 206.1720 - val_loss: 206.3138\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.8035 - val_loss: 202.9710\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 7ms/step - loss: 199.6406 - val_loss: 199.8662\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 196.7139 - val_loss: 197.2424\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.0643 - val_loss: 195.0279\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 191.6289 - val_loss: 192.6760\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 189.3605 - val_loss: 190.3749\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 7ms/step - loss: 187.1435 - val_loss: 188.4844\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 185.1398 - val_loss: 186.6795\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.3476 - val_loss: 184.9118\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 181.5677 - val_loss: 183.3594\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 179.9797 - val_loss: 181.7477\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 7ms/step - loss: 178.3911 - val_loss: 180.5156\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 176.9311 - val_loss: 179.1314\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 175.6185 - val_loss: 177.9440\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.2694 - val_loss: 176.6461\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.9680 - val_loss: 175.5532\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.7935 - val_loss: 174.4326\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 8ms/step - loss: 170.6236 - val_loss: 173.4305\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 13ms/step - loss: 169.5782 - val_loss: 172.4415\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.4319 - val_loss: 171.4772\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.4979 - val_loss: 170.4326\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.3801 - val_loss: 169.6563\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 165.4909 - val_loss: 168.7153\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.5804 - val_loss: 167.8792\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 7ms/step - loss: 163.5452 - val_loss: 166.9815\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.5798 - val_loss: 166.2150\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.7713 - val_loss: 165.3873\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.8751 - val_loss: 164.5773\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 13ms/step - loss: 160.0337 - val_loss: 163.8319\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.1981 - val_loss: 163.0781\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 9ms/step - loss: 158.3325 - val_loss: 162.3534\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 10ms/step - loss: 157.5315 - val_loss: 161.6313\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 156.7345 - val_loss: 160.9941\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.0145 - val_loss: 160.3017\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.2400 - val_loss: 159.6208\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 7ms/step - loss: 154.4693 - val_loss: 158.9608\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.7977 - val_loss: 158.3058\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.0273 - val_loss: 157.6198\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 152.3074 - val_loss: 157.0005\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.6339 - val_loss: 156.3249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the mean and standard deviation of the mean squared errors\n",
        "mean_mse = np.mean(mean_squared_errors)\n",
        "std_mse = np.std(mean_squared_errors)\n",
        "\n",
        "print(\"Mean of Mean Squared Errors: {}\".format(mean_mse))\n",
        "print(\"Standard Deviation of Mean Squared Errors: {}\".format(std_mse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFxyCVr4ZmiJ",
        "outputId": "4b460100-6165-433c-fb3d-f1c053ba21f0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of Mean Squared Errors: 166.13418518066408\n",
            "Standard Deviation of Mean Squared Errors: 21.988124298575194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**D. Increase the no. of hidden layers**"
      ],
      "metadata": {
        "id": "fKJMB5Szd0Ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = data.drop('Strength' ,axis=1)\n",
        "target = data['Strength']\n",
        "\n",
        "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
        "predictors_norm.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Mevy49Wnd-mV",
        "outputId": "8c771312-43f8-4a27-9181-083065f3acfe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
              "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
              "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
              "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
              "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
              "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
              "\n",
              "   Coarse Aggregate  Fine Aggregate       Age  \n",
              "0          0.862735       -1.217079 -0.279597  \n",
              "1          1.055651       -1.217079 -0.279597  \n",
              "2         -0.526262       -2.239829  3.551340  \n",
              "3         -0.526262       -2.239829  5.055221  \n",
              "4          0.070492        0.647569  4.976069  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0bf80086-90bf-4def-8544-70a68a6249fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>0.862735</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>1.055651</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>3.551340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>5.055221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.790075</td>\n",
              "      <td>0.678079</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>0.488555</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>0.070492</td>\n",
              "      <td>0.647569</td>\n",
              "      <td>4.976069</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bf80086-90bf-4def-8544-70a68a6249fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0bf80086-90bf-4def-8544-70a68a6249fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0bf80086-90bf-4def-8544-70a68a6249fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0bafeaaf-f46c-4e0b-adaf-912b24492088\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0bafeaaf-f46c-4e0b-adaf-912b24492088')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0bafeaaf-f46c-4e0b-adaf-912b24492088 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "predictors_norm",
              "summary": "{\n  \"name\": \"predictors_norm\",\n  \"rows\": 1030,\n  \"fields\": [\n    {\n      \"column\": \"Cement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -1.7144205995851924,\n        \"max\": 2.476711702426229,\n        \"num_unique_values\": 278,\n        \"samples\": [\n          0.5428581904707304,\n          0.08642665895030859,\n          -0.18341336597371433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blast Furnace Slag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9999999999999999,\n        \"min\": -0.8564718244890963,\n        \"max\": 3.3090676049756658,\n        \"num_unique_values\": 185,\n        \"samples\": [\n          0.24112579368094536,\n          0.5227691106981788,\n          0.7232806079985139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fly Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -0.8467325968146493,\n        \"max\": 2.2799762647844055,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          0.6845890845282162,\n          1.3721212679882784,\n          2.200285034428808\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Water\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.798851260765261,\n        \"max\": 3.064158880238681,\n        \"num_unique_values\": 195,\n        \"samples\": [\n          0.647774509026194,\n          0.1045563170481933,\n          -2.541290911120519\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Superplasticizer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -1.0386382541022239,\n        \"max\": 4.351528287732031,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          1.4723088927149754,\n          3.681942381914111,\n          1.7234036073966954\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coarse Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.211063531411115,\n        \"max\": 2.213148774849662,\n        \"num_unique_values\": 284,\n        \"samples\": [\n          -1.553862226614819,\n          -0.7590473413621567,\n          -0.7577612331335922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fine Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.239829000131109,\n        \"max\": 2.7317347935640552,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          -0.7930116391962395,\n          -0.9751110656587321,\n          -0.05338862623556972\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -0.7070159638428309,\n        \"max\": 5.055221007679151,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.7177129576873293,\n          0.8601858498403454,\n          -0.27959728738378287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define regression model with 3 hidden layers with 10 nodes each\n",
        "def regression_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "    # create model\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  return model"
      ],
      "metadata": {
        "id": "X16FDrzSeEVw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_cols = predictors_norm.shape[1] # number of predictors\n",
        "mean_squared_errors = []\n",
        "\n",
        "for i in range(50):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(predictors_norm, target, test_size = 0.3, random_state = 1)\n",
        "    model = regression_model()\n",
        "    model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50, verbose=2)\n",
        "    mse = model.evaluate(x_test, y_test, verbose=0)\n",
        "    mean_squared_errors.append(mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GryL7Pphep0y",
        "outputId": "83e59cd8-f199-489e-df3b-3efae3d14e50"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 50ms/step - loss: 1546.0913 - val_loss: 1572.9220\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 5ms/step - loss: 1525.5540 - val_loss: 1550.9110\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 5ms/step - loss: 1502.7925 - val_loss: 1524.4172\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1474.1895 - val_loss: 1491.1025\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1436.8556 - val_loss: 1448.2728\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 7ms/step - loss: 1389.2594 - val_loss: 1393.0293\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1328.6954 - val_loss: 1324.1312\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1252.5530 - val_loss: 1238.1884\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1159.9634 - val_loss: 1138.3992\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1054.2446 - val_loss: 1021.8716\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 934.7495 - val_loss: 900.0038\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 811.4103 - val_loss: 777.2928\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 690.6212 - val_loss: 658.8425\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 576.1733 - val_loss: 554.3666\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 476.6120 - val_loss: 470.2480\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 395.3647 - val_loss: 406.8760\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 334.5836 - val_loss: 359.6938\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 288.5212 - val_loss: 329.2097\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 7ms/step - loss: 257.7532 - val_loss: 306.9309\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 236.3176 - val_loss: 290.7848\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 220.0428 - val_loss: 276.5901\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 8ms/step - loss: 207.7966 - val_loss: 265.6104\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 198.1859 - val_loss: 256.4851\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 190.3042 - val_loss: 246.6232\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 183.7102 - val_loss: 239.4181\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 178.1820 - val_loss: 232.0638\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 5ms/step - loss: 173.7464 - val_loss: 227.2353\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 169.9272 - val_loss: 221.4273\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.4469 - val_loss: 216.0936\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 7ms/step - loss: 163.3104 - val_loss: 212.3446\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 160.5686 - val_loss: 208.1912\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 158.1150 - val_loss: 205.4393\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 155.7519 - val_loss: 202.1404\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 153.8296 - val_loss: 199.6613\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 151.8913 - val_loss: 195.4701\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.1490 - val_loss: 193.7458\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 148.6064 - val_loss: 192.3573\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 146.9143 - val_loss: 188.6267\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.3144 - val_loss: 187.5103\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 143.9706 - val_loss: 185.7734\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.5092 - val_loss: 184.3010\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 5ms/step - loss: 141.3373 - val_loss: 182.2524\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 140.3121 - val_loss: 179.7277\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 139.0500 - val_loss: 178.2598\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 138.1426 - val_loss: 177.8254\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 137.3569 - val_loss: 175.7393\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 136.4965 - val_loss: 175.0131\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 135.7186 - val_loss: 174.0146\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 134.7111 - val_loss: 172.5979\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 133.7253 - val_loss: 170.0407\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 52ms/step - loss: 1550.4727 - val_loss: 1580.2909\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1536.5227 - val_loss: 1565.1477\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 1520.4213 - val_loss: 1547.1512\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 5ms/step - loss: 1500.3234 - val_loss: 1523.7316\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1474.4690 - val_loss: 1494.7551\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1442.1891 - val_loss: 1458.3243\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1401.3351 - val_loss: 1411.8353\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 8ms/step - loss: 1349.1979 - val_loss: 1352.9182\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1286.1066 - val_loss: 1282.4113\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 9ms/step - loss: 1211.9609 - val_loss: 1200.0742\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 11ms/step - loss: 1127.0853 - val_loss: 1108.7552\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 13ms/step - loss: 1034.9210 - val_loss: 1007.6804\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 13ms/step - loss: 932.9119 - val_loss: 898.6230\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 824.3981 - val_loss: 783.4949\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 13ms/step - loss: 713.5386 - val_loss: 670.6075\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 13ms/step - loss: 606.0826 - val_loss: 562.7405\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 507.3035 - val_loss: 469.5191\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 12ms/step - loss: 422.4552 - val_loss: 396.2768\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 357.2629 - val_loss: 341.8447\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 308.6837 - val_loss: 308.4405\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 276.0999 - val_loss: 288.5780\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 255.0840 - val_loss: 276.2802\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 240.1711 - val_loss: 268.0263\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 229.3602 - val_loss: 261.5744\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 220.3020 - val_loss: 256.1976\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 213.0240 - val_loss: 251.5525\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 206.2479 - val_loss: 244.6175\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 199.8359 - val_loss: 239.8207\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 194.3340 - val_loss: 234.8672\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 189.4634 - val_loss: 231.2487\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 184.6620 - val_loss: 226.5577\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 180.4132 - val_loss: 222.1208\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 176.2767 - val_loss: 218.9203\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 172.6680 - val_loss: 215.8192\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 169.2660 - val_loss: 212.1998\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.1093 - val_loss: 209.1067\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 163.4170 - val_loss: 205.7902\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 160.9200 - val_loss: 203.2434\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 158.6508 - val_loss: 200.0261\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 156.2867 - val_loss: 198.2728\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 154.2672 - val_loss: 196.5405\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 152.5237 - val_loss: 194.6337\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 150.4891 - val_loss: 192.8770\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 148.7926 - val_loss: 191.1899\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 147.4043 - val_loss: 190.7431\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 145.9560 - val_loss: 187.9104\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.7153 - val_loss: 186.5331\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 143.6710 - val_loss: 185.1143\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 7ms/step - loss: 142.4870 - val_loss: 184.1166\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.7095 - val_loss: 181.4222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "23/23 - 1s - 58ms/step - loss: 1566.7020 - val_loss: 1596.3625\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 6ms/step - loss: 1550.9733 - val_loss: 1581.4098\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 1537.1141 - val_loss: 1567.6548\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1523.1530 - val_loss: 1552.4968\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1506.9065 - val_loss: 1533.5356\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 5ms/step - loss: 1485.9648 - val_loss: 1509.4802\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 7ms/step - loss: 1459.4888 - val_loss: 1477.3790\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 5ms/step - loss: 1424.5848 - val_loss: 1436.4689\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1380.9233 - val_loss: 1384.8101\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1326.4176 - val_loss: 1321.5988\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1258.6779 - val_loss: 1245.2520\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 1177.2139 - val_loss: 1148.9037\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1077.3877 - val_loss: 1038.8475\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 5ms/step - loss: 963.5605 - val_loss: 912.0682\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 7ms/step - loss: 835.2346 - val_loss: 775.8652\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 5ms/step - loss: 700.0086 - val_loss: 639.2155\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 567.1583 - val_loss: 515.0461\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 447.5766 - val_loss: 417.1502\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 353.7560 - val_loss: 347.6654\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 288.2707 - val_loss: 306.6985\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 13ms/step - loss: 247.5219 - val_loss: 283.4338\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 12ms/step - loss: 223.4837 - val_loss: 268.8084\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 13ms/step - loss: 208.4697 - val_loss: 256.3159\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 197.9528 - val_loss: 246.9792\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 7ms/step - loss: 190.2588 - val_loss: 239.5743\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 13ms/step - loss: 184.0325 - val_loss: 231.7298\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 14ms/step - loss: 179.1745 - val_loss: 226.5125\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 12ms/step - loss: 175.0730 - val_loss: 220.6076\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 11ms/step - loss: 171.5503 - val_loss: 216.9612\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 168.4595 - val_loss: 212.1705\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 165.6857 - val_loss: 209.3207\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 163.2076 - val_loss: 206.1949\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 5ms/step - loss: 161.3031 - val_loss: 204.0335\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 159.4581 - val_loss: 201.5171\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 158.0436 - val_loss: 199.5079\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 156.4164 - val_loss: 198.0519\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 155.0149 - val_loss: 196.6808\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 153.7706 - val_loss: 195.2895\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 152.4602 - val_loss: 193.0015\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 151.5063 - val_loss: 191.3553\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.5116 - val_loss: 190.0805\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.2590 - val_loss: 188.8212\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 5ms/step - loss: 148.2866 - val_loss: 187.3484\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 5ms/step - loss: 147.4192 - val_loss: 185.9407\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 146.3144 - val_loss: 184.6691\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.5051 - val_loss: 184.3265\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.6038 - val_loss: 182.5457\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 5ms/step - loss: 143.9381 - val_loss: 181.5583\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.9833 - val_loss: 180.5939\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.1640 - val_loss: 179.4815\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 55ms/step - loss: 1551.2994 - val_loss: 1582.1373\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 6ms/step - loss: 1533.0044 - val_loss: 1561.5291\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1511.3821 - val_loss: 1536.0208\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 5ms/step - loss: 1483.9863 - val_loss: 1502.3409\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1448.0895 - val_loss: 1457.2229\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1398.0865 - val_loss: 1394.8990\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1329.8331 - val_loss: 1312.6848\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1240.1245 - val_loss: 1206.8669\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1127.9314 - val_loss: 1076.9546\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 994.9144 - val_loss: 932.5737\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 5ms/step - loss: 849.8087 - val_loss: 779.1028\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 699.6862 - val_loss: 630.4362\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 560.0819 - val_loss: 498.6428\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 5ms/step - loss: 439.9011 - val_loss: 397.1628\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 7ms/step - loss: 348.3284 - val_loss: 326.5219\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 5ms/step - loss: 283.6147 - val_loss: 282.1709\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 243.2340 - val_loss: 257.2213\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 219.4592 - val_loss: 243.0131\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 204.9401 - val_loss: 234.3418\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 195.8720 - val_loss: 227.6479\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 189.1211 - val_loss: 221.7854\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 184.0044 - val_loss: 217.3569\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 179.7162 - val_loss: 213.5807\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 5ms/step - loss: 176.7363 - val_loss: 210.4168\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 173.2160 - val_loss: 207.2531\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 170.6861 - val_loss: 204.4604\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 168.2306 - val_loss: 201.5914\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.1175 - val_loss: 199.0672\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 163.9127 - val_loss: 197.5955\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 162.0402 - val_loss: 194.8544\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 160.1403 - val_loss: 192.8011\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 158.4606 - val_loss: 190.7448\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 156.9620 - val_loss: 189.5574\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 155.2462 - val_loss: 187.4434\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 153.7346 - val_loss: 185.9423\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 152.4325 - val_loss: 185.5967\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.9263 - val_loss: 183.3715\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.4842 - val_loss: 182.2971\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.4207 - val_loss: 180.9014\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 147.3076 - val_loss: 180.5369\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.7015 - val_loss: 178.8381\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 5ms/step - loss: 144.5797 - val_loss: 177.1763\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 7ms/step - loss: 143.7421 - val_loss: 175.9491\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 11ms/step - loss: 142.6366 - val_loss: 176.4778\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.4808 - val_loss: 173.6707\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 13ms/step - loss: 140.3883 - val_loss: 173.6472\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 139.3732 - val_loss: 172.2213\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 13ms/step - loss: 138.4013 - val_loss: 171.5868\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 16ms/step - loss: 137.8235 - val_loss: 171.9121\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 8ms/step - loss: 136.6775 - val_loss: 169.6009\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 56ms/step - loss: 1540.8239 - val_loss: 1570.6053\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1519.4043 - val_loss: 1547.8925\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1495.8948 - val_loss: 1522.5801\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 7ms/step - loss: 1468.5944 - val_loss: 1492.1469\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1435.3522 - val_loss: 1454.5977\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1393.9401 - val_loss: 1407.3826\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1341.6028 - val_loss: 1349.0137\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1276.1371 - val_loss: 1275.7521\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 1196.5358 - val_loss: 1187.2455\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 5ms/step - loss: 1102.8673 - val_loss: 1085.2236\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 995.9000 - val_loss: 970.5733\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 879.7145 - val_loss: 848.5215\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 7ms/step - loss: 759.9174 - val_loss: 725.6289\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 5ms/step - loss: 641.8203 - val_loss: 610.8024\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 5ms/step - loss: 534.4709 - val_loss: 507.5904\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 442.0412 - val_loss: 423.7889\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 369.5794 - val_loss: 360.4374\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 315.9312 - val_loss: 315.2596\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 7ms/step - loss: 277.6198 - val_loss: 288.2100\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 252.3675 - val_loss: 270.4720\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 236.2323 - val_loss: 257.8770\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 224.0055 - val_loss: 249.8392\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 215.5166 - val_loss: 243.9327\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 208.7961 - val_loss: 238.4413\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 202.5305 - val_loss: 233.8752\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 197.6548 - val_loss: 229.7109\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 193.0378 - val_loss: 225.8066\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 188.7324 - val_loss: 222.4039\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 184.9235 - val_loss: 218.8703\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 181.2374 - val_loss: 215.1717\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 177.9519 - val_loss: 212.4173\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 174.7070 - val_loss: 209.5426\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 171.6168 - val_loss: 206.7839\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 168.6320 - val_loss: 204.5230\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 165.8930 - val_loss: 201.4314\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 7ms/step - loss: 163.3112 - val_loss: 199.0103\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 160.6600 - val_loss: 196.2263\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 158.3757 - val_loss: 193.7079\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 156.1824 - val_loss: 191.2290\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 154.1775 - val_loss: 188.8445\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 5ms/step - loss: 151.9340 - val_loss: 186.7325\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 5ms/step - loss: 150.1099 - val_loss: 184.9164\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.1637 - val_loss: 182.2584\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 5ms/step - loss: 146.3661 - val_loss: 180.9704\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 144.5410 - val_loss: 179.1621\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 142.9577 - val_loss: 177.2941\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.4918 - val_loss: 175.3418\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.1192 - val_loss: 174.3811\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 138.6476 - val_loss: 172.7059\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 137.3667 - val_loss: 171.7204\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 53ms/step - loss: 1526.1332 - val_loss: 1553.0507\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1502.5620 - val_loss: 1528.5353\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1475.4745 - val_loss: 1499.5955\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1441.9789 - val_loss: 1461.8760\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 5ms/step - loss: 1399.3234 - val_loss: 1414.0298\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1346.3788 - val_loss: 1356.6230\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1283.4308 - val_loss: 1289.5227\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1211.2262 - val_loss: 1212.4271\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 9ms/step - loss: 1129.6743 - val_loss: 1130.2863\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1042.9565 - val_loss: 1042.4963\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 15ms/step - loss: 951.6038 - val_loss: 954.1367\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 10ms/step - loss: 861.8799 - val_loss: 867.4514\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 13ms/step - loss: 775.4814 - val_loss: 786.5963\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 13ms/step - loss: 696.4291 - val_loss: 711.3554\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 13ms/step - loss: 622.5101 - val_loss: 644.1754\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 14ms/step - loss: 555.6458 - val_loss: 580.0037\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 496.0580 - val_loss: 521.6880\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 441.7946 - val_loss: 468.0129\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 392.3148 - val_loss: 417.2653\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 348.0703 - val_loss: 369.7063\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 308.3551 - val_loss: 328.2469\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 274.8665 - val_loss: 293.0313\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 247.2090 - val_loss: 266.7300\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 226.3349 - val_loss: 247.7080\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 210.8743 - val_loss: 234.2925\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 199.3858 - val_loss: 224.9978\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 191.1530 - val_loss: 218.5860\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 185.1068 - val_loss: 213.6850\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 180.1423 - val_loss: 210.0390\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 176.0768 - val_loss: 206.3279\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 172.6215 - val_loss: 202.7534\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 169.6357 - val_loss: 200.1214\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.9214 - val_loss: 197.5065\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 164.3170 - val_loss: 194.7927\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 161.6440 - val_loss: 191.7599\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 7ms/step - loss: 159.4160 - val_loss: 189.2273\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 157.3047 - val_loss: 187.4171\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 155.1122 - val_loss: 184.9130\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 153.3429 - val_loss: 182.1729\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 151.4232 - val_loss: 180.6880\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 149.7558 - val_loss: 178.4295\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 148.1536 - val_loss: 177.2232\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.5452 - val_loss: 175.5974\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 145.1732 - val_loss: 174.0219\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 143.6194 - val_loss: 172.8467\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 142.6631 - val_loss: 170.2743\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 140.8285 - val_loss: 169.3895\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 139.7634 - val_loss: 168.4994\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 138.5137 - val_loss: 166.8506\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.4686 - val_loss: 164.7275\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 54ms/step - loss: 1547.1952 - val_loss: 1575.4065\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1532.3972 - val_loss: 1558.0713\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1514.8771 - val_loss: 1537.0015\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1492.3710 - val_loss: 1508.6298\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1461.9336 - val_loss: 1471.2250\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1421.2507 - val_loss: 1421.3333\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1368.4763 - val_loss: 1359.6465\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 5ms/step - loss: 1303.9379 - val_loss: 1284.0244\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 5ms/step - loss: 1225.8976 - val_loss: 1194.2939\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1134.2728 - val_loss: 1092.0135\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1030.5438 - val_loss: 978.5543\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 918.0763 - val_loss: 857.4622\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 799.2968 - val_loss: 736.3424\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 681.5483 - val_loss: 619.2916\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 7ms/step - loss: 570.0163 - val_loss: 510.6937\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 5ms/step - loss: 467.8808 - val_loss: 422.7171\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 387.2410 - val_loss: 349.7870\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 320.2165 - val_loss: 300.2849\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 272.9375 - val_loss: 268.0152\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 240.7556 - val_loss: 247.4948\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 218.9511 - val_loss: 234.9774\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 7ms/step - loss: 204.3571 - val_loss: 228.1593\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 194.9450 - val_loss: 223.2380\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 187.8356 - val_loss: 218.2082\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 182.5099 - val_loss: 215.0367\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 177.6940 - val_loss: 211.0093\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 173.8795 - val_loss: 207.8640\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 170.3673 - val_loss: 205.1390\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 167.2457 - val_loss: 201.7894\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 164.5879 - val_loss: 199.0121\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 162.0388 - val_loss: 196.4780\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 159.6778 - val_loss: 193.7296\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 157.5459 - val_loss: 190.8467\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 155.3991 - val_loss: 189.1835\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 153.3277 - val_loss: 187.5551\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 13ms/step - loss: 151.4515 - val_loss: 185.1228\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 12ms/step - loss: 149.5426 - val_loss: 182.7131\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 7ms/step - loss: 147.8903 - val_loss: 180.9367\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.2599 - val_loss: 179.4623\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 144.7608 - val_loss: 177.4538\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 143.1979 - val_loss: 175.5412\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 13ms/step - loss: 141.7739 - val_loss: 173.9052\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 13ms/step - loss: 140.3873 - val_loss: 172.8869\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 13ms/step - loss: 139.0724 - val_loss: 171.1834\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 137.7556 - val_loss: 169.7623\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 136.5942 - val_loss: 169.0205\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 135.3257 - val_loss: 167.6316\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 134.1242 - val_loss: 166.2489\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 133.3059 - val_loss: 165.4866\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 132.0810 - val_loss: 163.8665\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 53ms/step - loss: 1506.3479 - val_loss: 1527.0157\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1479.4233 - val_loss: 1497.1233\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 5ms/step - loss: 1448.8289 - val_loss: 1461.8137\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1411.6575 - val_loss: 1417.4449\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1365.1338 - val_loss: 1361.6915\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1306.5190 - val_loss: 1293.0326\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 7ms/step - loss: 1234.7408 - val_loss: 1207.9122\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1146.3721 - val_loss: 1107.9891\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1044.1670 - val_loss: 997.0740\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 931.5149 - val_loss: 880.1104\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 814.8391 - val_loss: 756.8464\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 696.6498 - val_loss: 639.2827\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 583.3131 - val_loss: 535.7743\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 481.7099 - val_loss: 446.3395\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 7ms/step - loss: 397.5040 - val_loss: 373.6491\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 5ms/step - loss: 330.0801 - val_loss: 320.4070\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 278.8206 - val_loss: 286.0782\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 245.3824 - val_loss: 263.4936\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 222.3641 - val_loss: 250.2283\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 207.7463 - val_loss: 241.1621\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 198.2038 - val_loss: 235.9786\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 191.2763 - val_loss: 232.1232\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 186.0936 - val_loss: 228.1327\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 181.9917 - val_loss: 224.6541\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 7ms/step - loss: 178.5054 - val_loss: 222.3029\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 175.4530 - val_loss: 219.0231\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 172.6853 - val_loss: 217.2968\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 170.2057 - val_loss: 215.0079\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 167.9206 - val_loss: 212.3392\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 166.0270 - val_loss: 209.8649\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 5ms/step - loss: 164.3369 - val_loss: 207.5808\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 162.3394 - val_loss: 205.6712\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 160.5767 - val_loss: 204.0917\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 159.0730 - val_loss: 202.9892\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 157.5701 - val_loss: 200.9796\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 155.9258 - val_loss: 199.6826\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 154.5748 - val_loss: 198.1874\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 153.1886 - val_loss: 196.4711\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 151.9270 - val_loss: 194.5373\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 150.6533 - val_loss: 193.7223\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 149.5191 - val_loss: 192.6652\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.3047 - val_loss: 190.9951\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 147.2474 - val_loss: 190.9824\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.0728 - val_loss: 188.6970\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.0969 - val_loss: 187.0975\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 143.9759 - val_loss: 186.1037\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.9195 - val_loss: 184.7286\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.1133 - val_loss: 184.5513\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 141.1007 - val_loss: 183.5975\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.3315 - val_loss: 182.3449\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 53ms/step - loss: 1532.8033 - val_loss: 1553.4501\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 9ms/step - loss: 1503.5269 - val_loss: 1521.6927\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 13ms/step - loss: 1472.4197 - val_loss: 1486.8912\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1437.1044 - val_loss: 1445.6353\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1395.1757 - val_loss: 1395.6134\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1344.7780 - val_loss: 1336.8533\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 7ms/step - loss: 1285.4956 - val_loss: 1268.6619\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1216.1464 - val_loss: 1188.9043\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1138.1180 - val_loss: 1098.7256\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 13ms/step - loss: 1050.6066 - val_loss: 1002.6620\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 7ms/step - loss: 957.4391 - val_loss: 900.0747\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 9ms/step - loss: 858.5441 - val_loss: 793.7996\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 11ms/step - loss: 756.9992 - val_loss: 688.3549\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 657.4155 - val_loss: 589.2636\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 561.7859 - val_loss: 501.2647\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 477.2260 - val_loss: 424.7615\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 405.0016 - val_loss: 363.6352\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 344.8696 - val_loss: 319.4456\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 300.7323 - val_loss: 288.8294\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 268.2942 - val_loss: 268.5366\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 245.5212 - val_loss: 255.6831\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 229.9902 - val_loss: 247.1037\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 217.7341 - val_loss: 241.0889\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 209.0565 - val_loss: 236.0664\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 202.1231 - val_loss: 231.5592\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 195.7290 - val_loss: 227.3229\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 190.8181 - val_loss: 223.6497\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 185.6397 - val_loss: 219.6175\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 181.5645 - val_loss: 215.7547\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 177.3531 - val_loss: 211.1960\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 173.4287 - val_loss: 207.9019\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 169.7117 - val_loss: 203.8605\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.2249 - val_loss: 200.6192\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 162.8004 - val_loss: 197.3567\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 159.9216 - val_loss: 194.2769\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 156.8029 - val_loss: 191.1968\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 153.9934 - val_loss: 188.0266\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 5ms/step - loss: 151.2307 - val_loss: 185.4172\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.8409 - val_loss: 183.0612\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.4112 - val_loss: 180.5023\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 144.1923 - val_loss: 178.1180\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.1215 - val_loss: 176.3169\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.0410 - val_loss: 174.2149\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 138.1617 - val_loss: 172.5173\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 136.5045 - val_loss: 170.4989\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 134.7492 - val_loss: 168.8867\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 133.0316 - val_loss: 167.2230\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 5ms/step - loss: 131.4071 - val_loss: 164.9317\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 129.8846 - val_loss: 163.3162\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 128.4603 - val_loss: 161.2115\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 52ms/step - loss: 1543.2845 - val_loss: 1560.3445\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 6ms/step - loss: 1514.7406 - val_loss: 1529.8215\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 5ms/step - loss: 1484.4753 - val_loss: 1495.5775\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1450.3240 - val_loss: 1455.0168\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1407.0503 - val_loss: 1404.8198\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1353.0563 - val_loss: 1343.0392\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1287.6266 - val_loss: 1269.9438\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1211.9753 - val_loss: 1186.6763\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 1126.6069 - val_loss: 1097.6373\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1034.9409 - val_loss: 1001.6752\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 5ms/step - loss: 938.0376 - val_loss: 903.6191\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 839.7462 - val_loss: 807.7960\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 745.2565 - val_loss: 719.0131\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 657.5291 - val_loss: 640.5599\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 580.6715 - val_loss: 572.7109\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 513.9329 - val_loss: 514.1057\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 455.9573 - val_loss: 462.1467\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 406.7025 - val_loss: 413.6665\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 360.9962 - val_loss: 367.8736\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 319.2630 - val_loss: 325.6596\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 283.3047 - val_loss: 291.1319\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 254.9240 - val_loss: 263.5266\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 232.1869 - val_loss: 243.2776\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 216.9024 - val_loss: 229.4028\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 205.5760 - val_loss: 219.2063\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 7ms/step - loss: 197.6847 - val_loss: 211.4246\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 191.2200 - val_loss: 205.5458\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 185.6671 - val_loss: 201.5138\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 7ms/step - loss: 180.9884 - val_loss: 197.2981\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 177.0218 - val_loss: 193.2372\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 173.0894 - val_loss: 189.5443\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 169.3896 - val_loss: 186.7616\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 13ms/step - loss: 166.5899 - val_loss: 182.6529\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 162.8341 - val_loss: 180.3623\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 159.9757 - val_loss: 178.0886\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 157.0880 - val_loss: 175.6339\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 154.4886 - val_loss: 173.0103\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 152.0598 - val_loss: 170.8646\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.7421 - val_loss: 168.7062\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 13ms/step - loss: 147.5482 - val_loss: 166.6888\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.0273 - val_loss: 165.8970\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 13ms/step - loss: 143.8007 - val_loss: 163.8610\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 8ms/step - loss: 141.9889 - val_loss: 162.1409\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 10ms/step - loss: 140.5861 - val_loss: 160.5809\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 9ms/step - loss: 139.0113 - val_loss: 159.5277\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.5217 - val_loss: 158.8411\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 136.2139 - val_loss: 157.7477\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 135.1701 - val_loss: 157.2078\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 133.7116 - val_loss: 155.6909\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 132.8258 - val_loss: 155.5042\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 51ms/step - loss: 1591.9185 - val_loss: 1615.2543\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1570.3547 - val_loss: 1595.3115\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1550.3563 - val_loss: 1576.0463\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1529.3076 - val_loss: 1554.7354\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1505.0623 - val_loss: 1529.7831\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1476.1176 - val_loss: 1499.4331\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 5ms/step - loss: 1440.8954 - val_loss: 1461.1389\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1398.0012 - val_loss: 1414.7321\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1346.7334 - val_loss: 1360.8794\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 7ms/step - loss: 1287.8690 - val_loss: 1297.9794\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1220.1855 - val_loss: 1226.8613\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1144.2950 - val_loss: 1148.3607\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1060.8500 - val_loss: 1062.0132\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 972.3651 - val_loss: 968.6808\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 878.0916 - val_loss: 874.1324\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 784.3907 - val_loss: 779.8641\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 692.7483 - val_loss: 687.5745\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 604.9487 - val_loss: 602.0593\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 524.3191 - val_loss: 525.4706\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 454.1653 - val_loss: 457.8592\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 394.0518 - val_loss: 402.9904\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 344.3010 - val_loss: 360.3398\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 306.2935 - val_loss: 326.1424\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 276.6188 - val_loss: 301.8712\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 253.9300 - val_loss: 284.2109\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 237.3748 - val_loss: 270.7928\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 224.6407 - val_loss: 260.7812\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 214.5055 - val_loss: 252.9727\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 207.0318 - val_loss: 245.8737\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 200.4528 - val_loss: 240.5501\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 195.1745 - val_loss: 235.1839\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 190.4886 - val_loss: 230.9836\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 186.5013 - val_loss: 226.5829\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 182.9667 - val_loss: 222.3729\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 179.6674 - val_loss: 218.8839\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 176.7284 - val_loss: 215.9113\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 173.6570 - val_loss: 212.5359\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 171.2008 - val_loss: 208.9711\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 168.5856 - val_loss: 206.1001\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.2488 - val_loss: 203.0961\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 164.0125 - val_loss: 200.4845\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 161.8180 - val_loss: 198.2954\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 159.8092 - val_loss: 196.3307\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 158.0917 - val_loss: 194.5698\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 156.1904 - val_loss: 192.7014\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 154.5502 - val_loss: 190.8902\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 152.9568 - val_loss: 188.7447\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 151.2244 - val_loss: 187.4019\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.8354 - val_loss: 186.0937\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.2165 - val_loss: 184.3997\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 52ms/step - loss: 1516.7687 - val_loss: 1540.6074\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 6ms/step - loss: 1495.4950 - val_loss: 1515.7644\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 12ms/step - loss: 1469.7458 - val_loss: 1485.1877\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1437.2759 - val_loss: 1447.1212\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1397.4534 - val_loss: 1400.0447\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1348.9209 - val_loss: 1343.5762\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1290.2037 - val_loss: 1274.6813\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 8ms/step - loss: 1219.2063 - val_loss: 1193.3800\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 11ms/step - loss: 1135.4246 - val_loss: 1097.9419\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 7ms/step - loss: 1036.5778 - val_loss: 987.8664\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 14ms/step - loss: 927.3033 - val_loss: 870.6376\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 8ms/step - loss: 812.6967 - val_loss: 751.1662\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 8ms/step - loss: 697.9918 - val_loss: 635.5120\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 11ms/step - loss: 588.6287 - val_loss: 530.6376\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 488.5237 - val_loss: 441.1848\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 402.7956 - val_loss: 368.1276\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 335.1013 - val_loss: 314.6705\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 285.0182 - val_loss: 281.1231\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 7ms/step - loss: 249.9840 - val_loss: 262.3597\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 227.5903 - val_loss: 251.3484\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 213.6596 - val_loss: 245.3760\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 7ms/step - loss: 203.8314 - val_loss: 241.8266\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 197.2943 - val_loss: 238.0509\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 5ms/step - loss: 192.1408 - val_loss: 234.4739\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 187.8633 - val_loss: 231.4623\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 184.1858 - val_loss: 228.4680\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 180.8193 - val_loss: 225.6850\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 177.7854 - val_loss: 221.4940\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 174.8211 - val_loss: 218.9973\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 7ms/step - loss: 172.3786 - val_loss: 216.2677\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 169.5958 - val_loss: 212.4929\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 167.6004 - val_loss: 209.4763\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 165.8315 - val_loss: 208.1773\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 163.7828 - val_loss: 205.0734\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 161.8499 - val_loss: 203.8877\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 159.8690 - val_loss: 201.8132\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 158.0310 - val_loss: 199.3386\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 7ms/step - loss: 156.5955 - val_loss: 197.8356\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 154.7188 - val_loss: 195.6359\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 153.3432 - val_loss: 194.2688\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 151.8529 - val_loss: 191.9975\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.3351 - val_loss: 190.0762\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.9965 - val_loss: 188.3372\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 147.9426 - val_loss: 187.7560\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.5495 - val_loss: 186.4482\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 145.5136 - val_loss: 184.5293\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.2408 - val_loss: 183.3240\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 143.2825 - val_loss: 182.6570\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 142.0322 - val_loss: 180.6884\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 5ms/step - loss: 141.0215 - val_loss: 179.1222\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 51ms/step - loss: 1557.9711 - val_loss: 1579.4784\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1539.2058 - val_loss: 1558.9792\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1518.8518 - val_loss: 1534.8458\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1493.5250 - val_loss: 1503.9928\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1460.5609 - val_loss: 1462.2361\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1416.6499 - val_loss: 1408.3068\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1359.1643 - val_loss: 1337.9832\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1287.1561 - val_loss: 1253.4921\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1201.0653 - val_loss: 1154.9744\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1100.2083 - val_loss: 1041.8295\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 986.2762 - val_loss: 918.4575\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 862.8282 - val_loss: 784.8854\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 731.3445 - val_loss: 650.9543\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 600.9333 - val_loss: 523.3994\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 475.8547 - val_loss: 417.7097\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 374.1479 - val_loss: 333.0268\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 296.1460 - val_loss: 277.0788\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 244.9230 - val_loss: 246.6594\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 215.7761 - val_loss: 232.9611\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 200.1890 - val_loss: 226.3972\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 191.2944 - val_loss: 222.3981\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 186.0535 - val_loss: 220.6607\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 182.1316 - val_loss: 217.5444\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 7ms/step - loss: 179.1642 - val_loss: 214.9664\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 176.7179 - val_loss: 212.9365\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 174.0663 - val_loss: 210.0306\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 171.8681 - val_loss: 207.4116\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 169.6494 - val_loss: 205.3391\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 167.7453 - val_loss: 203.9324\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 165.8257 - val_loss: 201.2635\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 164.2082 - val_loss: 199.0968\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 162.4157 - val_loss: 197.3716\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 13ms/step - loss: 160.8933 - val_loss: 195.4141\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 159.6427 - val_loss: 194.5280\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 7ms/step - loss: 158.1820 - val_loss: 192.3465\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 13ms/step - loss: 157.0368 - val_loss: 190.8427\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 155.5049 - val_loss: 189.6722\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 13ms/step - loss: 154.3480 - val_loss: 188.1428\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 15ms/step - loss: 153.3341 - val_loss: 187.0394\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 8ms/step - loss: 152.3949 - val_loss: 185.8396\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 11ms/step - loss: 151.4975 - val_loss: 184.4001\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 5ms/step - loss: 150.5839 - val_loss: 183.4695\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.7880 - val_loss: 182.1699\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.0287 - val_loss: 181.1011\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.2758 - val_loss: 180.9711\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 147.4374 - val_loss: 179.7686\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 146.9164 - val_loss: 178.2338\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 146.3994 - val_loss: 178.4393\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.3911 - val_loss: 177.0125\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.7001 - val_loss: 176.9908\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 53ms/step - loss: 1559.7698 - val_loss: 1588.4652\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1545.7161 - val_loss: 1573.6023\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 1530.2793 - val_loss: 1556.5120\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 5ms/step - loss: 1511.8580 - val_loss: 1535.7668\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1488.7668 - val_loss: 1507.9071\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1457.2690 - val_loss: 1470.0734\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1414.7153 - val_loss: 1417.2072\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1355.7607 - val_loss: 1346.3881\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1277.5558 - val_loss: 1254.2792\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1178.9716 - val_loss: 1136.8943\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 5ms/step - loss: 1058.8989 - val_loss: 1001.5432\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 920.9435 - val_loss: 855.7968\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 777.0177 - val_loss: 706.3038\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 632.7357 - val_loss: 569.9630\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 7ms/step - loss: 509.1668 - val_loss: 458.2686\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 409.0555 - val_loss: 381.7733\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 337.3650 - val_loss: 327.5450\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 285.5122 - val_loss: 292.9594\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 251.6417 - val_loss: 270.3491\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 229.8893 - val_loss: 256.9676\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 215.6503 - val_loss: 248.1086\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 206.3173 - val_loss: 241.7642\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 198.9961 - val_loss: 236.7719\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 193.6983 - val_loss: 232.0377\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 7ms/step - loss: 188.7067 - val_loss: 227.6636\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 184.6163 - val_loss: 224.1387\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 181.3047 - val_loss: 221.5879\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 177.4941 - val_loss: 217.7452\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 174.1514 - val_loss: 214.3772\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 171.3686 - val_loss: 211.2382\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 168.3854 - val_loss: 207.9530\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 165.7184 - val_loss: 206.0516\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 162.8864 - val_loss: 202.3933\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 160.2701 - val_loss: 199.8668\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 157.7592 - val_loss: 197.5394\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 155.2620 - val_loss: 195.0023\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 153.0472 - val_loss: 193.2132\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.8022 - val_loss: 190.5097\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.7348 - val_loss: 188.1506\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 146.6497 - val_loss: 185.5580\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 5ms/step - loss: 144.9882 - val_loss: 183.6452\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 143.1173 - val_loss: 181.2695\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 141.2861 - val_loss: 178.8948\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 139.7535 - val_loss: 177.0455\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 138.6619 - val_loss: 176.1632\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 136.8888 - val_loss: 174.7729\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 135.8023 - val_loss: 172.4088\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 7ms/step - loss: 134.5139 - val_loss: 170.6515\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 133.3511 - val_loss: 170.0341\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 132.3499 - val_loss: 168.9972\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 61ms/step - loss: 1566.0457 - val_loss: 1588.2269\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 19ms/step - loss: 1540.5925 - val_loss: 1564.4336\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1518.1089 - val_loss: 1541.9993\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1495.8440 - val_loss: 1517.7311\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1470.7540 - val_loss: 1489.4965\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1441.2653 - val_loss: 1455.8694\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 13ms/step - loss: 1405.7942 - val_loss: 1415.0089\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 14ms/step - loss: 1362.1367 - val_loss: 1365.7366\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 11ms/step - loss: 1309.0189 - val_loss: 1306.1229\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1245.0812 - val_loss: 1234.0746\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1168.8629 - val_loss: 1149.6520\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1080.7417 - val_loss: 1054.7173\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 983.4728 - val_loss: 949.8182\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 878.7850 - val_loss: 841.0033\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 772.9398 - val_loss: 730.5737\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 667.3865 - val_loss: 626.7034\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 568.6959 - val_loss: 530.7752\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 479.0647 - val_loss: 448.9659\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 402.6708 - val_loss: 379.7908\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 340.5225 - val_loss: 326.6823\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 292.2937 - val_loss: 288.4090\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 257.0649 - val_loss: 261.3080\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 231.4779 - val_loss: 242.9894\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 213.8727 - val_loss: 230.6307\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 201.4584 - val_loss: 222.0757\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 7ms/step - loss: 192.2412 - val_loss: 216.5351\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 5ms/step - loss: 185.4403 - val_loss: 211.8518\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 179.7718 - val_loss: 207.4176\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 175.3445 - val_loss: 203.7390\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 171.2405 - val_loss: 201.0230\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 167.7896 - val_loss: 198.0070\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 164.8203 - val_loss: 195.8372\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 162.3323 - val_loss: 193.8326\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 160.0056 - val_loss: 192.0513\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 157.9623 - val_loss: 190.3988\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 155.9614 - val_loss: 188.4186\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 154.0750 - val_loss: 186.5294\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 152.3900 - val_loss: 184.6057\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.8348 - val_loss: 182.8065\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.3107 - val_loss: 181.5047\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 147.5838 - val_loss: 179.6814\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.2369 - val_loss: 177.9796\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.9353 - val_loss: 177.1403\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 143.4766 - val_loss: 175.2548\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.2314 - val_loss: 173.8614\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.1226 - val_loss: 172.8576\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.1169 - val_loss: 172.0414\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 139.1344 - val_loss: 170.8831\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 138.2943 - val_loss: 169.6965\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.4998 - val_loss: 168.7596\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 51ms/step - loss: 1539.8119 - val_loss: 1560.1249\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1515.5483 - val_loss: 1534.6737\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1490.1655 - val_loss: 1506.4821\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1461.1992 - val_loss: 1473.6041\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1426.9601 - val_loss: 1432.7573\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 9ms/step - loss: 1382.1586 - val_loss: 1379.8381\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 10ms/step - loss: 1321.7567 - val_loss: 1306.0281\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1238.2772 - val_loss: 1204.4072\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1127.6244 - val_loss: 1079.2704\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 999.9546 - val_loss: 942.0633\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 5ms/step - loss: 862.9691 - val_loss: 802.8299\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 725.6345 - val_loss: 667.7651\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 596.1739 - val_loss: 543.7889\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 479.1223 - val_loss: 442.4450\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 7ms/step - loss: 384.6308 - val_loss: 365.6662\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 314.2115 - val_loss: 313.2443\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 266.6985 - val_loss: 282.4857\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 239.1708 - val_loss: 265.4536\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 221.6005 - val_loss: 256.6709\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 211.0534 - val_loss: 249.2695\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 203.2254 - val_loss: 242.7867\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 197.1638 - val_loss: 236.8982\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 191.7759 - val_loss: 232.1541\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 7ms/step - loss: 187.2170 - val_loss: 227.7681\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 13ms/step - loss: 182.8238 - val_loss: 223.6304\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 13ms/step - loss: 179.2711 - val_loss: 218.8772\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 176.2438 - val_loss: 216.6576\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 172.6397 - val_loss: 212.1322\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 169.9957 - val_loss: 208.2352\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 167.2641 - val_loss: 206.1155\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 13ms/step - loss: 164.9751 - val_loss: 202.7154\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 7ms/step - loss: 162.7433 - val_loss: 200.8452\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 13ms/step - loss: 160.8244 - val_loss: 198.5770\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 159.1778 - val_loss: 196.2707\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 11ms/step - loss: 157.3665 - val_loss: 195.3013\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 155.8898 - val_loss: 193.1585\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 154.4874 - val_loss: 191.9701\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 153.1866 - val_loss: 189.1487\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 151.7891 - val_loss: 189.1372\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.6859 - val_loss: 186.5286\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 149.1907 - val_loss: 185.8407\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 5ms/step - loss: 147.8857 - val_loss: 184.5474\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 146.8688 - val_loss: 183.0103\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.6893 - val_loss: 181.7460\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.7466 - val_loss: 181.2825\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 143.6854 - val_loss: 179.4086\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.7705 - val_loss: 177.3112\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.7305 - val_loss: 175.9839\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 7ms/step - loss: 140.6833 - val_loss: 175.4804\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 140.0215 - val_loss: 174.4280\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 52ms/step - loss: 1568.4807 - val_loss: 1597.5673\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1551.1873 - val_loss: 1580.4125\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1534.8887 - val_loss: 1563.1544\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1517.1276 - val_loss: 1543.5601\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1496.1494 - val_loss: 1519.1343\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 5ms/step - loss: 1469.5605 - val_loss: 1488.5509\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1435.1863 - val_loss: 1449.2308\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1391.6139 - val_loss: 1401.4790\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 1339.1000 - val_loss: 1343.4854\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1277.7355 - val_loss: 1275.1902\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1207.0375 - val_loss: 1197.9302\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1126.9395 - val_loss: 1112.6116\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 7ms/step - loss: 1039.9910 - val_loss: 1016.4530\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 945.1071 - val_loss: 915.9838\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 846.0032 - val_loss: 812.5234\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 745.0123 - val_loss: 709.9524\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 8ms/step - loss: 645.7544 - val_loss: 609.9762\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 551.3589 - val_loss: 519.6514\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 466.9289 - val_loss: 442.3846\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 395.0511 - val_loss: 376.5114\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 335.0882 - val_loss: 325.5291\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 289.1626 - val_loss: 288.0369\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 255.5324 - val_loss: 260.6678\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 230.2568 - val_loss: 241.9100\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 212.5790 - val_loss: 228.8593\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 199.6717 - val_loss: 218.4869\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 189.7945 - val_loss: 210.9736\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 182.0650 - val_loss: 205.0404\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 8ms/step - loss: 176.3085 - val_loss: 200.0939\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 171.0447 - val_loss: 196.0390\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.8916 - val_loss: 192.1421\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 163.5216 - val_loss: 188.9231\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 160.5525 - val_loss: 186.1798\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 158.0821 - val_loss: 184.7264\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 155.9758 - val_loss: 182.5128\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 153.9955 - val_loss: 181.3130\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 152.2160 - val_loss: 179.8975\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 150.7037 - val_loss: 178.6491\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.0720 - val_loss: 177.5069\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 147.8969 - val_loss: 176.2629\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 5ms/step - loss: 146.5635 - val_loss: 174.7786\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 7ms/step - loss: 145.5998 - val_loss: 173.5997\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 144.4708 - val_loss: 173.4105\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 143.4324 - val_loss: 172.4986\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.5516 - val_loss: 171.9420\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 141.6967 - val_loss: 170.9252\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.8803 - val_loss: 170.1770\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 140.2145 - val_loss: 169.4935\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 139.5203 - val_loss: 169.3613\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 138.9071 - val_loss: 168.6108\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 73ms/step - loss: 1561.5771 - val_loss: 1590.1307\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 18ms/step - loss: 1548.2133 - val_loss: 1576.2158\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 13ms/step - loss: 1534.1814 - val_loss: 1560.0387\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 5ms/step - loss: 1516.7933 - val_loss: 1539.8588\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 7ms/step - loss: 1493.7633 - val_loss: 1512.3848\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1462.9208 - val_loss: 1475.4797\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1422.0797 - val_loss: 1428.8169\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1370.2799 - val_loss: 1371.6414\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1306.4995 - val_loss: 1302.9746\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1232.9613 - val_loss: 1222.0841\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1147.8375 - val_loss: 1132.3287\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1053.7751 - val_loss: 1032.0565\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 949.8142 - val_loss: 922.9378\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 837.3326 - val_loss: 804.9698\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 720.3741 - val_loss: 685.6268\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 605.3299 - val_loss: 573.3551\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 500.4312 - val_loss: 472.6364\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 410.3293 - val_loss: 392.2677\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 340.5215 - val_loss: 330.4138\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 287.3829 - val_loss: 288.4962\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 250.7112 - val_loss: 259.0321\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 224.5877 - val_loss: 240.5410\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 207.2903 - val_loss: 227.2998\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 7ms/step - loss: 194.3400 - val_loss: 218.7557\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 185.1622 - val_loss: 212.1178\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 177.9657 - val_loss: 207.5588\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 172.6439 - val_loss: 202.3807\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 7ms/step - loss: 167.8474 - val_loss: 199.6667\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 163.8514 - val_loss: 196.7940\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 160.8000 - val_loss: 194.6277\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 158.2240 - val_loss: 192.5455\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 155.8923 - val_loss: 190.2731\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 153.8152 - val_loss: 188.4661\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 151.9379 - val_loss: 186.1761\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.4365 - val_loss: 185.0189\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.8035 - val_loss: 183.5724\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 147.4077 - val_loss: 182.4012\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 5ms/step - loss: 145.9507 - val_loss: 181.0615\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 144.9727 - val_loss: 180.0933\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 143.6587 - val_loss: 178.4377\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.6990 - val_loss: 177.8020\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.6242 - val_loss: 176.5991\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.6997 - val_loss: 175.7113\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 139.6927 - val_loss: 174.3593\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 138.9045 - val_loss: 173.1666\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 137.9806 - val_loss: 172.0410\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.0347 - val_loss: 171.3074\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 136.3389 - val_loss: 170.3935\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 135.7537 - val_loss: 169.4355\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 134.7237 - val_loss: 168.0253\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 52ms/step - loss: 1535.3949 - val_loss: 1562.6099\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1520.1262 - val_loss: 1545.5798\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 1501.9806 - val_loss: 1523.8828\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1478.3258 - val_loss: 1496.0883\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1447.9529 - val_loss: 1460.7472\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1410.1107 - val_loss: 1416.2733\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 7ms/step - loss: 1363.0585 - val_loss: 1362.6310\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 5ms/step - loss: 1307.0076 - val_loss: 1297.9353\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1239.1642 - val_loss: 1222.0288\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1159.0038 - val_loss: 1132.1019\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1065.6598 - val_loss: 1029.5887\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 960.7298 - val_loss: 916.1339\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 845.6886 - val_loss: 795.1188\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 726.6944 - val_loss: 670.6561\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 607.7469 - val_loss: 559.5712\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 5ms/step - loss: 503.0532 - val_loss: 462.5042\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 415.0060 - val_loss: 388.1008\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 347.6533 - val_loss: 337.1774\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 300.3657 - val_loss: 304.8755\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 270.4021 - val_loss: 285.8663\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 250.8469 - val_loss: 275.4832\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 237.9294 - val_loss: 268.1212\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 228.1550 - val_loss: 261.7917\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 7ms/step - loss: 220.3562 - val_loss: 256.7646\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 213.6000 - val_loss: 251.6236\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 207.8207 - val_loss: 245.9308\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 202.4325 - val_loss: 240.7493\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 197.3913 - val_loss: 236.4479\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 192.5855 - val_loss: 231.9231\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 188.1638 - val_loss: 227.8606\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 8ms/step - loss: 183.9222 - val_loss: 223.2241\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 14ms/step - loss: 180.0022 - val_loss: 219.1894\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 11ms/step - loss: 176.3177 - val_loss: 215.2988\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 15ms/step - loss: 172.5833 - val_loss: 211.5716\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 11ms/step - loss: 169.0539 - val_loss: 208.2634\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 165.4786 - val_loss: 203.9581\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 162.0886 - val_loss: 200.2021\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 158.6952 - val_loss: 196.9020\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 155.3595 - val_loss: 194.0764\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 152.1800 - val_loss: 191.0087\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 5ms/step - loss: 149.1397 - val_loss: 188.0089\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 5ms/step - loss: 146.0524 - val_loss: 184.7144\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 7ms/step - loss: 143.1869 - val_loss: 181.2774\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 140.2492 - val_loss: 178.3028\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.3826 - val_loss: 175.8833\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 134.7484 - val_loss: 172.4461\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 132.1654 - val_loss: 169.5156\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 129.6218 - val_loss: 167.0287\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 127.2896 - val_loss: 164.9172\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 125.1086 - val_loss: 161.7914\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 50ms/step - loss: 1521.1633 - val_loss: 1542.5339\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1500.0623 - val_loss: 1519.1404\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1475.8188 - val_loss: 1490.9065\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1445.4169 - val_loss: 1455.1156\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 5ms/step - loss: 1406.1090 - val_loss: 1409.0851\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1354.7837 - val_loss: 1350.2522\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1288.4962 - val_loss: 1276.1708\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1207.4912 - val_loss: 1187.0127\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1112.9042 - val_loss: 1085.8884\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1007.7193 - val_loss: 979.9797\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 897.6815 - val_loss: 871.5695\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 787.9484 - val_loss: 767.7192\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 684.3469 - val_loss: 671.0484\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 590.3604 - val_loss: 586.5480\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 509.6046 - val_loss: 514.6577\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 5ms/step - loss: 442.1717 - val_loss: 451.7635\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 384.9210 - val_loss: 401.7379\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 338.7000 - val_loss: 359.6100\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 302.7709 - val_loss: 324.2750\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 270.7757 - val_loss: 295.8192\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 246.7697 - val_loss: 274.8417\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 228.8926 - val_loss: 258.0556\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 5ms/step - loss: 214.9933 - val_loss: 245.5393\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 205.4287 - val_loss: 235.8562\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 198.0038 - val_loss: 229.8919\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 192.9968 - val_loss: 225.9117\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 188.3627 - val_loss: 220.6212\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 184.4167 - val_loss: 217.3204\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 181.1690 - val_loss: 214.3266\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 178.5462 - val_loss: 211.5877\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 175.8459 - val_loss: 209.1429\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 173.4099 - val_loss: 206.9864\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 171.2257 - val_loss: 204.6454\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 169.2893 - val_loss: 203.1758\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.9570 - val_loss: 200.3954\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 164.9114 - val_loss: 198.5394\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 162.8156 - val_loss: 196.0703\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 5ms/step - loss: 161.1408 - val_loss: 194.9005\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 159.0720 - val_loss: 192.9309\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 157.5890 - val_loss: 190.1889\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 155.7600 - val_loss: 189.3943\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 5ms/step - loss: 154.1577 - val_loss: 187.8963\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 152.6416 - val_loss: 186.7469\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.8341 - val_loss: 183.5991\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 149.3552 - val_loss: 182.2346\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.0660 - val_loss: 180.8116\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 146.5047 - val_loss: 179.2671\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 145.0946 - val_loss: 178.3003\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 143.7183 - val_loss: 177.0695\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 142.2380 - val_loss: 175.8576\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 66ms/step - loss: 1606.2748 - val_loss: 1629.2174\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 20ms/step - loss: 1578.6063 - val_loss: 1600.8319\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 13ms/step - loss: 1551.7029 - val_loss: 1574.0641\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 13ms/step - loss: 1524.5359 - val_loss: 1544.3217\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1493.9622 - val_loss: 1509.7767\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 9ms/step - loss: 1457.3004 - val_loss: 1466.5063\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 8ms/step - loss: 1410.1630 - val_loss: 1410.4812\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 10ms/step - loss: 1349.7472 - val_loss: 1343.2059\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 5ms/step - loss: 1277.7618 - val_loss: 1262.9147\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 7ms/step - loss: 1193.6937 - val_loss: 1171.6509\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1098.8392 - val_loss: 1071.2903\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 995.0125 - val_loss: 964.8527\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 884.5128 - val_loss: 855.2170\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 772.6028 - val_loss: 743.7481\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 7ms/step - loss: 660.8629 - val_loss: 640.3376\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 556.6376 - val_loss: 543.2958\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 461.5900 - val_loss: 459.2237\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 378.6925 - val_loss: 391.0711\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 7ms/step - loss: 315.2025 - val_loss: 338.0120\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 268.3082 - val_loss: 303.8516\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 238.8416 - val_loss: 281.8265\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 221.8716 - val_loss: 267.6037\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 210.1978 - val_loss: 259.3680\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 202.7656 - val_loss: 252.0751\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 196.7992 - val_loss: 245.3240\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 191.5223 - val_loss: 239.6402\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 186.7819 - val_loss: 234.4834\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 7ms/step - loss: 182.8051 - val_loss: 229.1282\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 179.3527 - val_loss: 225.2994\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 175.5816 - val_loss: 220.4903\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 172.2997 - val_loss: 216.4793\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 169.1914 - val_loss: 212.7872\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 166.4814 - val_loss: 209.3085\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 163.9426 - val_loss: 206.3791\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 161.5229 - val_loss: 203.7129\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 7ms/step - loss: 159.2381 - val_loss: 201.1539\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 157.2133 - val_loss: 198.0716\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 155.4739 - val_loss: 196.0419\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 153.5299 - val_loss: 192.6834\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 151.8506 - val_loss: 191.6738\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 150.2937 - val_loss: 188.4204\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 148.7929 - val_loss: 186.9043\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 147.3592 - val_loss: 184.9617\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 145.9544 - val_loss: 183.8123\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 144.7542 - val_loss: 181.6444\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 7ms/step - loss: 143.5634 - val_loss: 180.0780\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.3672 - val_loss: 178.5476\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.1837 - val_loss: 177.1235\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 139.9092 - val_loss: 175.2844\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 138.6765 - val_loss: 173.6966\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 51ms/step - loss: 1477.5226 - val_loss: 1503.1250\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1443.5016 - val_loss: 1465.5679\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 5ms/step - loss: 1402.0963 - val_loss: 1419.5627\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 7ms/step - loss: 1350.7426 - val_loss: 1361.3533\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1286.1589 - val_loss: 1290.7393\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1208.7590 - val_loss: 1204.3818\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1116.1185 - val_loss: 1104.0682\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1010.0829 - val_loss: 991.8586\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 893.8443 - val_loss: 868.7505\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 7ms/step - loss: 770.6514 - val_loss: 745.9374\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 649.1237 - val_loss: 631.3869\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 538.4811 - val_loss: 530.9780\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 446.3786 - val_loss: 450.0416\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 372.7441 - val_loss: 391.5863\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 320.3398 - val_loss: 349.2834\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 282.7955 - val_loss: 318.7615\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 256.7083 - val_loss: 297.6484\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 238.4289 - val_loss: 281.9602\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 224.2261 - val_loss: 269.8496\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 213.5394 - val_loss: 258.9298\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 204.9632 - val_loss: 250.7033\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 197.6849 - val_loss: 243.4541\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 192.0067 - val_loss: 236.3134\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 186.8147 - val_loss: 231.2153\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 8ms/step - loss: 182.4355 - val_loss: 226.2097\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 178.3364 - val_loss: 222.0224\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 175.0050 - val_loss: 217.8197\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 171.7185 - val_loss: 214.5395\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 168.6200 - val_loss: 211.2646\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 165.8051 - val_loss: 208.8099\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 163.3927 - val_loss: 206.3629\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 8ms/step - loss: 160.8817 - val_loss: 205.0096\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 11ms/step - loss: 158.7841 - val_loss: 202.0921\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 156.7538 - val_loss: 200.0685\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 7ms/step - loss: 155.0425 - val_loss: 197.3214\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 13ms/step - loss: 153.2532 - val_loss: 196.3384\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 12ms/step - loss: 151.8446 - val_loss: 195.4090\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.5350 - val_loss: 193.1091\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.0280 - val_loss: 192.1275\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 147.8076 - val_loss: 190.7581\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 146.7867 - val_loss: 189.0001\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.5686 - val_loss: 187.5709\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.4268 - val_loss: 186.4845\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 5ms/step - loss: 143.4679 - val_loss: 186.0249\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.3907 - val_loss: 185.0469\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.6014 - val_loss: 183.4844\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 140.9835 - val_loss: 183.4792\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 139.9327 - val_loss: 180.3627\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 139.2005 - val_loss: 179.0046\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 138.3586 - val_loss: 178.3197\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 52ms/step - loss: 1587.1680 - val_loss: 1613.0533\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1567.3964 - val_loss: 1595.2812\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1551.9805 - val_loss: 1580.6312\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1538.3577 - val_loss: 1566.9071\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1523.9087 - val_loss: 1551.0419\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 7ms/step - loss: 1506.2278 - val_loss: 1530.4467\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1483.2798 - val_loss: 1503.4154\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1452.9556 - val_loss: 1467.7798\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1413.1876 - val_loss: 1421.0808\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1360.8309 - val_loss: 1361.0726\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1293.9736 - val_loss: 1282.1394\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1208.4829 - val_loss: 1186.4780\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1106.1000 - val_loss: 1074.4078\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 990.1862 - val_loss: 948.9448\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 864.5540 - val_loss: 820.4391\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 736.7251 - val_loss: 692.7637\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 614.3221 - val_loss: 573.9691\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 502.5922 - val_loss: 472.6642\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 410.1501 - val_loss: 389.9236\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 335.9947 - val_loss: 330.8134\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 283.1711 - val_loss: 289.8846\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 5ms/step - loss: 247.3680 - val_loss: 264.3403\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 5ms/step - loss: 223.4798 - val_loss: 248.8357\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 208.1822 - val_loss: 238.3251\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 196.6722 - val_loss: 231.9487\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 188.6951 - val_loss: 225.5872\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 181.8522 - val_loss: 220.5204\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 176.1713 - val_loss: 216.3846\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 171.4568 - val_loss: 212.3047\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 166.6691 - val_loss: 208.3851\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 162.9122 - val_loss: 204.4413\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 159.4793 - val_loss: 201.2820\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 156.3359 - val_loss: 199.1174\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 153.4109 - val_loss: 195.4258\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.6276 - val_loss: 193.0286\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.4922 - val_loss: 191.1905\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.4088 - val_loss: 188.5849\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 144.3859 - val_loss: 186.8403\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 142.7737 - val_loss: 184.9304\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 141.3469 - val_loss: 182.3511\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 139.6493 - val_loss: 181.2849\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 138.2336 - val_loss: 179.1870\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 136.7570 - val_loss: 177.6259\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 135.6422 - val_loss: 175.7085\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 134.4268 - val_loss: 174.8028\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 7ms/step - loss: 133.2844 - val_loss: 172.4624\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 132.3693 - val_loss: 171.0625\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 131.4239 - val_loss: 169.8918\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 130.4099 - val_loss: 168.9322\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 129.7479 - val_loss: 167.8580\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 62ms/step - loss: 1545.0190 - val_loss: 1571.9725\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 17ms/step - loss: 1526.3304 - val_loss: 1552.2065\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 5ms/step - loss: 1504.8029 - val_loss: 1527.5862\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 15ms/step - loss: 1477.0142 - val_loss: 1495.6805\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 11ms/step - loss: 1440.8928 - val_loss: 1452.9453\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 13ms/step - loss: 1393.1019 - val_loss: 1396.2913\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1331.3273 - val_loss: 1324.9131\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1255.4480 - val_loss: 1238.5350\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1165.5891 - val_loss: 1139.6608\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1064.6888 - val_loss: 1028.9227\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 7ms/step - loss: 954.8624 - val_loss: 909.8807\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 7ms/step - loss: 837.4262 - val_loss: 790.1268\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 5ms/step - loss: 719.4123 - val_loss: 673.0403\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 606.7382 - val_loss: 565.6902\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 507.3527 - val_loss: 476.1204\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 425.4314 - val_loss: 407.5831\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 5ms/step - loss: 361.6019 - val_loss: 359.2686\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 315.5429 - val_loss: 324.5549\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 282.0015 - val_loss: 301.8170\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 258.5715 - val_loss: 284.5592\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 241.1076 - val_loss: 270.7614\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 227.1716 - val_loss: 259.7552\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 216.4919 - val_loss: 249.9924\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 5ms/step - loss: 206.9705 - val_loss: 241.7058\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 198.8306 - val_loss: 234.1045\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 191.5376 - val_loss: 226.5227\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 184.8803 - val_loss: 221.0807\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 179.1321 - val_loss: 215.2902\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 174.0701 - val_loss: 210.4519\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 169.3194 - val_loss: 206.1921\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 165.1229 - val_loss: 202.3948\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 161.5323 - val_loss: 198.9549\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 158.3999 - val_loss: 196.1813\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 155.4111 - val_loss: 192.5867\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 152.8433 - val_loss: 190.6658\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.7103 - val_loss: 188.3766\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.4551 - val_loss: 186.5335\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.5853 - val_loss: 184.1508\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 144.8638 - val_loss: 182.0329\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 143.1764 - val_loss: 180.5840\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.6040 - val_loss: 178.6348\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.2365 - val_loss: 177.2252\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 138.7019 - val_loss: 175.7362\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.4873 - val_loss: 174.3581\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 136.4413 - val_loss: 173.4563\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 135.4214 - val_loss: 171.6772\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 134.4712 - val_loss: 170.6084\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 133.4695 - val_loss: 169.9129\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 132.6979 - val_loss: 168.7892\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 131.8432 - val_loss: 167.7241\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 51ms/step - loss: 1571.9336 - val_loss: 1600.6125\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1557.3003 - val_loss: 1587.5846\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1544.8173 - val_loss: 1575.7283\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1532.6270 - val_loss: 1562.7957\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 7ms/step - loss: 1518.8353 - val_loss: 1546.7271\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1501.2496 - val_loss: 1526.3522\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1478.7977 - val_loss: 1498.9508\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1449.2582 - val_loss: 1462.9229\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1409.2280 - val_loss: 1415.8688\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1357.0168 - val_loss: 1353.7131\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1289.4685 - val_loss: 1276.3289\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1205.5099 - val_loss: 1182.5350\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 1106.7056 - val_loss: 1070.4187\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 992.3490 - val_loss: 949.5956\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 869.8889 - val_loss: 822.3757\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 744.9303 - val_loss: 697.8115\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 624.0931 - val_loss: 583.0792\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 513.7921 - val_loss: 484.9016\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 423.6766 - val_loss: 404.4530\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 350.1165 - val_loss: 347.6025\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 297.7574 - val_loss: 309.8699\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 262.3661 - val_loss: 286.0030\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 238.8544 - val_loss: 271.4967\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 7ms/step - loss: 223.7464 - val_loss: 262.4391\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 213.7455 - val_loss: 256.2734\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 206.2152 - val_loss: 250.4880\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 200.1281 - val_loss: 245.5447\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 13ms/step - loss: 194.8702 - val_loss: 240.6945\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 190.2136 - val_loss: 235.4409\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 13ms/step - loss: 185.9155 - val_loss: 231.4460\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 182.0618 - val_loss: 226.8811\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 178.3124 - val_loss: 221.7936\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 13ms/step - loss: 174.7042 - val_loss: 218.1909\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 13ms/step - loss: 171.5107 - val_loss: 214.8260\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 168.4793 - val_loss: 210.7598\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 12ms/step - loss: 165.5942 - val_loss: 206.9739\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 162.8345 - val_loss: 203.5090\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 160.3030 - val_loss: 200.6539\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 158.0424 - val_loss: 197.3045\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 155.8567 - val_loss: 194.5040\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 153.8767 - val_loss: 192.9972\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 7ms/step - loss: 152.0112 - val_loss: 189.7373\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 150.2228 - val_loss: 187.8829\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.7346 - val_loss: 185.9560\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 147.2691 - val_loss: 184.8260\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 145.9995 - val_loss: 182.8987\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 144.8207 - val_loss: 181.9473\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 5ms/step - loss: 143.8104 - val_loss: 180.0038\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.7786 - val_loss: 178.7257\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 141.2713 - val_loss: 176.9584\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 51ms/step - loss: 1553.8466 - val_loss: 1575.6995\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1532.7316 - val_loss: 1552.5287\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1509.0040 - val_loss: 1525.2227\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1479.9296 - val_loss: 1490.4069\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1443.6650 - val_loss: 1447.5521\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1398.8901 - val_loss: 1394.4962\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1343.4399 - val_loss: 1330.1335\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1276.4689 - val_loss: 1254.5975\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1199.4553 - val_loss: 1166.9146\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1111.4979 - val_loss: 1069.4584\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1013.8183 - val_loss: 963.9418\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 908.6355 - val_loss: 851.9429\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 7ms/step - loss: 799.9670 - val_loss: 742.0914\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 693.2396 - val_loss: 633.8799\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 589.2084 - val_loss: 538.2191\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 496.5757 - val_loss: 451.4976\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 414.3780 - val_loss: 383.4480\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 350.0156 - val_loss: 328.0341\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 297.0338 - val_loss: 289.3223\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 258.5858 - val_loss: 263.5098\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 230.4380 - val_loss: 246.9397\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 212.4308 - val_loss: 233.5723\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 198.3371 - val_loss: 225.5701\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 189.2393 - val_loss: 219.0951\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 182.1542 - val_loss: 214.8476\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 176.7866 - val_loss: 211.0630\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 172.8737 - val_loss: 208.1143\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 169.1315 - val_loss: 202.9714\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 165.6107 - val_loss: 200.7478\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 162.8330 - val_loss: 198.6242\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 160.4045 - val_loss: 196.0411\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 158.4058 - val_loss: 192.7536\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 156.4443 - val_loss: 190.7213\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 154.8456 - val_loss: 189.3921\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 153.2924 - val_loss: 187.0872\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 151.8961 - val_loss: 186.0710\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.4568 - val_loss: 184.5803\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.2148 - val_loss: 181.9909\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 147.9159 - val_loss: 181.5102\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 146.7737 - val_loss: 178.9055\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 5ms/step - loss: 145.3073 - val_loss: 177.7179\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.2185 - val_loss: 176.8743\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 143.1848 - val_loss: 175.5701\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.1440 - val_loss: 174.1910\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 141.3419 - val_loss: 173.3288\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.0676 - val_loss: 170.8421\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 139.1029 - val_loss: 169.5848\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 138.4829 - val_loss: 169.4820\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.3181 - val_loss: 168.2159\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 5ms/step - loss: 136.3511 - val_loss: 166.2123\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 70ms/step - loss: 1494.4685 - val_loss: 1517.2263\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 19ms/step - loss: 1468.8586 - val_loss: 1488.9559\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 13ms/step - loss: 1437.9868 - val_loss: 1453.5576\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 11ms/step - loss: 1398.1942 - val_loss: 1407.2913\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1347.1067 - val_loss: 1346.9832\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1280.3147 - val_loss: 1269.0325\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1196.6237 - val_loss: 1173.0487\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1097.1847 - val_loss: 1059.9049\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 982.3220 - val_loss: 933.1309\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 857.4695 - val_loss: 794.8998\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 723.6241 - val_loss: 658.8626\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 593.2551 - val_loss: 531.2329\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 476.3639 - val_loss: 424.2903\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 379.8806 - val_loss: 342.3358\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 308.5801 - val_loss: 288.0761\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 258.8708 - val_loss: 256.5262\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 227.3749 - val_loss: 239.0106\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 207.1133 - val_loss: 230.5664\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 195.6874 - val_loss: 226.2876\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 187.0861 - val_loss: 223.6866\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 181.6109 - val_loss: 221.5045\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 177.0474 - val_loss: 219.6522\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 173.2007 - val_loss: 217.9958\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 169.7762 - val_loss: 215.5324\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.6379 - val_loss: 213.5936\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 163.8315 - val_loss: 211.7673\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 161.3654 - val_loss: 209.0685\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 158.6659 - val_loss: 207.0268\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 156.2878 - val_loss: 205.2998\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 154.0707 - val_loss: 202.0362\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 152.1701 - val_loss: 201.0391\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.3117 - val_loss: 199.2045\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.5314 - val_loss: 196.6476\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 146.9223 - val_loss: 195.5744\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 145.3505 - val_loss: 193.5590\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 7ms/step - loss: 143.9564 - val_loss: 191.6610\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 142.5593 - val_loss: 190.5416\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.2436 - val_loss: 189.2182\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 139.8461 - val_loss: 187.8844\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 138.6527 - val_loss: 186.7280\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.8452 - val_loss: 184.5262\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 136.2493 - val_loss: 182.9891\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 135.0721 - val_loss: 181.8273\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 5ms/step - loss: 133.9192 - val_loss: 180.0249\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 133.0975 - val_loss: 178.9946\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 132.1020 - val_loss: 177.3990\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 131.1332 - val_loss: 176.7184\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 130.3289 - val_loss: 175.2635\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 129.4344 - val_loss: 174.1269\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 128.6033 - val_loss: 172.9497\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 52ms/step - loss: 1525.0797 - val_loss: 1542.1335\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 6ms/step - loss: 1493.8461 - val_loss: 1508.7961\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1458.1890 - val_loss: 1468.8876\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 7ms/step - loss: 1414.7527 - val_loss: 1422.4896\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1364.8595 - val_loss: 1368.3666\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1307.0240 - val_loss: 1306.8491\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 5ms/step - loss: 1241.3500 - val_loss: 1237.4841\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 7ms/step - loss: 1168.0708 - val_loss: 1161.1975\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 5ms/step - loss: 1089.1407 - val_loss: 1076.0487\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1003.3715 - val_loss: 988.6207\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 914.4903 - val_loss: 899.9191\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 825.9647 - val_loss: 811.1905\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 739.4186 - val_loss: 728.3234\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 658.2726 - val_loss: 651.5518\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 585.0525 - val_loss: 582.7230\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 518.5293 - val_loss: 525.9551\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 462.6586 - val_loss: 476.4823\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 7ms/step - loss: 414.7780 - val_loss: 435.7037\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 373.6937 - val_loss: 401.0810\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 340.3127 - val_loss: 372.4244\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 7ms/step - loss: 311.2162 - val_loss: 349.1385\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 287.8836 - val_loss: 329.1879\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 267.8144 - val_loss: 311.9461\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 13ms/step - loss: 250.5855 - val_loss: 297.0710\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 13ms/step - loss: 236.0566 - val_loss: 283.9041\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 13ms/step - loss: 224.2953 - val_loss: 272.9914\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 13ms/step - loss: 214.8458 - val_loss: 262.5136\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 206.3956 - val_loss: 254.2841\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 199.6057 - val_loss: 246.1040\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 13ms/step - loss: 193.8879 - val_loss: 238.9768\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 11ms/step - loss: 188.9841 - val_loss: 233.0706\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 184.9284 - val_loss: 227.5797\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 181.0092 - val_loss: 222.2427\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 177.6369 - val_loss: 217.2755\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 174.3974 - val_loss: 212.9342\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 171.6006 - val_loss: 208.4489\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 168.8359 - val_loss: 204.6104\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 166.1620 - val_loss: 201.1127\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 163.7613 - val_loss: 197.7100\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 161.5126 - val_loss: 195.6764\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 159.1646 - val_loss: 192.2695\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 157.1942 - val_loss: 189.3889\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 7ms/step - loss: 155.1009 - val_loss: 187.5293\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 5ms/step - loss: 153.1280 - val_loss: 184.0707\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 150.9895 - val_loss: 182.1733\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.9884 - val_loss: 180.0120\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 147.1003 - val_loss: 178.5643\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 145.3654 - val_loss: 176.0215\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 143.6599 - val_loss: 175.2693\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 141.6904 - val_loss: 172.8160\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 51ms/step - loss: 1595.4612 - val_loss: 1622.9188\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1576.6682 - val_loss: 1606.0266\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1562.0273 - val_loss: 1593.1095\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1549.8003 - val_loss: 1580.9147\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1537.1997 - val_loss: 1567.6503\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1523.2124 - val_loss: 1552.5615\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 5ms/step - loss: 1507.3577 - val_loss: 1535.1816\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1489.4294 - val_loss: 1514.6838\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1468.5194 - val_loss: 1491.5374\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1445.2301 - val_loss: 1465.5396\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1418.8435 - val_loss: 1436.9058\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 1389.7488 - val_loss: 1404.3718\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1356.5345 - val_loss: 1368.2815\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 1319.7947 - val_loss: 1326.9821\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 7ms/step - loss: 1277.5818 - val_loss: 1279.8938\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 1226.3590 - val_loss: 1222.4445\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 1167.0801 - val_loss: 1157.4100\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1101.8923 - val_loss: 1084.5442\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 1029.2373 - val_loss: 1007.4717\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 951.7306 - val_loss: 925.2399\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 868.7499 - val_loss: 838.9666\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 784.0683 - val_loss: 751.3808\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 5ms/step - loss: 700.0074 - val_loss: 665.9677\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 618.0236 - val_loss: 586.9114\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 542.7066 - val_loss: 514.7238\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 474.4059 - val_loss: 453.8315\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 415.7946 - val_loss: 404.0304\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 368.9084 - val_loss: 362.8372\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 328.9190 - val_loss: 333.6939\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 299.6505 - val_loss: 311.1650\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 5ms/step - loss: 276.3723 - val_loss: 296.0893\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 258.7142 - val_loss: 284.4868\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 245.4505 - val_loss: 275.2742\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 234.3557 - val_loss: 268.2659\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 225.7035 - val_loss: 262.2020\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 218.5018 - val_loss: 257.4089\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 212.6323 - val_loss: 252.9677\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 206.9893 - val_loss: 248.4823\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 202.0530 - val_loss: 244.2153\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 197.7506 - val_loss: 240.8865\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 193.5337 - val_loss: 236.8956\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 7ms/step - loss: 190.1151 - val_loss: 232.8870\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 5ms/step - loss: 186.8809 - val_loss: 230.6203\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 183.7919 - val_loss: 228.6551\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 180.9759 - val_loss: 225.0947\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 178.5494 - val_loss: 222.1002\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 175.9492 - val_loss: 219.6792\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 173.7405 - val_loss: 217.4930\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 171.7292 - val_loss: 214.8710\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 169.6983 - val_loss: 212.7313\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 73ms/step - loss: 1551.1315 - val_loss: 1582.6055\n",
            "Epoch 2/50\n",
            "23/23 - 2s - 98ms/step - loss: 1529.7944 - val_loss: 1560.9408\n",
            "Epoch 3/50\n",
            "23/23 - 1s - 30ms/step - loss: 1507.3156 - val_loss: 1537.3895\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1481.3372 - val_loss: 1508.9006\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1449.0887 - val_loss: 1472.3613\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 7ms/step - loss: 1407.8016 - val_loss: 1424.0542\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1354.5034 - val_loss: 1361.3926\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 12ms/step - loss: 1286.4805 - val_loss: 1283.0481\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1203.6669 - val_loss: 1186.3468\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 5ms/step - loss: 1104.1996 - val_loss: 1075.4087\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 992.8644 - val_loss: 953.2517\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 873.4272 - val_loss: 825.1884\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 5ms/step - loss: 750.0067 - val_loss: 698.2495\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 630.1752 - val_loss: 579.3050\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 5ms/step - loss: 519.9177 - val_loss: 477.2271\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 426.5113 - val_loss: 391.4741\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 349.3415 - val_loss: 327.6832\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 291.1664 - val_loss: 283.3380\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 249.8481 - val_loss: 253.0590\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 220.7686 - val_loss: 234.3120\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 201.8503 - val_loss: 222.0188\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 5ms/step - loss: 188.2627 - val_loss: 214.1878\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 179.1631 - val_loss: 207.6608\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 5ms/step - loss: 172.5495 - val_loss: 204.0309\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 167.2010 - val_loss: 199.8439\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 162.8772 - val_loss: 196.9574\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 159.3255 - val_loss: 194.3556\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 156.3680 - val_loss: 191.8021\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 153.6494 - val_loss: 189.4620\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 12ms/step - loss: 151.4019 - val_loss: 186.2992\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.1851 - val_loss: 184.5273\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 147.3542 - val_loss: 182.4937\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.5928 - val_loss: 181.3857\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 144.1147 - val_loss: 179.3673\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.6293 - val_loss: 178.0254\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.4828 - val_loss: 177.4363\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.3760 - val_loss: 175.7022\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 139.2692 - val_loss: 174.2757\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 138.1273 - val_loss: 172.4616\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.1358 - val_loss: 171.1350\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 5ms/step - loss: 136.2842 - val_loss: 170.0965\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 135.3274 - val_loss: 168.8648\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 9ms/step - loss: 134.5660 - val_loss: 167.4602\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 10ms/step - loss: 133.5970 - val_loss: 166.7574\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 132.9757 - val_loss: 165.7775\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 132.2197 - val_loss: 165.4787\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 131.6107 - val_loss: 163.3251\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 7ms/step - loss: 130.8547 - val_loss: 163.1809\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 130.2684 - val_loss: 162.0709\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 5ms/step - loss: 129.4988 - val_loss: 161.2700\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 70ms/step - loss: 1547.4059 - val_loss: 1575.8386\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1527.2831 - val_loss: 1552.9318\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 13ms/step - loss: 1504.8596 - val_loss: 1525.8253\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 13ms/step - loss: 1477.9509 - val_loss: 1494.3805\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 13ms/step - loss: 1445.0991 - val_loss: 1455.8865\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 8ms/step - loss: 1404.1027 - val_loss: 1407.5117\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 13ms/step - loss: 1354.0325 - val_loss: 1349.0691\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 10ms/step - loss: 1294.3883 - val_loss: 1282.1506\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1225.4237 - val_loss: 1205.3247\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1147.0298 - val_loss: 1118.6248\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1058.2286 - val_loss: 1023.4052\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 959.4293 - val_loss: 918.8636\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 853.1755 - val_loss: 807.5812\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 741.4724 - val_loss: 694.2994\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 630.3783 - val_loss: 584.6013\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 522.4703 - val_loss: 481.8195\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 419.9784 - val_loss: 393.9773\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 338.1732 - val_loss: 328.5921\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 279.7948 - val_loss: 288.0129\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 8ms/step - loss: 243.4114 - val_loss: 264.1183\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 11ms/step - loss: 221.4036 - val_loss: 249.7126\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 207.7644 - val_loss: 240.0548\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 5ms/step - loss: 198.9832 - val_loss: 233.1366\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 192.0023 - val_loss: 227.1585\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 186.8145 - val_loss: 222.2867\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 182.3930 - val_loss: 217.9689\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 5ms/step - loss: 178.6353 - val_loss: 214.5434\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 175.5950 - val_loss: 211.0892\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 172.8385 - val_loss: 207.9936\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 170.1330 - val_loss: 204.2729\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 167.8425 - val_loss: 202.3011\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 165.7261 - val_loss: 199.6801\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 5ms/step - loss: 163.8472 - val_loss: 197.5716\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 161.8514 - val_loss: 195.9808\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 7ms/step - loss: 160.0574 - val_loss: 193.2352\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 158.3781 - val_loss: 191.9405\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 156.8380 - val_loss: 190.2063\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 155.2802 - val_loss: 188.1772\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 153.8536 - val_loss: 186.2793\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 152.4648 - val_loss: 184.6530\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 150.9213 - val_loss: 182.9172\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.8734 - val_loss: 181.1382\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.5755 - val_loss: 179.4373\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 147.5356 - val_loss: 178.8601\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.3143 - val_loss: 176.3251\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 145.1510 - val_loss: 175.3042\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.4430 - val_loss: 173.9848\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 143.1162 - val_loss: 172.8255\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.1570 - val_loss: 172.6249\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.2146 - val_loss: 170.5407\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 55ms/step - loss: 1584.3816 - val_loss: 1610.3726\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1566.2573 - val_loss: 1595.0310\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 5ms/step - loss: 1553.0259 - val_loss: 1583.2850\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 5ms/step - loss: 1542.0306 - val_loss: 1572.1185\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 5ms/step - loss: 1530.7406 - val_loss: 1560.1295\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 7ms/step - loss: 1518.5599 - val_loss: 1546.9438\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1505.1678 - val_loss: 1532.6886\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1490.5597 - val_loss: 1516.4106\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 5ms/step - loss: 1473.7352 - val_loss: 1498.2656\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 1454.6849 - val_loss: 1476.2935\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1431.4867 - val_loss: 1450.3711\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 7ms/step - loss: 1403.3080 - val_loss: 1418.4962\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 5ms/step - loss: 1368.4922 - val_loss: 1379.5525\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 1326.4772 - val_loss: 1329.9106\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 1271.7535 - val_loss: 1270.2826\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 1208.3079 - val_loss: 1200.2455\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 5ms/step - loss: 1135.8246 - val_loss: 1121.1836\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 1054.8916 - val_loss: 1034.2444\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 967.0938 - val_loss: 940.5588\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 871.7631 - val_loss: 840.1135\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 771.0756 - val_loss: 734.6411\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 667.4478 - val_loss: 629.0114\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 565.8373 - val_loss: 527.5374\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 13ms/step - loss: 473.3465 - val_loss: 443.2293\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 394.6880 - val_loss: 376.8049\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 9ms/step - loss: 332.8857 - val_loss: 328.0071\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 11ms/step - loss: 286.5275 - val_loss: 292.5092\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 13ms/step - loss: 253.0372 - val_loss: 266.5876\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 228.0517 - val_loss: 250.2335\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 15ms/step - loss: 210.1082 - val_loss: 238.9496\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 11ms/step - loss: 197.8019 - val_loss: 230.8965\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 7ms/step - loss: 188.6289 - val_loss: 224.1940\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 12ms/step - loss: 181.7374 - val_loss: 219.1402\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 175.7533 - val_loss: 214.5287\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 170.7459 - val_loss: 210.1717\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.5968 - val_loss: 206.4980\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 162.6722 - val_loss: 203.1597\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 159.5031 - val_loss: 199.5021\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 156.8225 - val_loss: 197.6081\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 154.2063 - val_loss: 194.2324\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 151.8830 - val_loss: 192.1971\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 150.1193 - val_loss: 190.2437\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.1509 - val_loss: 188.1579\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.7988 - val_loss: 186.3652\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.3180 - val_loss: 185.2439\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 144.1409 - val_loss: 183.7275\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 142.8644 - val_loss: 182.1508\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.7256 - val_loss: 181.0220\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.6543 - val_loss: 179.6321\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 139.6726 - val_loss: 177.7342\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 55ms/step - loss: 1590.1694 - val_loss: 1620.4226\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1574.2587 - val_loss: 1605.4631\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1561.3857 - val_loss: 1591.5581\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1548.1294 - val_loss: 1574.9093\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1529.5609 - val_loss: 1550.7638\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1504.4104 - val_loss: 1519.7261\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 7ms/step - loss: 1471.7286 - val_loss: 1478.8811\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1428.8506 - val_loss: 1425.7067\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1373.2703 - val_loss: 1354.2266\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1297.8524 - val_loss: 1266.4133\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1208.2128 - val_loss: 1158.8889\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 1098.7872 - val_loss: 1042.4915\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 981.7001 - val_loss: 910.2274\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 854.9552 - val_loss: 779.9766\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 5ms/step - loss: 730.9432 - val_loss: 653.8840\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 612.9414 - val_loss: 542.5532\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 5ms/step - loss: 507.7965 - val_loss: 451.9868\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 421.2334 - val_loss: 381.6501\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 355.0601 - val_loss: 330.6880\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 306.6060 - val_loss: 298.4814\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 272.8394 - val_loss: 279.5959\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 250.2862 - val_loss: 267.2338\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 5ms/step - loss: 235.0262 - val_loss: 257.7194\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 223.7693 - val_loss: 251.3036\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 214.7090 - val_loss: 245.5522\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 208.1674 - val_loss: 240.4296\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 201.7080 - val_loss: 235.2649\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 196.3155 - val_loss: 229.8785\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 191.7432 - val_loss: 224.5268\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 7ms/step - loss: 187.5674 - val_loss: 221.5439\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 183.1219 - val_loss: 217.5157\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 179.1955 - val_loss: 212.5230\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 175.4596 - val_loss: 209.8035\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 171.9236 - val_loss: 206.4469\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 168.7563 - val_loss: 202.6249\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 165.8113 - val_loss: 199.4070\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 163.0936 - val_loss: 197.0331\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 160.7511 - val_loss: 195.4829\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 158.4268 - val_loss: 191.6747\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 155.8509 - val_loss: 189.7832\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 7ms/step - loss: 153.5007 - val_loss: 187.7972\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 151.4461 - val_loss: 185.4520\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.2591 - val_loss: 183.8342\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 5ms/step - loss: 147.3599 - val_loss: 182.0405\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.8343 - val_loss: 178.5573\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 143.8835 - val_loss: 177.9771\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.2221 - val_loss: 175.8098\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.5596 - val_loss: 174.0540\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 139.1623 - val_loss: 172.7080\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 13ms/step - loss: 137.6491 - val_loss: 170.7120\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 81ms/step - loss: 1505.3738 - val_loss: 1522.5000\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 5ms/step - loss: 1476.4155 - val_loss: 1489.0851\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1441.5460 - val_loss: 1449.1051\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1398.5834 - val_loss: 1398.4716\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1343.6534 - val_loss: 1335.0482\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 5ms/step - loss: 1274.6470 - val_loss: 1256.3765\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1190.9148 - val_loss: 1163.0135\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1093.9738 - val_loss: 1056.7467\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 984.1795 - val_loss: 940.5583\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 7ms/step - loss: 869.2465 - val_loss: 818.2266\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 750.5995 - val_loss: 699.2174\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 635.7985 - val_loss: 588.7246\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 532.9262 - val_loss: 491.4220\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 444.8644 - val_loss: 410.9814\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 373.2144 - val_loss: 351.4385\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 318.8430 - val_loss: 309.6138\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 279.6609 - val_loss: 279.7375\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 5ms/step - loss: 251.5112 - val_loss: 258.3543\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 232.0362 - val_loss: 244.4570\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 217.4500 - val_loss: 234.3388\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 207.0471 - val_loss: 226.5979\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 198.7851 - val_loss: 220.6796\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 192.2158 - val_loss: 215.1087\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 5ms/step - loss: 186.7791 - val_loss: 210.8731\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 181.9956 - val_loss: 207.0101\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 5ms/step - loss: 177.9222 - val_loss: 204.5497\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 174.0000 - val_loss: 201.6001\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 170.9688 - val_loss: 198.8716\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 168.0573 - val_loss: 197.0468\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 165.6246 - val_loss: 195.3290\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 163.1332 - val_loss: 192.9338\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 161.2673 - val_loss: 191.4815\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 159.2716 - val_loss: 189.7061\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 157.2900 - val_loss: 188.0573\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 155.4877 - val_loss: 186.5982\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 153.8645 - val_loss: 185.3493\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 152.3766 - val_loss: 184.3031\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 8ms/step - loss: 150.8649 - val_loss: 182.5048\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 149.5781 - val_loss: 180.7137\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 147.8917 - val_loss: 179.8577\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 146.5566 - val_loss: 178.8175\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.1909 - val_loss: 177.5829\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 143.9991 - val_loss: 176.2432\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 142.8832 - val_loss: 175.5611\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.4885 - val_loss: 174.1882\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.3603 - val_loss: 171.8903\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 139.2381 - val_loss: 171.4366\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 138.1152 - val_loss: 170.4584\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 137.1736 - val_loss: 169.2841\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 136.0628 - val_loss: 168.4510\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 53ms/step - loss: 1493.0024 - val_loss: 1509.1323\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1458.2472 - val_loss: 1471.0753\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1419.7274 - val_loss: 1427.4065\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1374.3060 - val_loss: 1375.7661\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1319.5920 - val_loss: 1313.7131\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1252.9962 - val_loss: 1239.1656\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1173.0880 - val_loss: 1149.0435\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1077.3326 - val_loss: 1046.4604\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 970.1204 - val_loss: 928.8669\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 5ms/step - loss: 853.2849 - val_loss: 806.4220\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 7ms/step - loss: 733.3929 - val_loss: 687.2216\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 618.5185 - val_loss: 577.6715\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 516.4823 - val_loss: 481.7645\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 431.9242 - val_loss: 406.1885\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 365.8209 - val_loss: 351.3940\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 317.0015 - val_loss: 312.1230\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 282.3948 - val_loss: 284.6543\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 256.3956 - val_loss: 265.6935\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 7ms/step - loss: 238.6592 - val_loss: 251.3581\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 11ms/step - loss: 224.5419 - val_loss: 240.4612\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 213.7794 - val_loss: 232.2675\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 204.8497 - val_loss: 225.7197\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 197.8530 - val_loss: 219.8555\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 191.9829 - val_loss: 215.9509\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 7ms/step - loss: 186.8245 - val_loss: 210.9764\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 13ms/step - loss: 182.2092 - val_loss: 207.7047\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 7ms/step - loss: 178.2653 - val_loss: 204.2484\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 13ms/step - loss: 174.8903 - val_loss: 200.6915\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 7ms/step - loss: 171.6923 - val_loss: 197.4437\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 13ms/step - loss: 168.8319 - val_loss: 195.0601\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 9ms/step - loss: 166.1026 - val_loss: 192.5563\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 163.7035 - val_loss: 189.8380\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 161.6512 - val_loss: 187.8010\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 159.5935 - val_loss: 185.8261\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 157.5211 - val_loss: 183.9444\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 155.9991 - val_loss: 181.7681\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 154.2145 - val_loss: 180.8683\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 152.7040 - val_loss: 178.9468\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 151.2243 - val_loss: 177.3634\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 149.6792 - val_loss: 176.2731\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 5ms/step - loss: 148.4615 - val_loss: 174.6578\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 147.2070 - val_loss: 173.2258\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 145.8492 - val_loss: 171.3348\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 5ms/step - loss: 144.8372 - val_loss: 170.6634\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 143.5005 - val_loss: 169.1974\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 142.5393 - val_loss: 168.2912\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.3123 - val_loss: 166.4546\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.3911 - val_loss: 165.1846\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 139.4697 - val_loss: 164.6553\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 138.2856 - val_loss: 163.8340\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 52ms/step - loss: 1552.6012 - val_loss: 1583.5092\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1540.2921 - val_loss: 1571.9714\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1528.5243 - val_loss: 1559.9106\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1515.4987 - val_loss: 1544.9000\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1498.1608 - val_loss: 1524.3246\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1474.7860 - val_loss: 1497.6448\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1442.2062 - val_loss: 1458.8906\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1395.0364 - val_loss: 1404.6283\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1335.6141 - val_loss: 1336.7205\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1262.3932 - val_loss: 1255.8486\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 1175.1843 - val_loss: 1159.6748\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 1073.1084 - val_loss: 1050.5028\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 960.5989 - val_loss: 931.2574\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 841.6599 - val_loss: 811.3222\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 723.3657 - val_loss: 695.8708\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 613.0578 - val_loss: 592.4495\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 515.8887 - val_loss: 502.1954\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 433.7148 - val_loss: 429.8442\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 367.1574 - val_loss: 374.8695\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 317.4015 - val_loss: 333.5172\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 280.3465 - val_loss: 302.8086\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 5ms/step - loss: 252.1414 - val_loss: 281.8401\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 5ms/step - loss: 232.8983 - val_loss: 267.5609\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 218.6599 - val_loss: 258.1920\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 208.7541 - val_loss: 251.0804\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 201.2225 - val_loss: 245.5680\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 195.4095 - val_loss: 242.1015\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 190.5014 - val_loss: 238.5750\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 186.6491 - val_loss: 235.1256\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 183.3909 - val_loss: 232.1830\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 180.3037 - val_loss: 229.5545\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 177.6700 - val_loss: 226.6404\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 174.9470 - val_loss: 224.4818\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 172.6430 - val_loss: 221.4133\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 170.2929 - val_loss: 219.1544\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 168.2667 - val_loss: 217.1283\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 166.1395 - val_loss: 214.1243\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 164.2159 - val_loss: 211.6147\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 162.4478 - val_loss: 208.8559\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 160.6654 - val_loss: 207.2685\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 159.0054 - val_loss: 205.1798\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 157.2514 - val_loss: 202.2094\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 155.7915 - val_loss: 200.5572\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 154.2045 - val_loss: 198.2331\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 152.6270 - val_loss: 195.8395\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 151.1545 - val_loss: 193.9337\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 7ms/step - loss: 149.9891 - val_loss: 192.3274\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 5ms/step - loss: 148.3502 - val_loss: 190.0726\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 146.8072 - val_loss: 187.5003\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 145.4455 - val_loss: 184.7708\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 74ms/step - loss: 1506.8518 - val_loss: 1530.7231\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 6ms/step - loss: 1483.9586 - val_loss: 1503.5927\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1453.8165 - val_loss: 1466.4114\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 16ms/step - loss: 1412.7130 - val_loss: 1417.2150\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 8ms/step - loss: 1358.3024 - val_loss: 1352.8334\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 11ms/step - loss: 1287.8984 - val_loss: 1271.7727\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1200.3198 - val_loss: 1172.1356\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1096.9500 - val_loss: 1057.3552\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 979.7378 - val_loss: 936.5461\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 857.8011 - val_loss: 813.3930\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 7ms/step - loss: 736.4326 - val_loss: 697.0682\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 623.6366 - val_loss: 597.4114\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 526.8302 - val_loss: 518.1942\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 450.0297 - val_loss: 457.2470\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 390.8864 - val_loss: 413.9261\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 346.9834 - val_loss: 381.2085\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 313.2123 - val_loss: 354.4960\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 286.6338 - val_loss: 332.4507\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 265.4297 - val_loss: 313.7562\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 248.5205 - val_loss: 297.9880\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 234.2731 - val_loss: 283.0857\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 222.4940 - val_loss: 270.6156\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 212.7307 - val_loss: 259.1732\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 203.6269 - val_loss: 249.4782\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 196.0146 - val_loss: 240.0790\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 189.4066 - val_loss: 231.2480\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 183.4409 - val_loss: 224.5962\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 177.8284 - val_loss: 218.6095\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 173.0781 - val_loss: 213.4199\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 168.7966 - val_loss: 207.6730\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 164.8032 - val_loss: 202.8502\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 161.2772 - val_loss: 198.9580\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 158.2490 - val_loss: 194.9372\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 155.2791 - val_loss: 191.5048\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 152.6483 - val_loss: 188.5160\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 7ms/step - loss: 150.2594 - val_loss: 184.8621\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 147.9394 - val_loss: 182.2151\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.7353 - val_loss: 179.6079\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 143.9667 - val_loss: 177.2058\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.9158 - val_loss: 173.1981\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 140.0765 - val_loss: 171.6534\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 138.4915 - val_loss: 169.1316\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 136.8294 - val_loss: 166.8512\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 135.2192 - val_loss: 164.3992\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 133.6976 - val_loss: 162.6219\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 132.3248 - val_loss: 160.8693\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 131.0394 - val_loss: 159.9420\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 129.7189 - val_loss: 158.0029\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 128.2111 - val_loss: 155.9010\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 127.1241 - val_loss: 154.8183\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 51ms/step - loss: 1525.9889 - val_loss: 1558.0760\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1505.6407 - val_loss: 1538.2263\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1482.1584 - val_loss: 1513.0703\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1452.2189 - val_loss: 1481.0671\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1414.6123 - val_loss: 1439.2874\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1365.3267 - val_loss: 1385.9830\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1303.0247 - val_loss: 1317.7812\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1226.0496 - val_loss: 1236.1964\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1136.9036 - val_loss: 1140.4441\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1035.9164 - val_loss: 1034.7671\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 924.9250 - val_loss: 922.1155\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 811.1188 - val_loss: 803.8604\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 696.6946 - val_loss: 689.7768\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 586.2262 - val_loss: 588.1302\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 488.4554 - val_loss: 498.3090\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 407.7664 - val_loss: 423.2141\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 344.3928 - val_loss: 366.6516\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 297.3772 - val_loss: 327.1380\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 265.0028 - val_loss: 297.2549\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 240.9779 - val_loss: 275.6285\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 222.9855 - val_loss: 259.4484\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 209.6887 - val_loss: 246.8674\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 198.7445 - val_loss: 236.3861\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 190.4900 - val_loss: 228.8262\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 7ms/step - loss: 184.1772 - val_loss: 222.1146\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 178.7151 - val_loss: 217.4747\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 174.5137 - val_loss: 213.3427\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 170.6666 - val_loss: 209.3460\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 167.5650 - val_loss: 206.7679\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 14ms/step - loss: 164.7847 - val_loss: 203.5578\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 13ms/step - loss: 162.4887 - val_loss: 201.6051\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 160.1512 - val_loss: 199.0563\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 14ms/step - loss: 158.1419 - val_loss: 196.9472\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 14ms/step - loss: 155.9428 - val_loss: 194.1697\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 154.1699 - val_loss: 192.4687\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 11ms/step - loss: 152.4762 - val_loss: 190.8318\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 150.9216 - val_loss: 189.4797\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.5515 - val_loss: 186.9676\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.2236 - val_loss: 185.6451\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 147.1368 - val_loss: 184.3664\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.9603 - val_loss: 183.2298\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.0028 - val_loss: 182.0848\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 144.0956 - val_loss: 180.5705\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 142.9598 - val_loss: 179.8445\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.1819 - val_loss: 178.1584\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.2411 - val_loss: 176.7388\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.4784 - val_loss: 176.0394\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 139.7563 - val_loss: 175.0353\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 139.0095 - val_loss: 174.4457\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 5ms/step - loss: 138.3025 - val_loss: 173.7277\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 51ms/step - loss: 1551.3252 - val_loss: 1573.0562\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1515.4807 - val_loss: 1535.6456\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 1478.1228 - val_loss: 1494.5016\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1435.4774 - val_loss: 1447.4873\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1385.2705 - val_loss: 1390.0048\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1323.9866 - val_loss: 1320.2952\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1249.0846 - val_loss: 1237.9193\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1161.9265 - val_loss: 1139.8032\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 5ms/step - loss: 1060.1617 - val_loss: 1030.5317\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 947.5286 - val_loss: 912.9102\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 829.0690 - val_loss: 791.3761\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 5ms/step - loss: 710.3966 - val_loss: 673.8453\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 596.7330 - val_loss: 568.2035\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 497.5625 - val_loss: 477.4915\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 413.5740 - val_loss: 408.8040\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 350.0915 - val_loss: 357.3729\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 301.2989 - val_loss: 325.1877\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 268.7690 - val_loss: 302.1178\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 246.3036 - val_loss: 287.2778\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 7ms/step - loss: 230.2104 - val_loss: 277.0695\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 218.8848 - val_loss: 268.4263\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 209.6361 - val_loss: 260.6892\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 202.4735 - val_loss: 253.2352\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 196.7234 - val_loss: 247.4744\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 190.7669 - val_loss: 241.2305\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 186.3761 - val_loss: 235.1516\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 5ms/step - loss: 182.3917 - val_loss: 230.5276\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 7ms/step - loss: 178.7489 - val_loss: 226.8465\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 175.5387 - val_loss: 221.7401\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 172.8302 - val_loss: 218.6678\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 7ms/step - loss: 169.9877 - val_loss: 214.4062\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 5ms/step - loss: 167.8305 - val_loss: 211.4389\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 165.4546 - val_loss: 208.6877\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 163.5316 - val_loss: 205.7673\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 7ms/step - loss: 161.7971 - val_loss: 203.3859\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 159.6677 - val_loss: 201.2062\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 157.9539 - val_loss: 198.5869\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 156.3642 - val_loss: 196.4961\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 154.8612 - val_loss: 195.0029\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 153.4023 - val_loss: 192.7649\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 151.8480 - val_loss: 190.4576\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 7ms/step - loss: 150.4416 - val_loss: 188.7112\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 149.2563 - val_loss: 187.2398\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 147.9874 - val_loss: 185.0014\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.9686 - val_loss: 184.0397\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.6255 - val_loss: 182.3840\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.5527 - val_loss: 180.8993\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 143.6033 - val_loss: 179.4458\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.6266 - val_loss: 177.4508\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 141.3797 - val_loss: 176.1948\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 71ms/step - loss: 1549.0537 - val_loss: 1568.3618\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 20ms/step - loss: 1516.5553 - val_loss: 1535.0280\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 13ms/step - loss: 1484.0272 - val_loss: 1499.8589\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 11ms/step - loss: 1448.2444 - val_loss: 1458.1783\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1404.4250 - val_loss: 1406.3165\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1349.0343 - val_loss: 1340.0363\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1277.9495 - val_loss: 1258.7548\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1192.3584 - val_loss: 1164.6305\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1095.2821 - val_loss: 1058.5940\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 986.9299 - val_loss: 945.1504\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 872.8209 - val_loss: 825.9442\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 756.5905 - val_loss: 709.5709\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 7ms/step - loss: 643.6861 - val_loss: 602.9938\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 541.8310 - val_loss: 510.5664\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 454.6172 - val_loss: 437.0815\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 386.0197 - val_loss: 381.0808\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 333.8412 - val_loss: 343.2792\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 296.7155 - val_loss: 317.8039\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 271.6368 - val_loss: 300.2622\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 253.2103 - val_loss: 286.7560\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 239.0008 - val_loss: 275.8628\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 227.9256 - val_loss: 265.9576\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 218.9201 - val_loss: 256.1481\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 209.7406 - val_loss: 249.4495\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 7ms/step - loss: 202.2114 - val_loss: 242.1246\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 195.6855 - val_loss: 235.1309\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 189.6404 - val_loss: 229.1668\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 184.2566 - val_loss: 223.4841\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 179.2166 - val_loss: 219.2358\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 5ms/step - loss: 175.1777 - val_loss: 214.4277\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 170.9707 - val_loss: 211.1639\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 167.3380 - val_loss: 207.4569\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 164.3339 - val_loss: 203.9534\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 161.2759 - val_loss: 201.3893\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 158.3902 - val_loss: 198.6756\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 155.8073 - val_loss: 196.6946\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 153.5060 - val_loss: 194.6233\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 151.3518 - val_loss: 192.0927\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.3397 - val_loss: 190.2947\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 147.5023 - val_loss: 187.6702\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 5ms/step - loss: 145.6456 - val_loss: 186.3845\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 5ms/step - loss: 143.8591 - val_loss: 184.3307\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 5ms/step - loss: 142.3907 - val_loss: 182.4935\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 140.9754 - val_loss: 181.4928\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 139.3680 - val_loss: 179.1429\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 138.0977 - val_loss: 178.2837\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 136.8166 - val_loss: 176.1054\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 135.7413 - val_loss: 174.7678\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 134.4501 - val_loss: 173.6108\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 133.3191 - val_loss: 172.0835\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 52ms/step - loss: 1506.0759 - val_loss: 1523.3362\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1471.7410 - val_loss: 1484.6711\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 7ms/step - loss: 1432.6154 - val_loss: 1440.5443\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1385.0743 - val_loss: 1384.4961\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1325.6002 - val_loss: 1312.2494\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1249.7158 - val_loss: 1227.2257\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1160.3054 - val_loss: 1125.8389\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1057.0417 - val_loss: 1013.0977\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 942.8530 - val_loss: 895.8282\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 824.7964 - val_loss: 780.3744\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 709.7564 - val_loss: 673.8678\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 607.4713 - val_loss: 583.9264\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 521.9058 - val_loss: 511.5977\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 453.5305 - val_loss: 454.0720\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 5ms/step - loss: 397.5454 - val_loss: 409.0327\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 7ms/step - loss: 353.4905 - val_loss: 368.7549\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 315.2746 - val_loss: 335.5286\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 283.7629 - val_loss: 307.5446\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 258.1130 - val_loss: 283.7013\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 236.1995 - val_loss: 263.4927\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 219.4651 - val_loss: 249.4788\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 5ms/step - loss: 207.0355 - val_loss: 238.3033\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 197.1519 - val_loss: 230.5199\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 8ms/step - loss: 190.0029 - val_loss: 225.9072\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 183.8233 - val_loss: 219.3511\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 178.8963 - val_loss: 215.3652\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 174.7142 - val_loss: 210.7094\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 13ms/step - loss: 171.2956 - val_loss: 207.0358\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 168.2156 - val_loss: 205.2881\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 165.2672 - val_loss: 201.5275\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 162.6006 - val_loss: 198.4164\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 160.3604 - val_loss: 197.8588\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 157.6144 - val_loss: 194.4864\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 155.4988 - val_loss: 192.0604\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 12ms/step - loss: 153.4536 - val_loss: 189.9264\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 15ms/step - loss: 151.9130 - val_loss: 188.4655\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 10ms/step - loss: 150.4136 - val_loss: 186.4074\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.0929 - val_loss: 185.4144\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 147.7268 - val_loss: 183.3773\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.3922 - val_loss: 181.8741\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 145.1430 - val_loss: 180.3716\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.1286 - val_loss: 179.3787\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 143.0082 - val_loss: 177.5466\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.1720 - val_loss: 177.2807\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 141.2088 - val_loss: 175.4761\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 140.2187 - val_loss: 173.9913\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 139.3604 - val_loss: 173.2646\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 138.2367 - val_loss: 172.9344\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.3192 - val_loss: 171.0155\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 136.4611 - val_loss: 169.3498\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 52ms/step - loss: 1546.9215 - val_loss: 1567.3087\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1517.9891 - val_loss: 1535.7137\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1486.7644 - val_loss: 1500.4962\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1449.9320 - val_loss: 1458.7867\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1405.6799 - val_loss: 1407.0540\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1351.6221 - val_loss: 1344.8025\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1287.2612 - val_loss: 1272.7638\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1213.4359 - val_loss: 1189.1348\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1129.3729 - val_loss: 1094.7769\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1035.8031 - val_loss: 991.7643\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 933.1375 - val_loss: 880.4164\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 824.4277 - val_loss: 762.6521\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 713.6663 - val_loss: 650.2717\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 607.0486 - val_loss: 547.5687\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 512.4953 - val_loss: 452.7758\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 428.3516 - val_loss: 377.8994\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 359.5350 - val_loss: 322.0894\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 307.0046 - val_loss: 281.3219\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 268.5423 - val_loss: 254.0204\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 241.7326 - val_loss: 237.5375\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 224.3543 - val_loss: 228.7354\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 213.2871 - val_loss: 223.3951\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 6ms/step - loss: 204.8311 - val_loss: 220.6538\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 198.8620 - val_loss: 218.4079\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 194.0769 - val_loss: 216.5911\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 190.0760 - val_loss: 213.8902\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 186.4389 - val_loss: 212.6938\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 183.2477 - val_loss: 209.9953\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 180.2894 - val_loss: 208.5240\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 177.1868 - val_loss: 206.1702\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 174.5003 - val_loss: 204.4131\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 7ms/step - loss: 171.8746 - val_loss: 202.2424\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 169.5447 - val_loss: 199.3279\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 5ms/step - loss: 166.9801 - val_loss: 197.8665\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 164.6600 - val_loss: 195.7416\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 162.5705 - val_loss: 194.5367\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 160.4267 - val_loss: 192.3884\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 158.4919 - val_loss: 190.9641\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 156.8084 - val_loss: 189.5731\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 155.0323 - val_loss: 187.8360\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 153.3045 - val_loss: 186.7971\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 151.7487 - val_loss: 185.3227\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 150.2924 - val_loss: 184.3101\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.9706 - val_loss: 182.5573\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 147.3785 - val_loss: 181.6112\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 146.2557 - val_loss: 180.6453\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 144.7980 - val_loss: 179.9570\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 143.6480 - val_loss: 178.3091\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.6067 - val_loss: 177.4120\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 141.2944 - val_loss: 175.9447\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 67ms/step - loss: 1608.0272 - val_loss: 1638.8340\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 18ms/step - loss: 1578.6671 - val_loss: 1608.9954\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1550.3829 - val_loss: 1578.7527\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1521.2585 - val_loss: 1547.5627\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1489.9520 - val_loss: 1513.1675\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 7ms/step - loss: 1455.1654 - val_loss: 1474.4756\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 8ms/step - loss: 1416.1317 - val_loss: 1431.7382\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 14ms/step - loss: 1372.9493 - val_loss: 1383.3903\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 10ms/step - loss: 1323.5441 - val_loss: 1329.5117\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1267.9169 - val_loss: 1267.6364\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1204.4265 - val_loss: 1198.9144\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 7ms/step - loss: 1134.1763 - val_loss: 1123.2993\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 1057.3219 - val_loss: 1040.3110\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 973.9761 - val_loss: 953.2263\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 887.2573 - val_loss: 859.3660\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 796.9262 - val_loss: 765.8144\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 706.8416 - val_loss: 673.9579\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 620.0250 - val_loss: 585.9550\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 537.1816 - val_loss: 507.4478\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 464.3732 - val_loss: 436.4427\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 5ms/step - loss: 401.0939 - val_loss: 376.4087\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 347.7693 - val_loss: 331.9784\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 308.1186 - val_loss: 297.9597\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 277.9899 - val_loss: 273.4844\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 256.0834 - val_loss: 257.2907\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 240.5303 - val_loss: 246.5488\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 229.8898 - val_loss: 238.9879\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 5ms/step - loss: 222.1003 - val_loss: 234.1424\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 215.8466 - val_loss: 230.1324\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 211.0507 - val_loss: 227.0829\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 206.4942 - val_loss: 223.7270\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 202.4241 - val_loss: 220.8543\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 7ms/step - loss: 198.7660 - val_loss: 218.3154\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 195.2689 - val_loss: 215.7278\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 192.2416 - val_loss: 213.7692\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 189.2040 - val_loss: 210.8084\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 186.0920 - val_loss: 208.4627\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 5ms/step - loss: 183.3382 - val_loss: 205.8133\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 180.6884 - val_loss: 203.8262\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 178.0894 - val_loss: 201.6528\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 175.5134 - val_loss: 199.7008\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 173.3466 - val_loss: 197.8591\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 170.6535 - val_loss: 195.8206\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 4ms/step - loss: 168.4281 - val_loss: 194.5175\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.4722 - val_loss: 193.1844\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 164.2262 - val_loss: 191.2263\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 161.7992 - val_loss: 189.3891\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 160.0192 - val_loss: 187.7549\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 157.8605 - val_loss: 186.0356\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 5ms/step - loss: 155.9843 - val_loss: 184.5734\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 51ms/step - loss: 1496.0024 - val_loss: 1513.3441\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1469.5304 - val_loss: 1482.9670\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1437.8580 - val_loss: 1445.8704\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1399.4825 - val_loss: 1400.1686\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1351.5475 - val_loss: 1344.9374\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 5ms/step - loss: 1292.8457 - val_loss: 1275.8652\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1220.2797 - val_loss: 1192.9767\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1133.0717 - val_loss: 1093.1329\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 7ms/step - loss: 1031.6036 - val_loss: 978.4894\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 917.2739 - val_loss: 855.2714\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 796.4525 - val_loss: 725.6781\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 671.4971 - val_loss: 598.7740\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 551.9760 - val_loss: 485.2166\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 447.3808 - val_loss: 391.5019\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 363.1130 - val_loss: 319.3762\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 299.0875 - val_loss: 270.4295\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 254.5730 - val_loss: 240.5813\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 227.4803 - val_loss: 221.7430\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 5ms/step - loss: 208.7391 - val_loss: 212.8607\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 196.9514 - val_loss: 207.8058\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 189.6369 - val_loss: 204.0774\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 183.7288 - val_loss: 201.2617\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 179.3683 - val_loss: 199.1353\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 5ms/step - loss: 175.3871 - val_loss: 197.3874\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 171.9011 - val_loss: 194.7025\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 168.9469 - val_loss: 192.6339\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 5ms/step - loss: 166.1253 - val_loss: 190.1723\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 163.4514 - val_loss: 188.2159\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 161.0769 - val_loss: 185.9815\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 158.8914 - val_loss: 183.8701\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 156.6629 - val_loss: 181.6826\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 9ms/step - loss: 154.8319 - val_loss: 180.7950\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 11ms/step - loss: 152.8768 - val_loss: 178.5654\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 151.1095 - val_loss: 176.9676\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 149.5579 - val_loss: 174.4634\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 5ms/step - loss: 147.8554 - val_loss: 173.3075\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.2669 - val_loss: 171.4001\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.4411 - val_loss: 169.3758\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 142.9653 - val_loss: 168.2381\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.6755 - val_loss: 166.9471\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 8ms/step - loss: 140.1492 - val_loss: 165.2059\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 11ms/step - loss: 138.9730 - val_loss: 163.3117\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 13ms/step - loss: 137.3642 - val_loss: 162.1588\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 13ms/step - loss: 136.0950 - val_loss: 160.8078\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 134.9285 - val_loss: 159.9512\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 133.9005 - val_loss: 158.0946\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 132.6309 - val_loss: 156.5902\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 131.3800 - val_loss: 155.3698\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 130.3683 - val_loss: 154.4251\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 4ms/step - loss: 129.3171 - val_loss: 152.3717\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 51ms/step - loss: 1540.9962 - val_loss: 1568.1036\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1513.9988 - val_loss: 1538.0837\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1485.0446 - val_loss: 1505.9274\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1452.9558 - val_loss: 1469.3688\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 4ms/step - loss: 1415.3883 - val_loss: 1426.9677\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1371.0361 - val_loss: 1376.7802\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1318.4408 - val_loss: 1316.7729\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1255.5991 - val_loss: 1245.8815\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 5ms/step - loss: 1180.9177 - val_loss: 1164.9674\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1096.0559 - val_loss: 1072.8916\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1000.5346 - val_loss: 973.6165\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 898.8206 - val_loss: 869.4766\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 4ms/step - loss: 794.0630 - val_loss: 762.3881\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 688.0601 - val_loss: 660.8247\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 588.1400 - val_loss: 565.4695\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 5ms/step - loss: 497.0670 - val_loss: 480.2555\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 416.7702 - val_loss: 411.0198\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 4ms/step - loss: 351.7856 - val_loss: 356.5201\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 301.0690 - val_loss: 314.9911\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 262.4742 - val_loss: 286.3393\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 235.4793 - val_loss: 266.4444\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 216.3293 - val_loss: 251.5160\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 202.9383 - val_loss: 242.1593\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 193.3764 - val_loss: 234.6511\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 185.9791 - val_loss: 228.5356\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 180.7972 - val_loss: 223.4544\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 176.2536 - val_loss: 218.6482\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 172.4868 - val_loss: 214.4174\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 169.0188 - val_loss: 211.0514\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.1145 - val_loss: 207.7576\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 163.7047 - val_loss: 204.5907\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 161.2046 - val_loss: 201.7345\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 159.1503 - val_loss: 198.7461\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 157.0726 - val_loss: 196.4188\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 155.2884 - val_loss: 194.2825\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 153.3044 - val_loss: 192.2321\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 151.6947 - val_loss: 189.7995\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 149.9090 - val_loss: 188.0647\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.4360 - val_loss: 186.4189\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 6ms/step - loss: 147.0432 - val_loss: 185.1954\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.6405 - val_loss: 183.4478\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 7ms/step - loss: 144.3887 - val_loss: 181.4290\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 143.1358 - val_loss: 179.7141\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 7ms/step - loss: 141.9501 - val_loss: 179.1413\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 5ms/step - loss: 140.9987 - val_loss: 178.0616\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 139.9608 - val_loss: 176.7334\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 139.1221 - val_loss: 175.6118\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 138.0366 - val_loss: 174.9306\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.2874 - val_loss: 174.1078\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 7ms/step - loss: 136.3311 - val_loss: 172.9140\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 50ms/step - loss: 1525.0887 - val_loss: 1546.7061\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 8ms/step - loss: 1498.0829 - val_loss: 1517.1177\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1469.1519 - val_loss: 1483.9437\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1436.0972 - val_loss: 1444.3905\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 7ms/step - loss: 1396.0359 - val_loss: 1398.0154\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 6ms/step - loss: 1348.6270 - val_loss: 1342.8800\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1292.0559 - val_loss: 1279.1310\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1227.5616 - val_loss: 1203.6829\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1152.5238 - val_loss: 1122.5671\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1069.2941 - val_loss: 1031.2085\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 9ms/step - loss: 975.7919 - val_loss: 931.8893\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 10ms/step - loss: 873.9571 - val_loss: 826.0719\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 768.8562 - val_loss: 721.5718\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 7ms/step - loss: 666.5632 - val_loss: 624.8264\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 13ms/step - loss: 571.4244 - val_loss: 539.9020\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 14ms/step - loss: 486.7693 - val_loss: 465.5729\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 7ms/step - loss: 415.6770 - val_loss: 399.4343\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 352.7007 - val_loss: 350.7555\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 305.5127 - val_loss: 309.2860\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 267.5446 - val_loss: 278.3889\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 238.2630 - val_loss: 255.3576\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 216.9653 - val_loss: 238.1129\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 202.1009 - val_loss: 225.5311\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 190.8002 - val_loss: 216.6510\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 182.6250 - val_loss: 209.5572\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 176.5461 - val_loss: 203.8314\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 171.0966 - val_loss: 198.5249\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 166.7304 - val_loss: 195.3502\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 163.2172 - val_loss: 191.3957\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 7ms/step - loss: 160.1441 - val_loss: 188.1572\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 157.1349 - val_loss: 185.9280\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 154.7247 - val_loss: 183.2509\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 152.2655 - val_loss: 181.3812\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 149.9464 - val_loss: 178.9138\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 147.8394 - val_loss: 176.3478\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 145.9393 - val_loss: 174.7651\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 7ms/step - loss: 143.8214 - val_loss: 172.5658\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 7ms/step - loss: 141.9254 - val_loss: 171.4679\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.2112 - val_loss: 170.2150\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 138.3298 - val_loss: 168.1081\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.0049 - val_loss: 167.1890\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 135.4212 - val_loss: 164.6430\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 133.7218 - val_loss: 163.8201\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 131.9596 - val_loss: 162.2257\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 130.7050 - val_loss: 161.4963\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 4ms/step - loss: 128.9301 - val_loss: 158.9360\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 4ms/step - loss: 127.4495 - val_loss: 157.6341\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 5ms/step - loss: 125.8372 - val_loss: 155.1951\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 5ms/step - loss: 124.2231 - val_loss: 154.1887\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 122.5205 - val_loss: 152.7776\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 51ms/step - loss: 1551.1185 - val_loss: 1577.7142\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1533.9963 - val_loss: 1559.4296\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1515.2642 - val_loss: 1538.4004\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1492.6254 - val_loss: 1513.3163\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1465.2855 - val_loss: 1481.8987\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1430.7014 - val_loss: 1443.0237\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1387.4008 - val_loss: 1393.6298\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 4ms/step - loss: 1332.9186 - val_loss: 1331.4033\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 4ms/step - loss: 1264.9950 - val_loss: 1254.9224\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 6ms/step - loss: 1181.8473 - val_loss: 1160.9302\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 1082.2134 - val_loss: 1049.6516\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 965.2605 - val_loss: 927.8345\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 5ms/step - loss: 839.3583 - val_loss: 799.2382\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 711.8932 - val_loss: 673.4641\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 588.8248 - val_loss: 556.8438\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 4ms/step - loss: 476.4941 - val_loss: 457.9995\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 4ms/step - loss: 383.0409 - val_loss: 378.7255\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 7ms/step - loss: 311.1054 - val_loss: 323.9303\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 263.6022 - val_loss: 289.0949\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 233.0553 - val_loss: 268.1055\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 214.8150 - val_loss: 254.8535\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 5ms/step - loss: 203.6252 - val_loss: 245.8463\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 196.0299 - val_loss: 239.0705\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 190.6695 - val_loss: 233.0700\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 6ms/step - loss: 186.6814 - val_loss: 228.6934\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 4ms/step - loss: 183.5061 - val_loss: 224.8425\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 5ms/step - loss: 180.0729 - val_loss: 221.3005\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 177.3276 - val_loss: 217.4853\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 174.9508 - val_loss: 214.3788\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 172.6737 - val_loss: 212.1532\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 170.5391 - val_loss: 209.8893\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 168.7821 - val_loss: 207.5444\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 167.2758 - val_loss: 204.9435\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 165.4896 - val_loss: 203.0547\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 163.9321 - val_loss: 201.4007\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 162.4443 - val_loss: 199.6349\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 6ms/step - loss: 160.9914 - val_loss: 197.9185\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 4ms/step - loss: 159.6935 - val_loss: 195.8898\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 8ms/step - loss: 158.3532 - val_loss: 194.1211\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 8ms/step - loss: 157.0514 - val_loss: 192.3258\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 11ms/step - loss: 155.5715 - val_loss: 191.1394\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 7ms/step - loss: 154.2832 - val_loss: 189.4695\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 7ms/step - loss: 153.1130 - val_loss: 188.0966\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 12ms/step - loss: 151.8991 - val_loss: 186.6212\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 7ms/step - loss: 151.0998 - val_loss: 185.5457\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 13ms/step - loss: 149.7217 - val_loss: 183.7316\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 13ms/step - loss: 148.5222 - val_loss: 183.0193\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 15ms/step - loss: 147.3001 - val_loss: 181.1038\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 9ms/step - loss: 146.2358 - val_loss: 179.4857\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.2149 - val_loss: 178.5327\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 51ms/step - loss: 1564.4250 - val_loss: 1587.9257\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 7ms/step - loss: 1540.9039 - val_loss: 1564.4792\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1517.4283 - val_loss: 1538.4955\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1489.0391 - val_loss: 1505.6011\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1448.4598 - val_loss: 1456.1338\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1390.5175 - val_loss: 1390.6660\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 7ms/step - loss: 1316.3130 - val_loss: 1307.7821\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 5ms/step - loss: 1225.3558 - val_loss: 1209.0238\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1117.8475 - val_loss: 1093.3976\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 4ms/step - loss: 996.6219 - val_loss: 966.6804\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 6ms/step - loss: 867.8889 - val_loss: 834.7241\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 6ms/step - loss: 737.2626 - val_loss: 710.6619\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 7ms/step - loss: 619.7596 - val_loss: 598.1522\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 518.5237 - val_loss: 508.1605\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 6ms/step - loss: 437.5584 - val_loss: 441.2004\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 378.6190 - val_loss: 391.4874\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 335.4808 - val_loss: 354.6353\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 6ms/step - loss: 303.6203 - val_loss: 326.1630\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 6ms/step - loss: 279.2345 - val_loss: 304.7581\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 4ms/step - loss: 259.8293 - val_loss: 287.3315\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 4ms/step - loss: 244.5697 - val_loss: 273.1520\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 4ms/step - loss: 232.0583 - val_loss: 262.2795\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 222.2080 - val_loss: 253.5821\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 6ms/step - loss: 213.7841 - val_loss: 245.6348\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 206.3606 - val_loss: 239.2186\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 7ms/step - loss: 200.2064 - val_loss: 232.7732\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 194.6095 - val_loss: 227.8273\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 189.6183 - val_loss: 223.0200\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 6ms/step - loss: 184.9993 - val_loss: 217.8201\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 6ms/step - loss: 180.6760 - val_loss: 214.0718\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 176.5569 - val_loss: 210.1004\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 172.7204 - val_loss: 206.3588\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 6ms/step - loss: 169.5346 - val_loss: 203.3676\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 6ms/step - loss: 166.3962 - val_loss: 199.8868\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 4ms/step - loss: 163.5522 - val_loss: 197.1424\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 160.7973 - val_loss: 193.5831\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 4ms/step - loss: 158.1909 - val_loss: 191.2679\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 7ms/step - loss: 156.0645 - val_loss: 188.6300\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 7ms/step - loss: 154.0908 - val_loss: 186.4258\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 5ms/step - loss: 152.1922 - val_loss: 184.4686\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 4ms/step - loss: 150.2323 - val_loss: 181.2477\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 148.2574 - val_loss: 180.1582\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 6ms/step - loss: 146.6354 - val_loss: 178.4109\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 144.8237 - val_loss: 176.4933\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 143.3428 - val_loss: 175.0326\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.9359 - val_loss: 173.2536\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.4409 - val_loss: 171.8392\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 6ms/step - loss: 139.0377 - val_loss: 169.6754\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 4ms/step - loss: 138.1535 - val_loss: 168.2982\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 136.8425 - val_loss: 167.4762\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 51ms/step - loss: 1546.9463 - val_loss: 1564.6987\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1509.3730 - val_loss: 1523.0138\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 4ms/step - loss: 1469.5525 - val_loss: 1476.4706\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 6ms/step - loss: 1424.0403 - val_loss: 1425.2675\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 6ms/step - loss: 1373.5941 - val_loss: 1367.6440\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 7ms/step - loss: 1316.6278 - val_loss: 1304.2316\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 6ms/step - loss: 1253.0530 - val_loss: 1234.1943\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 12ms/step - loss: 1183.7675 - val_loss: 1155.2974\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 8ms/step - loss: 1106.4648 - val_loss: 1070.8228\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 9ms/step - loss: 1022.7218 - val_loss: 982.6729\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 10ms/step - loss: 935.4551 - val_loss: 890.7557\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 7ms/step - loss: 844.8335 - val_loss: 798.3373\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 753.8914 - val_loss: 708.0716\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 6ms/step - loss: 664.9285 - val_loss: 623.1327\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 13ms/step - loss: 582.1022 - val_loss: 544.1396\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 504.9685 - val_loss: 475.2439\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 437.3086 - val_loss: 416.8261\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 8ms/step - loss: 380.4931 - val_loss: 367.0442\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 12ms/step - loss: 332.0922 - val_loss: 327.8544\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 5ms/step - loss: 294.2496 - val_loss: 297.7943\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 263.9587 - val_loss: 277.5145\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 242.3658 - val_loss: 262.0789\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 4ms/step - loss: 226.0832 - val_loss: 251.9962\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 213.8442 - val_loss: 244.1432\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 5ms/step - loss: 204.0934 - val_loss: 237.5490\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 6ms/step - loss: 196.4416 - val_loss: 232.5102\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 6ms/step - loss: 189.8675 - val_loss: 227.8676\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 6ms/step - loss: 184.3343 - val_loss: 223.0215\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 5ms/step - loss: 179.1915 - val_loss: 218.9455\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 174.7727 - val_loss: 216.0352\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 4ms/step - loss: 170.7393 - val_loss: 211.5114\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 4ms/step - loss: 167.1523 - val_loss: 208.2747\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 163.7203 - val_loss: 205.8494\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 7ms/step - loss: 160.7387 - val_loss: 202.2705\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 6ms/step - loss: 157.8594 - val_loss: 199.9815\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 4ms/step - loss: 155.4629 - val_loss: 197.9352\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 152.9807 - val_loss: 196.3669\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 5ms/step - loss: 150.9776 - val_loss: 194.1915\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 4ms/step - loss: 148.8844 - val_loss: 191.5792\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 4ms/step - loss: 147.1298 - val_loss: 189.5544\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 145.1338 - val_loss: 188.0967\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 4ms/step - loss: 143.4964 - val_loss: 186.2656\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 4ms/step - loss: 142.0378 - val_loss: 184.6531\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 6ms/step - loss: 140.3072 - val_loss: 182.8504\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 4ms/step - loss: 139.2011 - val_loss: 180.7668\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 5ms/step - loss: 137.7122 - val_loss: 179.9118\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 5ms/step - loss: 136.5729 - val_loss: 178.2767\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 4ms/step - loss: 135.2150 - val_loss: 177.4081\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 6ms/step - loss: 134.2216 - val_loss: 176.3571\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 133.2336 - val_loss: 175.0768\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 52ms/step - loss: 1514.6420 - val_loss: 1525.1515\n",
            "Epoch 2/50\n",
            "23/23 - 0s - 4ms/step - loss: 1482.7668 - val_loss: 1490.1815\n",
            "Epoch 3/50\n",
            "23/23 - 0s - 6ms/step - loss: 1447.7231 - val_loss: 1449.2079\n",
            "Epoch 4/50\n",
            "23/23 - 0s - 4ms/step - loss: 1405.2085 - val_loss: 1399.8983\n",
            "Epoch 5/50\n",
            "23/23 - 0s - 7ms/step - loss: 1352.9110 - val_loss: 1339.7648\n",
            "Epoch 6/50\n",
            "23/23 - 0s - 4ms/step - loss: 1288.8315 - val_loss: 1265.3468\n",
            "Epoch 7/50\n",
            "23/23 - 0s - 4ms/step - loss: 1211.6362 - val_loss: 1179.6272\n",
            "Epoch 8/50\n",
            "23/23 - 0s - 6ms/step - loss: 1123.2006 - val_loss: 1083.7513\n",
            "Epoch 9/50\n",
            "23/23 - 0s - 6ms/step - loss: 1022.7050 - val_loss: 983.2968\n",
            "Epoch 10/50\n",
            "23/23 - 0s - 9ms/step - loss: 916.6626 - val_loss: 878.1102\n",
            "Epoch 11/50\n",
            "23/23 - 0s - 4ms/step - loss: 804.5802 - val_loss: 775.9860\n",
            "Epoch 12/50\n",
            "23/23 - 0s - 4ms/step - loss: 695.8220 - val_loss: 677.4731\n",
            "Epoch 13/50\n",
            "23/23 - 0s - 6ms/step - loss: 588.9006 - val_loss: 586.7480\n",
            "Epoch 14/50\n",
            "23/23 - 0s - 4ms/step - loss: 491.0847 - val_loss: 504.4654\n",
            "Epoch 15/50\n",
            "23/23 - 0s - 4ms/step - loss: 407.0731 - val_loss: 434.3992\n",
            "Epoch 16/50\n",
            "23/23 - 0s - 6ms/step - loss: 336.0038 - val_loss: 382.0988\n",
            "Epoch 17/50\n",
            "23/23 - 0s - 6ms/step - loss: 286.1801 - val_loss: 341.4171\n",
            "Epoch 18/50\n",
            "23/23 - 0s - 7ms/step - loss: 250.3632 - val_loss: 315.2565\n",
            "Epoch 19/50\n",
            "23/23 - 0s - 4ms/step - loss: 228.5956 - val_loss: 296.4482\n",
            "Epoch 20/50\n",
            "23/23 - 0s - 6ms/step - loss: 212.8787 - val_loss: 279.6442\n",
            "Epoch 21/50\n",
            "23/23 - 0s - 6ms/step - loss: 202.1429 - val_loss: 268.4861\n",
            "Epoch 22/50\n",
            "23/23 - 0s - 6ms/step - loss: 193.7167 - val_loss: 257.9474\n",
            "Epoch 23/50\n",
            "23/23 - 0s - 7ms/step - loss: 186.9747 - val_loss: 248.6770\n",
            "Epoch 24/50\n",
            "23/23 - 0s - 4ms/step - loss: 181.4086 - val_loss: 239.8865\n",
            "Epoch 25/50\n",
            "23/23 - 0s - 4ms/step - loss: 176.9350 - val_loss: 233.3584\n",
            "Epoch 26/50\n",
            "23/23 - 0s - 7ms/step - loss: 172.4805 - val_loss: 226.5950\n",
            "Epoch 27/50\n",
            "23/23 - 0s - 4ms/step - loss: 168.9983 - val_loss: 220.6020\n",
            "Epoch 28/50\n",
            "23/23 - 0s - 4ms/step - loss: 165.7927 - val_loss: 216.7576\n",
            "Epoch 29/50\n",
            "23/23 - 0s - 4ms/step - loss: 163.0136 - val_loss: 211.6125\n",
            "Epoch 30/50\n",
            "23/23 - 0s - 4ms/step - loss: 160.4291 - val_loss: 207.0625\n",
            "Epoch 31/50\n",
            "23/23 - 0s - 6ms/step - loss: 158.0822 - val_loss: 204.2087\n",
            "Epoch 32/50\n",
            "23/23 - 0s - 6ms/step - loss: 155.9136 - val_loss: 201.0332\n",
            "Epoch 33/50\n",
            "23/23 - 0s - 4ms/step - loss: 154.0544 - val_loss: 198.0128\n",
            "Epoch 34/50\n",
            "23/23 - 0s - 4ms/step - loss: 152.0193 - val_loss: 194.7791\n",
            "Epoch 35/50\n",
            "23/23 - 0s - 5ms/step - loss: 150.3299 - val_loss: 192.0432\n",
            "Epoch 36/50\n",
            "23/23 - 0s - 6ms/step - loss: 148.6532 - val_loss: 189.6104\n",
            "Epoch 37/50\n",
            "23/23 - 0s - 5ms/step - loss: 147.3152 - val_loss: 187.9130\n",
            "Epoch 38/50\n",
            "23/23 - 0s - 7ms/step - loss: 146.0624 - val_loss: 185.6214\n",
            "Epoch 39/50\n",
            "23/23 - 0s - 5ms/step - loss: 144.8055 - val_loss: 183.7031\n",
            "Epoch 40/50\n",
            "23/23 - 0s - 7ms/step - loss: 143.6655 - val_loss: 181.7332\n",
            "Epoch 41/50\n",
            "23/23 - 0s - 6ms/step - loss: 142.5195 - val_loss: 179.9969\n",
            "Epoch 42/50\n",
            "23/23 - 0s - 6ms/step - loss: 141.4519 - val_loss: 178.4730\n",
            "Epoch 43/50\n",
            "23/23 - 0s - 12ms/step - loss: 140.4149 - val_loss: 177.1782\n",
            "Epoch 44/50\n",
            "23/23 - 0s - 13ms/step - loss: 139.5433 - val_loss: 175.0347\n",
            "Epoch 45/50\n",
            "23/23 - 0s - 6ms/step - loss: 138.5620 - val_loss: 173.8536\n",
            "Epoch 46/50\n",
            "23/23 - 0s - 6ms/step - loss: 137.8366 - val_loss: 172.8320\n",
            "Epoch 47/50\n",
            "23/23 - 0s - 13ms/step - loss: 137.0321 - val_loss: 171.5566\n",
            "Epoch 48/50\n",
            "23/23 - 0s - 13ms/step - loss: 136.1382 - val_loss: 170.4400\n",
            "Epoch 49/50\n",
            "23/23 - 0s - 13ms/step - loss: 135.4384 - val_loss: 169.7552\n",
            "Epoch 50/50\n",
            "23/23 - 0s - 6ms/step - loss: 134.5809 - val_loss: 169.1201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the mean and standard deviation of the mean squared errors\n",
        "mean_mse = np.mean(mean_squared_errors)\n",
        "std_mse = np.std(mean_squared_errors)\n",
        "\n",
        "print(\"Mean of Mean Squared Errors: {}\".format(mean_mse))\n",
        "print(\"Standard Deviation of Mean Squared Errors: {}\".format(std_mse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95x7v9P7exOY",
        "outputId": "2117c924-37bf-4bfc-e8d7-c811aade5055"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of Mean Squared Errors: 171.76885772705077\n",
            "Standard Deviation of Mean Squared Errors: 9.68668555571361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# END"
      ],
      "metadata": {
        "id": "pSrbs5A8giVd"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}